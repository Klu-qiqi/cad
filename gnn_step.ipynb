{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –∏–º–ø–æ—Ä—Ç—ã –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "try:\n",
    "    from OCC.Core import STEPControl, TopExp, TopAbs\n",
    "    from OCC.Core.BRep import BRep_Tool\n",
    "    from OCC.Core.gp import gp_Pnt\n",
    "except ImportError:\n",
    "    print(\"–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ pythonocc-core: conda install -c conda-forge pythonocc-core=7.9.0\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ß—Ç–µ–Ω–∏–µ step —Ñ–∞–π–ª–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_step_file(filename):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç STEP-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç TopoDS_Shape\"\"\"\n",
    "    reader = STEPControl.STEPControl_Reader()\n",
    "    reader.ReadFile(str(filename))\n",
    "    reader.TransferRoots()\n",
    "    return reader.OneShape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω –∏ —Å–≤—è–∑–µ–π –≥—Ä–∞–Ω—å –≤–µ—Ä—à–∏–Ω–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topology(shape):\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–µ—Ä—à–∏–Ω—ã –∏ —Å–≤—è–∑–∏ –≥—Ä–∞–Ω—å-–≤–µ—Ä—à–∏–Ω–∞ \n",
    "    vertices = []\n",
    "    vertex_map = {}\n",
    "    face_vertex_indices = []\n",
    "\n",
    "    face_explorer = TopExp.TopExp_Explorer(shape, TopAbs.TopAbs_FACE)\n",
    "    while face_explorer.More():\n",
    "        face = face_explorer.Current()\n",
    "        local_vertices = []\n",
    "\n",
    "        edge_explorer = TopExp.TopExp_Explorer(face, TopAbs.TopAbs_EDGE)\n",
    "        while edge_explorer.More():\n",
    "            edge = edge_explorer.Current()\n",
    "            \n",
    "            # –í–ª–æ–∂–µ–Ω–Ω—ã–π —ç–∫—Å–ø–ª–æ—Ä–µ—Ä –¥–ª—è –≤–µ—Ä—à–∏–Ω \n",
    "            vertex_explorer = TopExp.TopExp_Explorer(edge, TopAbs.TopAbs_VERTEX)\n",
    "            while vertex_explorer.More():\n",
    "                vertex = vertex_explorer.Current()\n",
    "                p = BRep_Tool.Pnt(vertex)\n",
    "                key = (round(p.X(), 6), round(p.Y(), 6), round(p.Z(), 6))\n",
    "                if key not in vertex_map:\n",
    "                    vertex_map[key] = len(vertices)\n",
    "                    vertices.append(np.array([p.X(), p.Y(), p.Z()]))\n",
    "                local_vertices.append(vertex_map[key])\n",
    "                vertex_explorer.Next()\n",
    "            \n",
    "            edge_explorer.Next()\n",
    "\n",
    "        if local_vertices:\n",
    "            local_vertices = list(dict.fromkeys(local_vertices))\n",
    "            face_vertex_indices.append(local_vertices)\n",
    "        face_explorer.Next()\n",
    "\n",
    "    return np.array(vertices), face_vertex_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(vertices):\n",
    "    if len(vertices) == 0:\n",
    "        return vertices\n",
    "    center = vertices.mean(axis=0)\n",
    "    scale = np.max(np.abs(vertices - center)) + 1e-8\n",
    "    return (vertices - center) / scale\n",
    "\n",
    "def build_graph(vertices, face_vertex_indices):\n",
    "    n_vertices = len(vertices)\n",
    "    n_faces = len(face_vertex_indices)\n",
    "\n",
    "    vertices_norm = normalize_coordinates(vertices)\n",
    "    node_coords = np.zeros((n_vertices + n_faces, 3))\n",
    "    node_types = np.zeros(n_vertices + n_faces, dtype=int)\n",
    "\n",
    "    # –í–µ—Ä—à–∏–Ω—ã\n",
    "    node_coords[:n_vertices] = vertices_norm\n",
    "    node_types[:n_vertices] = 0\n",
    "\n",
    "    # –ì—Ä–∞–Ω–∏\n",
    "    for i, vtx_ids in enumerate(face_vertex_indices):\n",
    "        if vtx_ids:\n",
    "            center = vertices_norm[vtx_ids].mean(axis=0)\n",
    "            node_coords[n_vertices + i] = center\n",
    "            node_types[n_vertices + i] = 1\n",
    "\n",
    "    # –†—ë–±—Ä–∞\n",
    "    edge_index = []\n",
    "    for face_id, vtx_ids in enumerate(face_vertex_indices):\n",
    "        for vtx_id in vtx_ids:\n",
    "            edge_index.append([n_vertices + face_id, vtx_id])\n",
    "            edge_index.append([vtx_id, n_vertices + face_id])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(node_coords, dtype=torch.float)\n",
    "    node_type = torch.tensor(node_types, dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, node_type=node_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from OCC.Core.BRepPrimAPI import (\n",
    "    BRepPrimAPI_MakeBox, \n",
    "    BRepPrimAPI_MakeCylinder,\n",
    "    BRepPrimAPI_MakeSphere,\n",
    "    BRepPrimAPI_MakeCone\n",
    ")\n",
    "from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Fuse, BRepAlgoAPI_Cut\n",
    "from OCC.Core.gp import gp_Trsf, gp_Vec, gp_Ax2, gp_Pnt, gp_Dir\n",
    "from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "from OCC.Core.GProp import GProp_GProps\n",
    "from OCC.Core.BRepGProp import brepgprop_VolumeProperties\n",
    "from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape\n",
    "\n",
    "def compute_center_of_mass(shape):\n",
    "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å —Ç–µ–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ —Å–ø–∏—Å–æ–∫ [x, y, z]\"\"\"\n",
    "    props = GProp_GProps()\n",
    "    try:\n",
    "        brepgprop_VolumeProperties(shape, props)\n",
    "        cog = props.CentreOfMass()\n",
    "        return [float(cog.X()), float(cog.Y()), float(cog.Z())]  # –°–ø–∏—Å–æ–∫, –Ω–µ –º–∞—Å—Å–∏–≤!\n",
    "    except:\n",
    "        from OCC.Core.Bnd import Bnd_Box\n",
    "        from OCC.Core.BRepBndLib import brepbndlib_Add\n",
    "        bbox = Bnd_Box()\n",
    "        brepbndlib_Add(shape, bbox)\n",
    "        xmin, ymin, zmin, xmax, ymax, zmax = bbox.Get()\n",
    "        return [float((xmin+xmax)/2), float((ymin+ymax)/2), float((zmin+zmax)/2)]\n",
    "\n",
    "def create_synthetic_part(part_type=\"bracket\", seed=None, size_variation=1.0):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π –¥–µ—Ç–∞–ª–∏ —Å –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã –≤ JSON)\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "        shape: TopoDS_Shape ‚Äî –º–æ–¥–µ–ª—å\n",
    "        annotations: dict ‚Äî —Ä–∞–∑–º–µ—Ç–∫–∞ —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–ø–∏—Å–∫–∞–º–∏ (–Ω–µ numpy arrays)\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    base_size = 100.0 * size_variation\n",
    "    thickness = 10.0 * size_variation\n",
    "    \n",
    "    if part_type == \"bracket\":\n",
    "        base = BRepPrimAPI_MakeBox(base_size, base_size*0.5, thickness).Shape()\n",
    "        wall = BRepPrimAPI_MakeBox(thickness, base_size*0.5, base_size*0.4).Shape()\n",
    "        \n",
    "        trsf = gp_Trsf()\n",
    "        trsf.SetTranslation(gp_Vec(base_size - thickness, 0, thickness))\n",
    "        transform = BRepBuilderAPI_Transform(wall, trsf)\n",
    "        wall_pos = transform.Shape()\n",
    "        \n",
    "        part = BRepAlgoAPI_Fuse(base, wall_pos).Shape()\n",
    "        \n",
    "        holes = []\n",
    "        for i in range(2):\n",
    "            hole = BRepPrimAPI_MakeCylinder(5.0 * size_variation, thickness*1.5).Shape()\n",
    "            trsf = gp_Trsf()\n",
    "            trsf.SetTranslation(gp_Vec(base_size*0.3 + i*base_size*0.4, base_size*0.25, -thickness*0.25))\n",
    "            transform = BRepBuilderAPI_Transform(hole, trsf)\n",
    "            hole_pos = transform.Shape()\n",
    "            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()\n",
    "            holes.append({\n",
    "                'center': [\n",
    "                    float(base_size*0.3 + i*base_size*0.4),\n",
    "                    float(base_size*0.25),\n",
    "                    float(thickness/2)\n",
    "                ],\n",
    "                'diameter': float(10.0 * size_variation),\n",
    "                'type': 'through_hole'\n",
    "            })\n",
    "        \n",
    "        cog = compute_center_of_mass(part)\n",
    "        annotations = {\n",
    "            \"center_of_mass\": cog,\n",
    "            \"reference_planes\": [\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(base_size*0.25), float(thickness/2)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(base_size*base_size*0.5),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [float(base_size - thickness/2), float(base_size*0.25), float(base_size*0.2 + thickness)],\n",
    "                    \"normal\": [1.0, 0.0, 0.0],\n",
    "                    \"area\": float(base_size*0.5*base_size*0.4),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(base_size*0.25), 0.0],\n",
    "                    \"normal\": [0.0, 0.0, -1.0],\n",
    "                    \"area\": float(base_size*base_size*0.5),\n",
    "                    \"role\": 3\n",
    "                }\n",
    "            ],\n",
    "            \"fastening_elements\": holes,\n",
    "            \"functional_surfaces\": [\n",
    "                {\n",
    "                    \"center\": [float(base_size - thickness/2), float(base_size*0.25), float(base_size*0.2 + thickness + base_size*0.2)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(thickness*base_size*0.5),\n",
    "                    \"role\": 1\n",
    "                }\n",
    "            ],\n",
    "            \"part_type\": \"bracket\"\n",
    "        }\n",
    "        return part, annotations\n",
    "    \n",
    "    elif part_type == \"flange\":\n",
    "        radius = base_size * 0.5\n",
    "        flange = BRepPrimAPI_MakeCylinder(radius, thickness).Shape()\n",
    "        center_hole = BRepPrimAPI_MakeCylinder(radius*0.2, thickness*1.5).Shape()\n",
    "        part = BRepAlgoAPI_Cut(flange, center_hole).Shape()\n",
    "        \n",
    "        holes = []\n",
    "        for i in range(4):\n",
    "            angle = np.radians(i * 90)\n",
    "            x = radius * 0.6 * np.cos(angle)\n",
    "            y = radius * 0.6 * np.sin(angle)\n",
    "            hole = BRepPrimAPI_MakeCylinder(6.0 * size_variation, thickness*1.5).Shape()\n",
    "            trsf = gp_Trsf()\n",
    "            trsf.SetTranslation(gp_Vec(x, y, -thickness*0.25))\n",
    "            transform = BRepBuilderAPI_Transform(hole, trsf)\n",
    "            hole_pos = transform.Shape()\n",
    "            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()\n",
    "            holes.append({\n",
    "                'center': [float(x), float(y), float(thickness/2)],\n",
    "                'diameter': float(12.0 * size_variation),\n",
    "                'type': 'mounting_hole'\n",
    "            })\n",
    "        \n",
    "        cog = compute_center_of_mass(part)\n",
    "        annotations = {\n",
    "            \"center_of_mass\": cog,\n",
    "            \"reference_planes\": [\n",
    "                {\n",
    "                    \"center\": [0.0, 0.0, float(thickness/2)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(np.pi * radius**2),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [0.0, 0.0, 0.0],\n",
    "                    \"normal\": [0.0, 0.0, -1.0],\n",
    "                    \"area\": float(np.pi * radius**2),\n",
    "                    \"role\": 3\n",
    "                }\n",
    "            ],\n",
    "            \"fastening_elements\": holes,\n",
    "            \"functional_surfaces\": [\n",
    "                {\n",
    "                    \"center\": [0.0, 0.0, float(thickness/2)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(np.pi * (radius**2 - (radius*0.2)**2)),\n",
    "                    \"role\": 1\n",
    "                }\n",
    "            ],\n",
    "            \"part_type\": \"flange\"\n",
    "        }\n",
    "        return part, annotations\n",
    "    \n",
    "    elif part_type == \"block_with_holes\":\n",
    "        block = BRepPrimAPI_MakeBox(base_size, base_size, base_size*0.5).Shape()\n",
    "        \n",
    "        holes = []\n",
    "        for i in range(2):\n",
    "            for j in range(3):\n",
    "                x = base_size * 0.25 + j * base_size * 0.25\n",
    "                y = base_size * 0.3 + i * base_size * 0.4\n",
    "                hole = BRepPrimAPI_MakeCylinder(4.0 * size_variation, base_size*0.6).Shape()\n",
    "                trsf = gp_Trsf()\n",
    "                trsf.SetTranslation(gp_Vec(x, y, -base_size*0.05))\n",
    "                transform = BRepBuilderAPI_Transform(hole, trsf)\n",
    "                hole_pos = transform.Shape()\n",
    "                block = BRepAlgoAPI_Cut(block, hole_pos).Shape()\n",
    "                holes.append({\n",
    "                    'center': [float(x), float(y), float(base_size*0.25)],\n",
    "                    'diameter': float(8.0 * size_variation),\n",
    "                    'type': 'grid_hole'\n",
    "                })\n",
    "        \n",
    "        cog = compute_center_of_mass(block)\n",
    "        annotations = {\n",
    "            \"center_of_mass\": cog,\n",
    "            \"reference_planes\": [\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(base_size/2), float(base_size*0.25)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(base_size**2),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(base_size/2), 0.0],\n",
    "                    \"normal\": [0.0, 0.0, -1.0],\n",
    "                    \"area\": float(base_size**2),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [0.0, float(base_size/2), float(base_size*0.25)],\n",
    "                    \"normal\": [-1.0, 0.0, 0.0],\n",
    "                    \"area\": float(base_size*base_size*0.5),\n",
    "                    \"role\": 3\n",
    "                }\n",
    "            ],\n",
    "            \"fastening_elements\": holes,\n",
    "            \"functional_surfaces\": [],\n",
    "            \"part_type\": \"block_with_holes\"\n",
    "        }\n",
    "        return block, annotations\n",
    "    \n",
    "    elif part_type == \"t_bracket\":\n",
    "        base = BRepPrimAPI_MakeBox(base_size, thickness, thickness).Shape()\n",
    "        vertical = BRepPrimAPI_MakeBox(thickness, base_size*0.6, base_size*0.3).Shape()\n",
    "        \n",
    "        trsf = gp_Trsf()\n",
    "        trsf.SetTranslation(gp_Vec((base_size-thickness)/2, 0, thickness))\n",
    "        transform = BRepBuilderAPI_Transform(vertical, trsf)\n",
    "        vertical_pos = transform.Shape()\n",
    "        \n",
    "        part = BRepAlgoAPI_Fuse(base, vertical_pos).Shape()\n",
    "        \n",
    "        holes = []\n",
    "        for i in range(2):\n",
    "            hole = BRepPrimAPI_MakeCylinder(5.0 * size_variation, thickness*1.5).Shape()\n",
    "            trsf = gp_Trsf()\n",
    "            trsf.SetTranslation(gp_Vec(base_size*0.25 + i*base_size*0.5, thickness/2, -thickness*0.25))\n",
    "            transform = BRepBuilderAPI_Transform(hole, trsf)\n",
    "            hole_pos = transform.Shape()\n",
    "            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()\n",
    "            holes.append({\n",
    "                'center': [\n",
    "                    float(base_size*0.25 + i*base_size*0.5),\n",
    "                    float(thickness/2),\n",
    "                    float(thickness/2)\n",
    "                ],\n",
    "                'diameter': float(10.0 * size_variation),\n",
    "                'type': 'mounting_hole'\n",
    "            })\n",
    "        \n",
    "        cog = compute_center_of_mass(part)\n",
    "        annotations = {\n",
    "            \"center_of_mass\": cog,\n",
    "            \"reference_planes\": [\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(thickness/2), float(thickness/2)],\n",
    "                    \"normal\": [0.0, 0.0, 1.0],\n",
    "                    \"area\": float(base_size*thickness),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [float(base_size/2), float(thickness/2), 0.0],\n",
    "                    \"normal\": [0.0, 0.0, -1.0],\n",
    "                    \"area\": float(base_size*thickness),\n",
    "                    \"role\": 3\n",
    "                },\n",
    "                {\n",
    "                    \"center\": [float((base_size-thickness)/2 + thickness/2), float(base_size*0.3), float(base_size*0.15 + thickness)],\n",
    "                    \"normal\": [1.0, 0.0, 0.0],\n",
    "                    \"area\": float(thickness*base_size*0.6),\n",
    "                    \"role\": 3\n",
    "                }\n",
    "            ],\n",
    "            \"fastening_elements\": holes,\n",
    "            \"functional_surfaces\": [],\n",
    "            \"part_type\": \"t_bracket\"\n",
    "        }\n",
    "        return part, annotations\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–µ—Ç–∞–ª–∏: {part_type}\")\n",
    "\n",
    "\n",
    "def generate_enhanced_dataset(output_dir=\"enhanced_dataset\", n_samples=500):\n",
    "    \"\"\"\n",
    "    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏\n",
    "    \n",
    "    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–∞:\n",
    "        enhanced_dataset/\n",
    "        ‚îú‚îÄ‚îÄ raw/              # STEP-—Ñ–∞–π–ª—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "        ‚îú‚îÄ‚îÄ annotations/      # JSON —Å –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã)\n",
    "        ‚îî‚îÄ‚îÄ pairs/            # –ü–∞—Ä—ã –º–æ–¥–µ–ª–µ–π —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.join(output_dir, \"raw\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"annotations\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, \"pairs\"), exist_ok=True)\n",
    "    \n",
    "    part_types = [\"bracket\", \"flange\", \"block_with_holes\", \"t_bracket\"]\n",
    "    pair_id = 0\n",
    "    \n",
    "    print(f\"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {n_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π...\")\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        part_type = np.random.choice(part_types)\n",
    "        size_var = np.random.uniform(0.8, 1.2)\n",
    "        \n",
    "        shape_orig, ann_orig = create_synthetic_part(\n",
    "            part_type=part_type, \n",
    "            seed=i,\n",
    "            size_variation=size_var\n",
    "        )\n",
    "        \n",
    "        orig_filename = f\"{part_type}_{i:06d}.step\"\n",
    "        orig_path = os.path.join(output_dir, \"raw\", orig_filename)\n",
    "        writer = STEPControl_Writer()\n",
    "        writer.Transfer(shape_orig, STEPControl_AsIs)\n",
    "        writer.Write(orig_path)\n",
    "        \n",
    "        ann_path = os.path.join(output_dir, \"annotations\", f\"{part_type}_{i:06d}.json\")\n",
    "        with open(ann_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(ann_orig, f, indent=2, ensure_ascii=False)  # ensure_ascii=False –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—Ü—ã\n",
    "        \n",
    "        n_pairs = np.random.randint(3, 6)\n",
    "        for j in range(n_pairs):\n",
    "            angles = np.radians(np.random.uniform(-60, 60, 3))\n",
    "            R = (\n",
    "                np.array([[1, 0, 0],\n",
    "                          [0, np.cos(angles[0]), -np.sin(angles[0])],\n",
    "                          [0, np.sin(angles[0]), np.cos(angles[0])]]) @\n",
    "                np.array([[np.cos(angles[1]), 0, np.sin(angles[1])],\n",
    "                          [0, 1, 0],\n",
    "                          [-np.sin(angles[1]), 0, np.cos(angles[1])]]) @\n",
    "                np.array([[np.cos(angles[2]), -np.sin(angles[2]), 0],\n",
    "                          [np.sin(angles[2]), np.cos(angles[2]), 0],\n",
    "                          [0, 0, 1]])\n",
    "            )\n",
    "            t = np.random.uniform(-30, 30, 3) * size_var\n",
    "            \n",
    "            trsf = gp_Trsf()\n",
    "            trsf.SetValues(\n",
    "                float(R[0,0]), float(R[0,1]), float(R[0,2]), float(t[0]),\n",
    "                float(R[1,0]), float(R[1,1]), float(R[1,2]), float(t[1]),\n",
    "                float(R[2,0]), float(R[2,1]), float(R[2,2]), float(t[2])\n",
    "            )\n",
    "            transform = BRepBuilderAPI_Transform(shape_orig, trsf)\n",
    "            shape_transformed = transform.Shape()\n",
    "            \n",
    "            trans_filename = f\"{part_type}_{i:06d}_trans_{j:02d}.step\"\n",
    "            trans_path = os.path.join(output_dir, \"raw\", trans_filename)\n",
    "            writer = STEPControl_Writer()\n",
    "            writer.Transfer(shape_transformed, STEPControl_AsIs)\n",
    "            writer.Write(trans_path)\n",
    "            \n",
    "            pair_metadata = {\n",
    "                \"pair_id\": pair_id,\n",
    "                \"source\": orig_filename,\n",
    "                \"target\": trans_filename,\n",
    "                \"part_type\": part_type,\n",
    "                \"size_variation\": float(size_var),  # –Ø–≤–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
    "                \"rotation_matrix\": R.tolist(),      # –í —Å–ø–∏—Å–æ–∫\n",
    "                \"translation_vector\": t.tolist(),    # –í —Å–ø–∏—Å–æ–∫\n",
    "                \"center_of_mass_original\": ann_orig[\"center_of_mass\"],\n",
    "                \"has_reference_planes\": len(ann_orig.get(\"reference_planes\", [])) >= 3,\n",
    "                \"has_holes\": len(ann_orig.get(\"fastening_elements\", [])) >= 2\n",
    "            }\n",
    "            \n",
    "            pair_path = os.path.join(output_dir, \"pairs\", f\"pair_{pair_id:06d}.json\")\n",
    "            with open(pair_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump(pair_metadata, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            pair_id += 1\n",
    "    \n",
    "    dataset_metadata = {\n",
    "        \"total_samples\": n_samples,\n",
    "        \"total_pairs\": pair_id,\n",
    "        \"part_types\": part_types,\n",
    "        \"role_mapping\": {\n",
    "            0: \"decorative\",\n",
    "            1: \"functional\",\n",
    "            2: \"fastening\",\n",
    "            3: \"reference_plane\"\n",
    "        },\n",
    "        \"annotation_keys\": [\n",
    "            \"center_of_mass\",\n",
    "            \"reference_planes\",\n",
    "            \"fastening_elements\",\n",
    "            \"functional_surfaces\"\n",
    "        ],\n",
    "        \"generation_date\": \"2026-02-20\"\n",
    "    }\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"dataset_metadata.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dataset_metadata, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {n_samples} –º–æ–¥–µ–ª–µ–π –∏ {pair_id} –ø–∞—Ä\")\n",
    "    print(f\"üìÅ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_dir}\")\n",
    "    print(f\"üìä –°—Ç—Ä—É–∫—Ç—É—Ä–∞:\")\n",
    "    print(f\"   ‚Ä¢ {n_samples} –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –≤ {output_dir}/raw/\")\n",
    "    print(f\"   ‚Ä¢ {n_samples} —Ñ–∞–π–ª–æ–≤ —Ä–∞–∑–º–µ—Ç–∫–∏ –≤ {output_dir}/annotations/\")\n",
    "    print(f\"   ‚Ä¢ {pair_id} –ø–∞—Ä —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏ –≤ {output_dir}/pairs/\")\n",
    "    \n",
    "    return output_dir\n",
    "\n",
    "\n",
    "def find_elements_by_role(role_probs, node_types, coords, role_idx=3, top_k=3):\n",
    "    \"\"\"\n",
    "    –ù–∞—Ö–æ–¥–∏—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞–¥–∞–Ω–Ω–æ–π —Ä–æ–ª–∏ (0=–¥–µ–∫–æ—Ä, 1=—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è, 2=–æ—Ç–≤–µ—Ä—Å—Ç–∏—è, 3=–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏)\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    role_probs : np.ndarray\n",
    "        –í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ä–æ–ª–µ–π –¥–ª—è –≤—Å–µ—Ö —É–∑–ª–æ–≤ (N, num_roles)\n",
    "    node_types : np.ndarray\n",
    "        –¢–∏–ø—ã —É–∑–ª–æ–≤: 0=–≤–µ—Ä—à–∏–Ω–∞, 1=–≥—Ä–∞–Ω—å\n",
    "    coords : np.ndarray\n",
    "        –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã —É–∑–ª–æ–≤ (N, 3)\n",
    "    role_idx : int\n",
    "        –ò–Ω–¥–µ–∫—Å —Ä–æ–ª–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ (0-3)\n",
    "    top_k : int\n",
    "        –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    np.ndarray : –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (top_k, 3)\n",
    "    \"\"\"\n",
    "    face_mask = (node_types == 1)\n",
    "    if not np.any(face_mask):\n",
    "        return np.array([])\n",
    "    \n",
    "    scores = role_probs[face_mask, role_idx]\n",
    "    top_indices = np.argsort(-scores)[:top_k]\n",
    "    face_indices = np.where(face_mask)[0][top_indices]\n",
    "    return coords[face_indices]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dataset_path = generate_enhanced_dataset(\\n    output_dir=\"enhanced_dataset\", \\n    n_samples=500  # 500 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π\\n)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "'''dataset_path = generate_enhanced_dataset(\n",
    "    output_dir=\"enhanced_dataset\", \n",
    "    n_samples=500  # 500 —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –¥–µ—Ç–∞–ª–µ–π\n",
    ")'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  –ö–ª–∞—Å—Å –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from OCC.Core.STEPControl import STEPControl_Reader\n",
    "\n",
    "class FixedSyntheticDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö (–º–º)\n",
    "    \"\"\"\n",
    "    def __init__(self, root=\"synthetic_dataset\", transform=None, pre_transform=None):\n",
    "        self.role_mapping = {\n",
    "            \"decorative\": 0,\n",
    "            \"functional\": 1,\n",
    "            \"fastening\": 2,\n",
    "            \"reference_plane\": 3\n",
    "        }\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "    \n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return os.path.join(self.root, \"raw\")\n",
    "    \n",
    "    @property\n",
    "    def ann_dir(self):\n",
    "        return os.path.join(self.root, \"annotations\")\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        files = [f for f in os.listdir(self.raw_dir) if f.endswith(\".step\") and \"_trans_\" not in f]\n",
    "        return sorted(files)\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f\"data_{idx:06d}.pt\" for idx in range(len(self.raw_file_names))]\n",
    "    \n",
    "    def process(self):\n",
    "        print(f\"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π...\")\n",
    "        \n",
    "        for idx, step_file in enumerate(self.raw_file_names):\n",
    "            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "            reader = STEPControl_Reader()\n",
    "            reader.ReadFile(os.path.join(self.raw_dir, step_file))\n",
    "            reader.TransferRoots()\n",
    "            shape = reader.OneShape()\n",
    "            \n",
    "            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ ‚Üí –ø–æ–ª—É—á–∞–µ–º –ò–°–•–û–î–ù–´–ï –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –º–º\n",
    "            vertices, face_vertex_indices = extract_topology(shape)\n",
    "            # vertices —Å–µ–π—á–∞—Å –≤ –º–∏–ª–ª–∏–º–µ—Ç—Ä–∞—Ö, –Ω–∞–ø—Ä–∏–º–µ—Ä: [[0.0, 0.0, 0.0], [100.0, 0.0, 0.0], ...]\n",
    "            \n",
    "            # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "            ann_file = os.path.splitext(step_file)[0] + \".json\"\n",
    "            ann_path = os.path.join(self.ann_dir, ann_file)\n",
    "            annotations = {}\n",
    "            if os.path.exists(ann_path):\n",
    "                with open(ann_path, \"r\") as f:\n",
    "                    annotations = json.load(f)\n",
    "            \n",
    "            # 4. –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –í –ò–°–•–û–î–ù–´–• –ö–û–û–†–î–ò–ù–ê–¢–ê–• (–º–º) ‚Äî –ö–õ–Æ–ß–ï–í–û–ô –ú–û–ú–ï–ù–¢!\n",
    "            n_vertices = len(vertices)\n",
    "            n_faces = len(face_vertex_indices)\n",
    "            node_roles = np.zeros(n_vertices + n_faces, dtype=np.int64)\n",
    "            node_roles[:n_vertices] = self.role_mapping[\"decorative\"]  # –≤–µ—Ä—à–∏–Ω—ã ‚Üí –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ\n",
    "            \n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π –≤ –ò–°–•–û–î–ù–´–• –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö (–º–º)\n",
    "            face_centers_mm = []\n",
    "            for vtx_ids in face_vertex_indices:\n",
    "                if vtx_ids:\n",
    "                    center = vertices[vtx_ids].mean(axis=0)  # vertices ‚Äî –≤ –º–º!\n",
    "                    face_centers_mm.append(center)\n",
    "            face_centers_mm = np.array(face_centers_mm)\n",
    "            \n",
    "            # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n",
    "            if idx == 0:\n",
    "                print(f\"\\nüîç –û—Ç–ª–∞–¥–∫–∞ –¥–ª—è {step_file}:\")\n",
    "                print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {n_faces}\")\n",
    "                print(f\"   –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π (–ø–µ—Ä–≤—ã–µ 3): {face_centers_mm[:3]}\")\n",
    "                print(f\"   –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–∑ JSON: {annotations.get('reference_planes', [])}\")\n",
    "            \n",
    "            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –≥—Ä–∞–Ω—è–º–∏ –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –≤ –º–º\n",
    "            assigned = np.zeros(n_faces, dtype=bool)\n",
    "            \n",
    "            # –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3) ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\n",
    "            ref_planes_found = 0\n",
    "            for ref_plane in annotations.get(\"reference_planes\", []):\n",
    "                ref_center = np.array(ref_plane[\"center\"])  # —Ç–æ–∂–µ –≤ –º–º!\n",
    "                if len(face_centers_mm) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_mm - ref_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    \n",
    "                    # –û—Ç–ª–∞–¥–∫–∞\n",
    "                    if idx == 0:\n",
    "                        print(f\"   –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è —Ü–µ–Ω—Ç—Ä: {ref_center}, –±–ª–∏–∂–∞–π—à–∞—è –≥—Ä–∞–Ω—å: {closest_idx}, —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {distances[closest_idx]:.2f} –º–º\")\n",
    "                    \n",
    "                    if distances[closest_idx] < 50.0:  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –¥–æ 50 –º–º –¥–ª—è –Ω–∞–¥—ë–∂–Ω–æ—Å—Ç–∏\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"reference_plane\"]\n",
    "                        assigned[closest_idx] = True\n",
    "                        ref_planes_found += 1\n",
    "            \n",
    "            if idx == 0:\n",
    "                print(f\"   –ù–∞–π–¥–µ–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π: {ref_planes_found}\")\n",
    "            \n",
    "            # –ö—Ä–µ–ø—ë–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ä–æ–ª—å 2)\n",
    "            for fastening in annotations.get(\"fastening_elements\", []):\n",
    "                fast_center = np.array(fastening[\"center\"])\n",
    "                if len(face_centers_mm) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_mm - fast_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 20.0 and not assigned[closest_idx]:  # –ø–æ—Ä–æ–≥ 20 –º–º\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"fastening\"]\n",
    "                        assigned[closest_idx] = True\n",
    "            \n",
    "            # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–æ–ª—å 1)\n",
    "            for func_surf in annotations.get(\"functional_surfaces\", []):\n",
    "                func_center = np.array(func_surf[\"center\"])\n",
    "                if len(face_centers_mm) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_mm - func_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 20.0 and not assigned[closest_idx]:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"functional\"]\n",
    "                        assigned[closest_idx] = True\n",
    "            \n",
    "            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏ ‚Üí —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (—Ä–æ–ª—å 1)\n",
    "            for i in range(n_faces):\n",
    "                if not assigned[i]:\n",
    "                    node_roles[n_vertices + i] = self.role_mapping[\"functional\"]\n",
    "            \n",
    "            # 5. –¢–µ–ø–µ—Ä—å —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –° –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ï–ô (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ)\n",
    "            data = build_graph(vertices, face_vertex_indices)\n",
    "            data.y = torch.tensor(node_roles, dtype=torch.long)\n",
    "            \n",
    "            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "            torch.save(data, os.path.join(self.processed_dir, f\"data_{idx:06d}.pt\"))\n",
    "        \n",
    "        print(f\"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π\")\n",
    "        print(f\"   –ì—Ä–∞—Ñ—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.processed_dir}\")\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return torch.load(\n",
    "            os.path.join(self.processed_dir, self.processed_file_names[idx]),\n",
    "            weights_only=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels=3, hidden_dim=64, num_roles=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_dim, heads=4, concat=True, dropout=0.2)\n",
    "        self.conv2 = GATv2Conv(hidden_dim * 4, hidden_dim, heads=2, concat=False, dropout=0.2)\n",
    "        self.role_classifier = torch.nn.Linear(hidden_dim, num_roles)\n",
    "        self.graph_proj = torch.nn.Linear(hidden_dim, 64)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        roles = self.role_classifier(x)\n",
    "        graph_emb = global_mean_pool(x, batch)\n",
    "        graph_emb = self.graph_proj(graph_emb)\n",
    "        return roles, graph_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –æ–±—É—á–µ–Ω–∏–µ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ –ü–µ—Ä–µ–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º...\n",
      "\n",
      "‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –ü–û–°–õ–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –≥—Ä–∞–Ω–∏):\n",
      "      –†–æ–ª—å 0 (–¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–∞—è        ):   0 —à—Ç.\n",
      "      –†–æ–ª—å 1 (—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è      ):   4 —à—Ç.\n",
      "      –†–æ–ª—å 2 (–∫—Ä–µ–ø—ë–∂–Ω–∞—è           ):   5 —à—Ç.\n",
      "      –†–æ–ª—å 3 (–æ–ø–æ—Ä–Ω–∞—è –ø–ª–æ—Å–∫–æ—Å—Ç—å   ):   3 —à—Ç.\n",
      "\n",
      "üåü –£–°–ü–ï–•: –ù–∞–π–¥–µ–Ω–æ 3 –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3) ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è!\n",
      "üöÄ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ...\n",
      "\n",
      "üöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π —Ä–æ–ª–∏ 3...\n",
      "\n",
      "–≠–ø–æ—Ö–∞   1/100 | Loss: 0.8651 ‚Üí 0.7193 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   2/100 | Loss: 0.6733 ‚Üí 0.6721 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   3/100 | Loss: 0.6552 ‚Üí 0.6635 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   4/100 | Loss: 0.6488 ‚Üí 0.6568 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   5/100 | Loss: 0.6425 ‚Üí 0.6490 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   6/100 | Loss: 0.6336 ‚Üí 0.6388 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   7/100 | Loss: 0.6228 ‚Üí 0.6233 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   8/100 | Loss: 0.6004 ‚Üí 0.5997 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞   9/100 | Loss: 0.5724 ‚Üí 0.5655 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  10/100 | Loss: 0.5386 ‚Üí 0.5295 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  11/100 | Loss: 0.5015 ‚Üí 0.4903 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  12/100 | Loss: 0.4737 ‚Üí 0.4618 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  13/100 | Loss: 0.4362 ‚Üí 0.4082 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  14/100 | Loss: 0.3962 ‚Üí 0.3599 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  15/100 | Loss: 0.3524 ‚Üí 0.3165 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  16/100 | Loss: 0.3190 ‚Üí 0.2821 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  17/100 | Loss: 0.2932 ‚Üí 0.2602 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  18/100 | Loss: 0.2742 ‚Üí 0.2423 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  19/100 | Loss: 0.2558 ‚Üí 0.2386 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  20/100 | Loss: 0.2442 ‚Üí 0.2323 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  21/100 | Loss: 0.2346 ‚Üí 0.1981 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  22/100 | Loss: 0.2225 ‚Üí 0.1869 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  23/100 | Loss: 0.2052 ‚Üí 0.1720 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  24/100 | Loss: 0.1981 ‚Üí 0.1604 | RefAcc: 99.5% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  25/100 | Loss: 0.1951 ‚Üí 0.1578 | RefAcc: 99.7% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  26/100 | Loss: 0.1841 ‚Üí 0.1486 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  27/100 | Loss: 0.1741 ‚Üí 0.1416 | RefAcc: 99.7% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  28/100 | Loss: 0.1720 ‚Üí 0.1301 | RefAcc: 99.7% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  29/100 | Loss: 0.1606 ‚Üí 0.1283 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  30/100 | Loss: 0.1560 ‚Üí 0.1246 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  31/100 | Loss: 0.1534 ‚Üí 0.1161 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  32/100 | Loss: 0.1453 ‚Üí 0.1071 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  33/100 | Loss: 0.1424 ‚Üí 0.1120 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  34/100 | Loss: 0.1388 ‚Üí 0.1019 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  35/100 | Loss: 0.1383 ‚Üí 0.1111 | RefAcc: 99.8% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  36/100 | Loss: 0.1382 ‚Üí 0.1060 | RefAcc: 99.8% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  37/100 | Loss: 0.1319 ‚Üí 0.0973 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  38/100 | Loss: 0.1265 ‚Üí 0.0950 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  39/100 | Loss: 0.1277 ‚Üí 0.0927 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  40/100 | Loss: 0.1271 ‚Üí 0.0945 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  41/100 | Loss: 0.1246 ‚Üí 0.0923 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  42/100 | Loss: 0.1192 ‚Üí 0.0895 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  43/100 | Loss: 0.1219 ‚Üí 0.1008 | RefAcc: 99.8% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  44/100 | Loss: 0.1254 ‚Üí 0.0881 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  45/100 | Loss: 0.1189 ‚Üí 0.0878 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  46/100 | Loss: 0.1167 ‚Üí 0.0901 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  47/100 | Loss: 0.1160 ‚Üí 0.0885 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  48/100 | Loss: 0.1137 ‚Üí 0.0861 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  49/100 | Loss: 0.1108 ‚Üí 0.0829 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  50/100 | Loss: 0.1070 ‚Üí 0.0835 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  51/100 | Loss: 0.1104 ‚Üí 0.0873 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  52/100 | Loss: 0.1146 ‚Üí 0.0852 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  53/100 | Loss: 0.1116 ‚Üí 0.0842 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  54/100 | Loss: 0.1106 ‚Üí 0.0847 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  55/100 | Loss: 0.1058 ‚Üí 0.0816 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  56/100 | Loss: 0.1037 ‚Üí 0.0805 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  57/100 | Loss: 0.1049 ‚Üí 0.0790 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  58/100 | Loss: 0.1039 ‚Üí 0.0796 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  59/100 | Loss: 0.1084 ‚Üí 0.0797 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  60/100 | Loss: 0.1021 ‚Üí 0.0816 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  61/100 | Loss: 0.1037 ‚Üí 0.0782 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  62/100 | Loss: 0.1042 ‚Üí 0.0786 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  63/100 | Loss: 0.1011 ‚Üí 0.0779 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  64/100 | Loss: 0.0996 ‚Üí 0.0792 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  65/100 | Loss: 0.1024 ‚Üí 0.0788 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  66/100 | Loss: 0.1055 ‚Üí 0.0793 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  67/100 | Loss: 0.1016 ‚Üí 0.0840 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  68/100 | Loss: 0.1014 ‚Üí 0.0795 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  69/100 | Loss: 0.1016 ‚Üí 0.0839 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  70/100 | Loss: 0.1018 ‚Üí 0.0767 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  71/100 | Loss: 0.1016 ‚Üí 0.0806 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  72/100 | Loss: 0.0979 ‚Üí 0.0760 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  73/100 | Loss: 0.0975 ‚Üí 0.0775 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  74/100 | Loss: 0.0974 ‚Üí 0.0766 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  75/100 | Loss: 0.0971 ‚Üí 0.0757 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  76/100 | Loss: 0.0957 ‚Üí 0.0772 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  77/100 | Loss: 0.0962 ‚Üí 0.0769 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  78/100 | Loss: 0.0958 ‚Üí 0.0792 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  79/100 | Loss: 0.0944 ‚Üí 0.0755 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  80/100 | Loss: 0.0974 ‚Üí 0.0749 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  81/100 | Loss: 0.0968 ‚Üí 0.0760 | RefAcc: 99.7% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  82/100 | Loss: 0.0973 ‚Üí 0.0736 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  83/100 | Loss: 0.0956 ‚Üí 0.0814 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  84/100 | Loss: 0.0941 ‚Üí 0.0741 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  85/100 | Loss: 0.0980 ‚Üí 0.0760 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  86/100 | Loss: 0.0944 ‚Üí 0.0766 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  87/100 | Loss: 0.0945 ‚Üí 0.0768 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  88/100 | Loss: 0.0926 ‚Üí 0.0733 | RefAcc: 100.0% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  89/100 | Loss: 0.0945 ‚Üí 0.0756 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  90/100 | Loss: 0.0918 ‚Üí 0.0756 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  91/100 | Loss: 0.0933 ‚Üí 0.0764 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  92/100 | Loss: 0.0928 ‚Üí 0.0765 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  93/100 | Loss: 0.0947 ‚Üí 0.0728 | RefAcc: 99.8% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞  94/100 | Loss: 0.0909 ‚Üí 0.0753 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  95/100 | Loss: 0.0960 ‚Üí 0.0820 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  96/100 | Loss: 0.0914 ‚Üí 0.0748 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  97/100 | Loss: 0.0921 ‚Üí 0.0731 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  98/100 | Loss: 0.0933 ‚Üí 0.0749 | RefAcc: 99.9% ‚Üí 100.0% \n",
      "–≠–ø–æ—Ö–∞  99/100 | Loss: 0.0940 ‚Üí 0.0709 | RefAcc: 99.9% ‚Üí 100.0% ‚≠ê\n",
      "–≠–ø–æ—Ö–∞ 100/100 | Loss: 0.0906 ‚Üí 0.0737 | RefAcc: 100.0% ‚Üí 100.0% \n",
      "\n",
      "‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: gnn_best.pth\n"
     ]
    }
   ],
   "source": [
    "# –ü–µ—Ä–µ—Å–æ–∑–¥–∞—ë–º –¥–∞—Ç–∞—Å–µ—Ç —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º –∫–ª–∞—Å—Å–æ–º\n",
    "print(\"üì¶ –ü–µ—Ä–µ–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º...\")\n",
    "dataset = FixedSyntheticDataset(root=\"enhanced_dataset\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–≤—É—é –º–æ–¥–µ–ª—å\n",
    "test_data = dataset[0]\n",
    "face_mask = (test_data.node_type == 1)\n",
    "true_roles = test_data.y[face_mask]\n",
    "\n",
    "print(\"\\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –ü–û–°–õ–ï –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\")\n",
    "print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {face_mask.sum().item()}\")\n",
    "print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –≥—Ä–∞–Ω–∏):\")\n",
    "for role in range(4):\n",
    "    count = (true_roles == role).sum().item()\n",
    "    role_name = [\"–¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–∞—è\", \"—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è\", \"–∫—Ä–µ–ø—ë–∂–Ω–∞—è\", \"–æ–ø–æ—Ä–Ω–∞—è –ø–ª–æ—Å–∫–æ—Å—Ç—å\"][role]\n",
    "    print(f\"      –†–æ–ª—å {role} ({role_name:20s}): {count:3d} —à—Ç.\")\n",
    "\n",
    "# –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å—Ç—å –ª–∏ –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏?\n",
    "role3_count = (true_roles == 3).sum().item()\n",
    "if role3_count >= 3:\n",
    "    print(f\"\\nüåü –£–°–ü–ï–•: –ù–∞–π–¥–µ–Ω–æ {role3_count} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3) ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è!\")\n",
    "    print(\"üöÄ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ...\")\n",
    "    \n",
    "    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏\n",
    "    from torch.utils.data import random_split\n",
    "    from torch_geometric.loader import DataLoader\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "    \n",
    "    # –ú–æ–¥–µ–ª—å –∏ –æ–±—É—á–µ–Ω–∏–µ\n",
    "    device = torch.device('cpu')\n",
    "    model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4).to(device)\n",
    "    \n",
    "    # –£—Å–∏–ª–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Ä–æ–ª–∏ 3 (–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏)\n",
    "    class_weights = torch.tensor([0.2, 0.3, 1.0, 10.0], dtype=torch.float, device=device)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "    \n",
    "    print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π —Ä–æ–ª–∏ 3...\\n\")\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    for epoch in range(100):\n",
    "        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_role3_correct = 0\n",
    "        train_role3_total = 0\n",
    "        \n",
    "        for data in train_loader:\n",
    "            data = data.to(device)\n",
    "            batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "            roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "            \n",
    "            face_mask = (data.node_type == 1)\n",
    "            if face_mask.sum() > 0:\n",
    "                loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "                \n",
    "                # –°—á—ë—Ç—á–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–æ–ª–∏ 3\n",
    "                preds = roles_pred[face_mask].argmax(dim=1)\n",
    "                role3_mask = (data.y[face_mask] == 3)\n",
    "                if role3_mask.sum() > 0:\n",
    "                    train_role3_correct += (preds[role3_mask] == 3).sum().item()\n",
    "                    train_role3_total += role3_mask.sum().item()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item() * data.num_graphs\n",
    "        \n",
    "        avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "        role3_acc = train_role3_correct / train_role3_total if train_role3_total > 0 else 0\n",
    "        \n",
    "        # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_role3_correct = 0\n",
    "        val_role3_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "                roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "                \n",
    "                face_mask = (data.node_type == 1)\n",
    "                if face_mask.sum() > 0:\n",
    "                    loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "                    val_loss += loss.item() * data.num_graphs\n",
    "                    \n",
    "                    preds = roles_pred[face_mask].argmax(dim=1)\n",
    "                    role3_mask = (data.y[face_mask] == 3)\n",
    "                    if role3_mask.sum() > 0:\n",
    "                        val_role3_correct += (preds[role3_mask] == 3).sum().item()\n",
    "                        val_role3_total += role3_mask.sum().item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_role3_acc = val_role3_correct / val_role3_total if val_role3_total > 0 else 0\n",
    "        \n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), \"gnn_best.pth\")\n",
    "            status = \"‚≠ê\"\n",
    "        else:\n",
    "            status = \"\"\n",
    "        \n",
    "        print(f\"–≠–ø–æ—Ö–∞ {epoch+1:3d}/100 | Loss: {avg_train_loss:.4f} ‚Üí {avg_val_loss:.4f} | \"\n",
    "              f\"RefAcc: {role3_acc:.1%} ‚Üí {val_role3_acc:.1%} {status}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: gnn_best.pth\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–∞–π–¥–µ–Ω–æ —Ç–æ–ª—å–∫–æ {role3_count} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (–Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3)\")\n",
    "    print(\"   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\")\n",
    "    print(\"   1. –ü–æ—Ä–æ–≥ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è 50 –º–º –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –º–∞–ª\")\n",
    "    print(\"   2. –ü—Ä–æ–±–ª–µ–º–∞ —Å –ø–æ—Ä—è–¥–∫–æ–º –≥—Ä–∞–Ω–µ–π –≤ face_vertex_indices\")\n",
    "    print(\"   3. –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ JSON –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–µ–∞–ª—å–Ω–æ–π –≥–µ–æ–º–µ—Ç—Ä–∏–∏\")\n",
    "    \n",
    "    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞\n",
    "    print(\"\\nüîç –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞:\")\n",
    "    print(f\"   –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π –∏–∑ –≥—Ä–∞—Ñ–∞ (–ø–µ—Ä–≤—ã–µ 5):\")\n",
    "    for i in range(min(5, len(face_centers_mm))):\n",
    "        print(f\"      –ì—Ä–∞–Ω—å {i}: {face_centers_mm[i]}\")\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "    step_file = dataset.raw_file_names[0]\n",
    "    ann_file = os.path.splitext(step_file)[0] + \".json\"\n",
    "    ann_path = os.path.join(dataset.ann_dir, ann_file)\n",
    "    \n",
    "    if os.path.exists(ann_path):\n",
    "        with open(ann_path, \"r\") as f:\n",
    "            annotations = json.load(f)\n",
    "        print(f\"\\n   –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –∏–∑ {ann_file}:\")\n",
    "        print(f\"      –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏: {len(annotations.get('reference_planes', []))} —à—Ç.\")\n",
    "        for i, rp in enumerate(annotations.get('reference_planes', [])):\n",
    "            print(f\"         {i+1}. –¶–µ–Ω—Ç—Ä: {rp['center']}, –ù–æ—Ä–º–∞–ª—å: {rp['normal']}, –ü–ª–æ—â–∞–¥—å: {rp['area']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—É—á–µ–Ω–∏—è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 0:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 1:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 2:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 3:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 4:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 5:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 6:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 7:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 8:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n",
      "\n",
      "–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ 9:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 12\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 3\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 4\n",
      "   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "model.load_state_dict(torch.load(\"gnn_best.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "dataset = FixedSyntheticDataset(root=\"enhanced_dataset\")\n",
    "\n",
    "for i in range(10):\n",
    "    test_data = dataset[i]\n",
    "    with torch.no_grad():\n",
    "        batch = torch.zeros(test_data.x.size(0), dtype=torch.long)\n",
    "        roles_pred, _ = model(test_data.x, test_data.edge_index, batch)\n",
    "        pred_classes = roles_pred.argmax(dim=1)\n",
    "\n",
    "    face_mask = (test_data.node_type == 1)\n",
    "    true_roles = test_data.y[face_mask]\n",
    "    pred_roles = pred_classes[face_mask]\n",
    "\n",
    "    print(f\"\\n–ö–∞—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –º–æ–¥–µ–ª–∏ {i}:\")\n",
    "    print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {face_mask.sum().item()}\")\n",
    "    print(f\"   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): {(true_roles == 3).sum().item()}\")\n",
    "    print(f\"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): {(pred_roles == 3).sum().item()}\")\n",
    "    print(f\"   –¢–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —Ä–æ–ª–∏ 3: {((pred_roles == 3) & (true_roles == 3)).sum().item() / (true_roles == 3).sum().item():.1%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ù–∞—Ö–æ–∂–¥–µ–Ω–∏–µ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –∏ –∞–ª–≥–æ—Ä–∏—Ç–º –£–º—ç—è–º—ã —Å GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reference_planes(role_probs, node_types, coords, top_k=3):\n",
    "    \"\"\"–ù–∞—Ö–æ–¥–∏—Ç –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3) —Å—Ä–µ–¥–∏ –≥—Ä–∞–Ω–µ–π\"\"\"\n",
    "    face_mask = (node_types == 1)\n",
    "    if not np.any(face_mask):\n",
    "        return np.array([])\n",
    "    ref_scores = role_probs[face_mask, 3]\n",
    "    top_indices = np.argsort(-ref_scores)[:top_k]\n",
    "    face_indices = np.where(face_mask)[0][top_indices]\n",
    "    return coords[face_indices]\n",
    "\n",
    "def align_with_umeyama(src_pts, tgt_pts):\n",
    "    \"\"\"–ê–ª–≥–æ—Ä–∏—Ç–º –£–º—ç—è–º—ã –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\"\"\"\n",
    "    assert src_pts.shape == tgt_pts.shape and src_pts.shape[0] >= 3\n",
    "    src_mean = src_pts.mean(axis=0)\n",
    "    tgt_mean = tgt_pts.mean(axis=0)\n",
    "    src_c = src_pts - src_mean\n",
    "    tgt_c = tgt_pts - tgt_mean\n",
    "    H = src_c.T @ tgt_c\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R_opt = Vt.T @ U.T\n",
    "    if np.linalg.det(R_opt) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R_opt = Vt.T @ U.T\n",
    "    t_opt = tgt_mean - R_opt @ src_mean\n",
    "    return R_opt, t_opt\n",
    "\n",
    "def align_models_enhanced(shape1, shape2, model_path=\"gnn_best.pth\"):\n",
    "    \"\"\"\n",
    "    –°–æ–≤–º–µ—â–µ–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å, –æ—Ç–≤–µ—Ä—Å—Ç–∏–π –∏ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    shape1 : TopoDS_Shape\n",
    "        –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å (—Ü–µ–ª—å)\n",
    "    shape2 : TopoDS_Shape\n",
    "        –í—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å (–∫–æ—Ç–æ—Ä—É—é –Ω—É–∂–Ω–æ —Å–æ–≤–º–µ—Å—Ç–∏—Ç—å)\n",
    "    model_path : str\n",
    "        –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ GNN\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    shape2_aligned : TopoDS_Shape\n",
    "        –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –≤—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å\n",
    "    R_mat : np.ndarray\n",
    "        –ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞ (3, 3)\n",
    "    t_vec : np.ndarray\n",
    "        –í–µ–∫—Ç–æ—Ä —Å–¥–≤–∏–≥–∞ (3,)\n",
    "    \"\"\"\n",
    "    from OCC.Core.gp import gp_Trsf\n",
    "    from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "    \n",
    "    # 1. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "    cog1 = np.array(compute_center_of_mass(shape1))\n",
    "    cog2 = np.array(compute_center_of_mass(shape2))\n",
    "    \n",
    "    # 2. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–æ–ª–µ–π —á–µ—Ä–µ–∑ GNN\n",
    "    v1, fv1 = extract_topology(shape1)\n",
    "    v2, fv2 = extract_topology(shape2)\n",
    "    g1 = build_graph(v1, fv1)\n",
    "    g2 = build_graph(v2, fv2)\n",
    "    \n",
    "    model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)\n",
    "        batch2 = torch.zeros(g2.x.size(0), dtype=torch.long)\n",
    "        roles1, _ = model(g1.x, g1.edge_index, batch1)\n",
    "        roles2, _ = model(g2.x, g2.edge_index, batch2)\n",
    "    \n",
    "    # 3. –°–±–æ—Ä –≤—Å–µ—Ö —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)\n",
    "    points1 = [cog1]  # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å ‚Äî –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞!\n",
    "    points2 = [cog2]\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç–≤–µ—Ä—Å—Ç–∏—è (—Ä–æ–ª—å 2) ‚Äî –¥–æ 2 —Ç–æ—á–µ–∫\n",
    "    holes1 = find_elements_by_role(\n",
    "        roles1.softmax(dim=1).numpy(), \n",
    "        g1.node_type.numpy(), \n",
    "        g1.x[:, :3].numpy(), \n",
    "        role_idx=2, \n",
    "        top_k=2\n",
    "    )\n",
    "    holes2 = find_elements_by_role(\n",
    "        roles2.softmax(dim=1).numpy(), \n",
    "        g2.node_type.numpy(), \n",
    "        g2.x[:, :3].numpy(), \n",
    "        role_idx=2, \n",
    "        top_k=2\n",
    "    )\n",
    "    points1.extend(holes1[:min(2, len(holes1))])\n",
    "    points2.extend(holes2[:min(2, len(holes2))])\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3) ‚Äî –¥–æ 2 —Ç–æ—á–µ–∫\n",
    "    ref_planes1 = find_elements_by_role(\n",
    "        roles1.softmax(dim=1).numpy(), \n",
    "        g1.node_type.numpy(), \n",
    "        g1.x[:, :3].numpy(), \n",
    "        role_idx=3, \n",
    "        top_k=2\n",
    "    )\n",
    "    ref_planes2 = find_elements_by_role(\n",
    "        roles2.softmax(dim=1).numpy(), \n",
    "        g2.node_type.numpy(), \n",
    "        g2.x[:, :3].numpy(), \n",
    "        role_idx=3, \n",
    "        top_k=2\n",
    "    )\n",
    "    points1.extend(ref_planes1[:min(2, len(ref_planes1))])\n",
    "    points2.extend(ref_planes2[:min(2, len(ref_planes2))])\n",
    "    \n",
    "    # 4. –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ç–æ—á–∫–∞–º (–º–∏–Ω–∏–º—É–º 3)\n",
    "    if len(points1) >= 3 and len(points2) >= 3:\n",
    "        src_pts = np.array(points1[:3])  # –ë–µ—Ä—ë–º –ø–µ—Ä–≤—ã–µ 3 —Ç–æ—á–∫–∏\n",
    "        tgt_pts = np.array(points2[:3])\n",
    "        R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)\n",
    "        \n",
    "        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "        trsf = gp_Trsf()\n",
    "        trsf.SetValues(\n",
    "            float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),\n",
    "            float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),\n",
    "            float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])\n",
    "        )\n",
    "        transform = BRepBuilderAPI_Transform(shape2, trsf)\n",
    "        shape2_aligned = transform.Shape()\n",
    "        \n",
    "        print(f\"‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø–æ {len(points1)} —Ç–æ—á–∫–∞–º:\")\n",
    "        print(f\"   ‚Ä¢ –¶–µ–Ω—Ç—Ä –º–∞—Å—Å\")\n",
    "        print(f\"   ‚Ä¢ {len(holes1[:2])} –æ—Ç–≤–µ—Ä—Å—Ç–∏–π\")\n",
    "        print(f\"   ‚Ä¢ {len(ref_planes1[:2])} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\")\n",
    "        return shape2_aligned, R_mat, t_vec\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3, –¥–æ—Å—Ç—É–ø–Ω–æ: {len(points1)})\")\n",
    "        print(f\"   –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ—á–∫–∏: —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å + {len(holes1)} –æ—Ç–≤–µ—Ä—Å—Ç–∏–π + {len(ref_planes1)} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\")\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –±–µ–∑ GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_large_planes(shape, min_area=50.0, max_planes=5):\n",
    "    \"\"\"–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å pythonocc-core 7.9.0)\"\"\"\n",
    "    from OCC.Core.TopExp import TopExp_Explorer\n",
    "    from OCC.Core.TopAbs import TopAbs_FACE\n",
    "    from OCC.Core.BRepGProp import brepgprop_SurfaceProperties\n",
    "    from OCC.Core.GProp import GProp_GProps\n",
    "    from OCC.Core.Geom import Geom_Plane\n",
    "\n",
    "    planes = []\n",
    "    explorer = TopExp_Explorer(shape, TopAbs_FACE)\n",
    "    \n",
    "    while explorer.More():\n",
    "        face = explorer.Current()  # –†–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å TopoDS_Shape\n",
    "        surface = BRep_Tool.Surface(face)\n",
    "        \n",
    "        if not surface.IsKind(\"Geom_Plane\"):\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        props = GProp_GProps()\n",
    "        brepgprop_SurfaceProperties(face, props)  # –†–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0\n",
    "        area = props.Mass()\n",
    "        \n",
    "        if area < min_area:\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        cog = props.CentreOfMass()\n",
    "        \n",
    "        try:\n",
    "            plane = Geom_Plane.DownCast(surface)\n",
    "            normal = plane.Axis().Direction()\n",
    "        except:\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        planes.append({\n",
    "            'area': area,\n",
    "            'center': np.array([cog.X(), cog.Y(), cog.Z()]),\n",
    "            'normal': np.array([normal.X(), normal.Y(), normal.Z()])\n",
    "        })\n",
    "        explorer.Next()\n",
    "    \n",
    "    planes.sort(key=lambda x: x['area'], reverse=True)\n",
    "    return planes[:max_planes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–º–µ—â–µ–Ω–∏—è "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000):\n",
    "    \"\"\"–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –≤–µ—Ä—à–∏–Ω–∞–º–∏\"\"\"\n",
    "    from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape\n",
    "    \n",
    "    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –•–∞—É—Å–¥–æ—Ä—Ñ–∞\n",
    "    dist_checker = BRepExtrema_DistShapeShape()\n",
    "    dist_checker.LoadS1(shape1)\n",
    "    dist_checker.LoadS2(shape2_aligned)\n",
    "    dist_checker.Perform()\n",
    "    \n",
    "    if not dist_checker.IsDone():\n",
    "        return {'success': False, 'error': '–†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è'}\n",
    "    \n",
    "    min_dist = dist_checker.Value()\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω\n",
    "    vertices1, _ = extract_topology(shape1)\n",
    "    vertices2, _ = extract_topology(shape2_aligned)\n",
    "    \n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –≤–µ—Ä—à–∏–Ω –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "    if len(vertices1) > n_max_vertices:\n",
    "        indices = np.random.choice(len(vertices1), n_max_vertices, replace=False)\n",
    "        vertices1 = vertices1[indices]\n",
    "    if len(vertices2) > n_max_vertices:\n",
    "        indices = np.random.choice(len(vertices2), n_max_vertices, replace=False)\n",
    "        vertices2 = vertices2[indices]\n",
    "    \n",
    "    if len(vertices1) == 0 or len(vertices2) == 0:\n",
    "        return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–µ—Ä—à–∏–Ω—ã'}\n",
    "    \n",
    "    # –†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π\n",
    "    tree2 = cKDTree(vertices2)\n",
    "    dists12, _ = tree2.query(vertices1, k=1)\n",
    "    \n",
    "    tree1 = cKDTree(vertices1)\n",
    "    dists21, _ = tree1.query(vertices2, k=1)\n",
    "    \n",
    "    hausdorff_sym = max(dists12.max(), dists21.max())\n",
    "    mean_dist = (dists12.mean() + dists21.mean()) / 2.0\n",
    "    \n",
    "    return {\n",
    "        'success': True,\n",
    "        'hausdorff_min': min_dist,\n",
    "        'hausdorff_symmetric': hausdorff_sym,\n",
    "        'mean_distance': mean_dist,\n",
    "        'max_distance': max(dists12.max(), dists21.max()),\n",
    "        'rms_distance': np.sqrt((dists12**2).mean()),\n",
    "        'inlier_ratio_0.1mm': (dists12 < 0.1).mean(),\n",
    "        'inlier_ratio_1.0mm': (dists12 < 1.0).mean(),\n",
    "        'sample_count': len(vertices1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ë–£–õ–ï–í–´ –û–ü–ï–†–ê–¶–ò–ò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def boolean_operations(shape1, shape2_aligned, tolerance=1e-3):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é —Å TopoDS_Shape (–±–µ–∑ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤)\n",
    "    \"\"\"\n",
    "    from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Fuse, BRepAlgoAPI_Common, BRepAlgoAPI_Cut\n",
    "    \n",
    "    results = {}\n",
    "    errors = []\n",
    "    \n",
    "    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ\n",
    "    try:\n",
    "        fuse = BRepAlgoAPI_Fuse(shape1, shape2_aligned)\n",
    "        fuse.SetFuzzyValue(tolerance)\n",
    "        if fuse.IsDone():\n",
    "            results['fuse'] = fuse.Shape()\n",
    "        else:\n",
    "            errors.append(\"fuse\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"fuse: {str(e)}\")\n",
    "    \n",
    "    # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ\n",
    "    try:\n",
    "        common = BRepAlgoAPI_Common(shape1, shape2_aligned)\n",
    "        common.SetFuzzyValue(tolerance)\n",
    "        if common.IsDone():\n",
    "            results['common'] = common.Shape()\n",
    "        else:\n",
    "            errors.append(\"common\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"common: {str(e)}\")\n",
    "    \n",
    "    # –†–∞–∑–Ω–æ—Å—Ç—å (A \\ B)\n",
    "    try:\n",
    "        cut1 = BRepAlgoAPI_Cut(shape1, shape2_aligned)\n",
    "        cut1.SetFuzzyValue(tolerance)\n",
    "        if cut1.IsDone():\n",
    "            results['diff1'] = cut1.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff1\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff1: {str(e)}\")\n",
    "    \n",
    "    # –†–∞–∑–Ω–æ—Å—Ç—å (B \\ A)\n",
    "    try:\n",
    "        cut2 = BRepAlgoAPI_Cut(shape2_aligned, shape1)\n",
    "        cut2.SetFuzzyValue(tolerance)\n",
    "        if cut2.IsDone():\n",
    "            results['diff2'] = cut2.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff2\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff2: {str(e)}\")\n",
    "    \n",
    "    # –°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å\n",
    "    if 'diff1' in results and 'diff2' in results:\n",
    "        try:\n",
    "            symdiff = BRepAlgoAPI_Fuse(results['diff1'], results['diff2'])\n",
    "            symdiff.SetFuzzyValue(tolerance)\n",
    "            if symdiff.IsDone():\n",
    "                results['symdiff'] = symdiff.Shape()\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if errors:\n",
    "        results['errors'] = errors\n",
    "    \n",
    "    return results\n",
    "\n",
    "def compute_volumes(shape):\n",
    "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—ä—ë–º –∏ –ø–ª–æ—â–∞–¥—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º TopoDS_Shape)\"\"\"\n",
    "    from OCC.Core.GProp import GProp_GProps\n",
    "    from OCC.Core.BRepGProp import brepgprop_VolumeProperties, brepgprop_SurfaceProperties\n",
    "    \n",
    "    volume = 0.0\n",
    "    area = 0.0\n",
    "    \n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_VolumeProperties(shape, props)\n",
    "        volume = props.Mass()\n",
    "    except:\n",
    "        volume = 0.0\n",
    "    \n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_SurfaceProperties(shape, props)\n",
    "        area = props.Mass()\n",
    "    except:\n",
    "        area = 0.0\n",
    "    \n",
    "    return volume, area\n",
    "\n",
    "def analyze_differences(shape1, shape2_aligned, tolerance=1e-3):\n",
    "    \"\"\"–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏\"\"\"\n",
    "    results = boolean_operations(shape1, shape2_aligned, tolerance)\n",
    "    \n",
    "    vol1, area1 = compute_volumes(shape1)\n",
    "    vol2, area2 = compute_volumes(shape2_aligned)\n",
    "    \n",
    "    vol_diff1 = compute_volumes(results['diff1'])[0] if 'diff1' in results else 0.0\n",
    "    vol_diff2 = compute_volumes(results['diff2'])[0] if 'diff2' in results else 0.0\n",
    "    vol_common = compute_volumes(results['common'])[0] if 'common' in results else 0.0\n",
    "    \n",
    "    total_vol = max(vol1, vol2)\n",
    "    diff_percent = ((vol_diff1 + vol_diff2) / total_vol * 100) if total_vol > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'volume_model1': vol1,\n",
    "        'volume_model2': vol2,\n",
    "        'volume_unique_to_1': vol_diff1,\n",
    "        'volume_unique_to_2': vol_diff2,\n",
    "        'volume_common': vol_common,\n",
    "        'difference_percent': diff_percent,\n",
    "        'area_model1': area1,\n",
    "        'area_model2': area2,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "def save_boolean_results(results, output_dir=\"outputs/boolean\"):\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ STEP-—Ñ–∞–π–ª—ã\"\"\"\n",
    "    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved = []\n",
    "    \n",
    "    mapping = {\n",
    "        'fuse': 'union.step',\n",
    "        'common': 'intersection.step',\n",
    "        'diff1': 'unique_to_model1.step',\n",
    "        'diff2': 'unique_to_model2.step',\n",
    "        'symdiff': 'all_differences.step'\n",
    "    }\n",
    "    \n",
    "    for key, filename in mapping.items():\n",
    "        if key in results:\n",
    "            try:\n",
    "                writer = STEPControl_Writer()\n",
    "                writer.Transfer(results[key], STEPControl_AsIs)\n",
    "                status = writer.Write(os.path.join(output_dir, filename))\n",
    "                if status == 1:\n",
    "                    saved.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {filename}: {e}\")\n",
    "    \n",
    "    return saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ó–ê–ü–£–°–ö –°–†–ê–í–ù–ï–ù–ò–Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'read_step_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 181\u001b[0m\n\u001b[1;32m    178\u001b[0m USE_GNN \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ True, –µ—Å–ª–∏ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å gnn_best.pth\u001b[39;00m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;66;03m# –ó–∞–ø—É—Å–∫\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mmain_pipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_file_1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_FILE_1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_file_2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEP_FILE_2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_gnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_GNN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgnn_best.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à—ë–Ω!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 37\u001b[0m, in \u001b[0;36mmain_pipeline\u001b[0;34m(step_file_1, step_file_2, use_gnn, model_path)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124müì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m shape1 \u001b[38;5;241m=\u001b[39m \u001b[43mread_step_file\u001b[49m(step_file_1)\n\u001b[1;32m     38\u001b[0m shape2 \u001b[38;5;241m=\u001b[39m read_step_file(step_file_2)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# 2. –°–æ–≤–º–µ—â–µ–Ω–∏–µ\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_step_file' is not defined"
     ]
    }
   ],
   "source": [
    "def main_pipeline(step_file_1, step_file_2, use_gnn=False, model_path=\"gnn_best.pth\"):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ —Å–æ–≤–º–µ—â–µ–Ω–∏—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å, –æ—Ç–≤–µ—Ä—Å—Ç–∏–π –∏ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    step_file_1 : str\n",
    "        –ü—É—Ç—å –∫ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏ STEP\n",
    "    step_file_2 : str\n",
    "        –ü—É—Ç—å –∫–æ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏ STEP\n",
    "    use_gnn : bool\n",
    "        –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GNN –¥–ª—è –ø–æ–∏—Å–∫–∞ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –∏ –æ—Ç–≤–µ—Ä—Å—Ç–∏–π (—Ç—Ä–µ–±—É–µ—Ç –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏)\n",
    "    model_path : str\n",
    "        –ü—É—Ç—å –∫ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ GNN\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    dict : –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –∏ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    \"\"\"\n",
    "    from OCC.Core.gp import gp_Trsf\n",
    "    from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "    import os\n",
    "    \n",
    "    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: –ø–æ–∏—Å–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –ø–æ —Ä–æ–ª–∏\n",
    "    def find_elements_by_role(role_probs, node_types, coords, role_idx=3, top_k=3):\n",
    "        face_mask = (node_types == 1)\n",
    "        if not np.any(face_mask):\n",
    "            return np.array([])\n",
    "        scores = role_probs[face_mask, role_idx]\n",
    "        top_indices = np.argsort(-scores)[:top_k]\n",
    "        face_indices = np.where(face_mask)[0][top_indices]\n",
    "        return coords[face_indices]\n",
    "    \n",
    "    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "    print(\"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...\")\n",
    "    shape1 = read_step_file(step_file_1)\n",
    "    shape2 = read_step_file(step_file_2)\n",
    "    \n",
    "    # 2. –°–æ–≤–º–µ—â–µ–Ω–∏–µ\n",
    "    print(\"üîß –°–æ–≤–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...\")\n",
    "    R_mat, t_vec = None, None\n",
    "    \n",
    "    if use_gnn:\n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É\")\n",
    "            use_gnn = False\n",
    "        else:\n",
    "            try:\n",
    "                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "                model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "                model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "                model.eval()\n",
    "                \n",
    "                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤\n",
    "                v1, fv1 = extract_topology(shape1)\n",
    "                v2, fv2 = extract_topology(shape2)\n",
    "                g1 = build_graph(v1, fv1)\n",
    "                g2 = build_graph(v2, fv2)\n",
    "                \n",
    "                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–æ–ª–µ–π\n",
    "                with torch.no_grad():\n",
    "                    batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)\n",
    "                    batch2 = torch.zeros(g2.x.size(0), dtype=torch.long)\n",
    "                    roles1, _ = model(g1.x, g1.edge_index, batch1)\n",
    "                    roles2, _ = model(g2.x, g2.edge_index, batch2)\n",
    "                \n",
    "                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)\n",
    "                cog1 = np.array(compute_center_of_mass(shape1))\n",
    "                cog2 = np.array(compute_center_of_mass(shape2))\n",
    "                \n",
    "                # –ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ä—Å—Ç–∏–π (—Ä–æ–ª—å 2) –∏ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3)\n",
    "                holes1 = find_elements_by_role(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy(), role_idx=2, top_k=2)\n",
    "                holes2 = find_elements_by_role(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy(), role_idx=2, top_k=2)\n",
    "                ref_planes1 = find_elements_by_role(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy(), role_idx=3, top_k=2)\n",
    "                ref_planes2 = find_elements_by_role(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy(), role_idx=3, top_k=2)\n",
    "                \n",
    "                # –°–±–æ—Ä —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)\n",
    "                points1 = [cog1]  # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å ‚Äî –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞!\n",
    "                points2 = [cog2]\n",
    "                points1.extend(holes1[:min(2, len(holes1))])      # –î–æ 2 –æ—Ç–≤–µ—Ä—Å—Ç–∏–π\n",
    "                points2.extend(holes2[:min(2, len(holes2))])\n",
    "                points1.extend(ref_planes1[:min(2, len(ref_planes1))])  # –î–æ 2 –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\n",
    "                points2.extend(ref_planes2[:min(2, len(ref_planes2))])\n",
    "                \n",
    "                # –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ –ø–µ—Ä–≤—ã–º 3 —Ç–æ—á–∫–∞–º\n",
    "                if len(points1) >= 3 and len(points2) >= 3:\n",
    "                    src_pts = np.array(points1[:3])\n",
    "                    tgt_pts = np.array(points2[:3])\n",
    "                    R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)  # ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –Ω–µ align_models_enhanced!\n",
    "                    print(f\"‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ GNN –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø–æ {len(points1[:3])} —Ç–æ—á–∫–∞–º:\")\n",
    "                    print(f\"   ‚Ä¢ –¶–µ–Ω—Ç—Ä –º–∞—Å—Å\")\n",
    "                    print(f\"   ‚Ä¢ {len(holes1[:2])} –æ—Ç–≤–µ—Ä—Å—Ç–∏–π\")\n",
    "                    print(f\"   ‚Ä¢ {len(ref_planes1[:2])} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\")\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (–Ω–∞–π–¥–µ–Ω–æ: {len(points1)}/{len(points2)}, –Ω—É–∂–Ω–æ ‚â•3) ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É\")\n",
    "                    use_gnn = False\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ GNN ({type(e).__name__}): {e}\")\n",
    "                print(\"‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –±–µ–∑ GNN\")\n",
    "                use_gnn = False\n",
    "    \n",
    "    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥: —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –∫—Ä—É–ø–Ω—ã–º –ø–ª–æ—Å–∫–∏–º –≥—Ä–∞–Ω—è–º\n",
    "    if not use_gnn:\n",
    "        planes1 = extract_large_planes(shape1, min_area=10.0, max_planes=5)\n",
    "        planes2 = extract_large_planes(shape2, min_area=10.0, max_planes=5)\n",
    "        \n",
    "        if len(planes1) >= 3 and len(planes2) >= 3:\n",
    "            src_pts = np.array([p['center'] for p in planes1[:3]])\n",
    "            tgt_pts = np.array([p['center'] for p in planes2[:3]])\n",
    "            R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)\n",
    "            print(\"‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–ø–æ 3 –∫—Ä—É–ø–Ω–µ–π—à–∏–º –ø–ª–æ—Å–∫–æ—Å—Ç—è–º)\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π ‚Äî –ø—Ä–∏–º–µ–Ω—è—é —Ç–æ–∂–¥–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\")\n",
    "            R_mat, t_vec = np.eye(3), np.zeros(3)\n",
    "    \n",
    "    # 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "    trsf = gp_Trsf()\n",
    "    trsf.SetValues(\n",
    "        float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),\n",
    "        float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),\n",
    "        float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])\n",
    "    )\n",
    "    \n",
    "    transform = BRepBuilderAPI_Transform(shape2, trsf)\n",
    "    shape2_aligned = transform.Shape()\n",
    "    \n",
    "    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–≤–º–µ—â—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "    os.makedirs(\"outputs/results\", exist_ok=True)\n",
    "    writer = STEPControl_Writer()\n",
    "    writer.Transfer(shape2_aligned, STEPControl_AsIs)\n",
    "    writer.Write(\"outputs/results/aligned_model.step\")\n",
    "    print(\"üíæ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_model.step\")\n",
    "    \n",
    "    # 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\n",
    "    print(\"\\nüìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è...\")\n",
    "    metrics = evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000)\n",
    "    if metrics['success']:\n",
    "        print(f\"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {metrics['mean_distance']:.4f} –º–º\")\n",
    "        print(f\"   –¢–æ—á–µ–∫ < 0.1 –º–º: {metrics['inlier_ratio_0.1mm']*100:.1f}%\")\n",
    "    \n",
    "    # 6. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "    print(\"\\nüîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏...\")\n",
    "    analysis = analyze_differences(shape1, shape2_aligned, tolerance=1e-3)\n",
    "    \n",
    "    print(f\"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 1:     {analysis['volume_model1']:.2f} –º–º¬≥\")\n",
    "    print(f\"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 2:     {analysis['volume_model2']:.2f} –º–º¬≥\")\n",
    "    print(f\"   –†–∞–∑–ª–∏—á–∏—è:           {analysis['difference_percent']:.2f}%\")\n",
    "    \n",
    "    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è\n",
    "    if analysis['difference_percent'] < 0.1:\n",
    "        print(\"‚úÖ –ú–æ–¥–µ–ª–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã\")\n",
    "    elif analysis['difference_percent'] < 1.0:\n",
    "        print(\"‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ (–≤–æ–∑–º–æ–∂–Ω—ã –¥–æ–ø—É—Å–∫–∏)\")\n",
    "    elif analysis['difference_percent'] < 5.0:\n",
    "        print(\"üî∂ –ú–æ–¥–µ–ª–∏ —É–º–µ—Ä–µ–Ω–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è\")\n",
    "    else:\n",
    "        print(\"‚ùå –ú–æ–¥–µ–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è\")\n",
    "    \n",
    "    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\n",
    "    saved_files = save_boolean_results(analysis['results'], \"outputs/boolean\")\n",
    "    if saved_files:\n",
    "        print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:\")\n",
    "        for fname in saved_files:\n",
    "            print(f\"   ‚Ä¢ outputs/boolean/{fname}\")\n",
    "        print(\"\\nüí° –û—Ç–∫—Ä–æ–π—Ç–µ 'all_differences.step' –≤ FreeCAD –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏—á–∏–π\")\n",
    "    \n",
    "    return {\n",
    "        'alignment_metrics': metrics,\n",
    "        'difference_analysis': analysis,\n",
    "        'saved_files': saved_files\n",
    "    }\n",
    "\n",
    "\n",
    "STEP_FILE_1 = \"synthetic_dataset/raw/bracket_000002_trans_00.step\"\n",
    "STEP_FILE_2 = \"synthetic_dataset/raw/bracket_000003_trans_00.step\"\n",
    "USE_GNN = True  # –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –≤ True, –µ—Å–ª–∏ –µ—Å—Ç—å –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å gnn_best.pth\n",
    "    \n",
    "    # –ó–∞–ø—É—Å–∫\n",
    "results = main_pipeline(\n",
    "        step_file_1=STEP_FILE_1,\n",
    "        step_file_2=STEP_FILE_2,\n",
    "        use_gnn=USE_GNN,\n",
    "        model_path=\"gnn_best.pth\"\n",
    "    )\n",
    "    \n",
    "print(\"\\n‚úÖ –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à—ë–Ω!\")\n",
    "print(\"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤:\")\n",
    "print(\"  ‚Ä¢ outputs/results/aligned_model.step ‚Äî —Å–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å\")\n",
    "print(\"  ‚Ä¢ outputs/boolean/ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cad_step",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

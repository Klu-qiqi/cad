{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–π STEP —Å GNN\n",
    "\n",
    "**–¶–µ–ª—å**: —Å—Ä–∞–≤–Ω–∏—Ç—å –¥–≤–µ 3D-–º–æ–¥–µ–ª–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ STEP, –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Ä–æ–ª–∏ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ —Å–æ–≤–º–µ—Å—Ç–∏—Ç—å –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "try:\n",
    "    from OCC.Core import STEPControl, TopExp, TopAbs\n",
    "    from OCC.Core.BRep import BRep_Tool\n",
    "    from OCC.Core.gp import gp_Pnt\n",
    "    import numpy as np\n",
    "except ImportError:\n",
    "    print(\"–Ω–µ—Ç pythonocc-core\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ClassNotWrappedError', 'CompSolid', 'Compound', 'Edge', 'Face', 'Handle_TopoDS_AlertAttribute_Create', 'Handle_TopoDS_AlertAttribute_DownCast', 'Handle_TopoDS_AlertAttribute_IsNull', 'Handle_TopoDS_AlertWithShape_Create', 'Handle_TopoDS_AlertWithShape_DownCast', 'Handle_TopoDS_AlertWithShape_IsNull', 'Handle_TopoDS_HShape_Create', 'Handle_TopoDS_HShape_DownCast', 'Handle_TopoDS_HShape_IsNull', 'Handle_TopoDS_TCompSolid_Create', 'Handle_TopoDS_TCompSolid_DownCast', 'Handle_TopoDS_TCompSolid_IsNull', 'Handle_TopoDS_TCompound_Create', 'Handle_TopoDS_TCompound_DownCast', 'Handle_TopoDS_TCompound_IsNull', 'Handle_TopoDS_TEdge_Create', 'Handle_TopoDS_TEdge_DownCast', 'Handle_TopoDS_TEdge_IsNull', 'Handle_TopoDS_TFace_Create', 'Handle_TopoDS_TFace_DownCast', 'Handle_TopoDS_TFace_IsNull', 'Handle_TopoDS_TShape_Create', 'Handle_TopoDS_TShape_DownCast', 'Handle_TopoDS_TShape_IsNull', 'Handle_TopoDS_TShell_Create', 'Handle_TopoDS_TShell_DownCast', 'Handle_TopoDS_TShell_IsNull', 'Handle_TopoDS_TSolid_Create', 'Handle_TopoDS_TSolid_DownCast', 'Handle_TopoDS_TSolid_IsNull', 'Handle_TopoDS_TVertex_Create', 'Handle_TopoDS_TVertex_DownCast', 'Handle_TopoDS_TVertex_IsNull', 'Handle_TopoDS_TWire_Create', 'Handle_TopoDS_TWire_DownCast', 'Handle_TopoDS_TWire_IsNull', 'IntEnum', 'MethodNotWrappedError', 'OCC', 'Proxy', 'Shell', 'Solid', 'SwigPyIterator', 'TopoDS_AlertAttribute', 'TopoDS_AlertAttribute_Send', 'TopoDS_AlertWithShape', 'TopoDS_Builder', 'TopoDS_CompSolid', 'TopoDS_Compound', 'TopoDS_Edge', 'TopoDS_Face', 'TopoDS_HShape', 'TopoDS_Iterator', 'TopoDS_Shape', 'TopoDS_Shell', 'TopoDS_Solid', 'TopoDS_TCompSolid', 'TopoDS_TCompound', 'TopoDS_TEdge', 'TopoDS_TFace', 'TopoDS_TShape', 'TopoDS_TShell', 'TopoDS_TSolid', 'TopoDS_TVertex', 'TopoDS_TWire', 'TopoDS_Vertex', 'TopoDS_Wire', 'Vertex', 'Wire', '_SwigNonDynamicMeta', '_TopoDS', '__builtin__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_dumps_object', '_swig_add_metaclass', '_swig_python_version_info', '_swig_repr', '_swig_setattr_nondynamic_class_variable', '_swig_setattr_nondynamic_instance_variable', 'cerr', 'cin', 'classnotwrapped', 'clog', 'cout', 'cvar', 'deprecated', 'endl', 'endl_cb_ptr', 'ends', 'ends_cb_ptr', 'flush', 'flush_cb_ptr', 'functools', 'ios', 'ios_base', 'iostream', 'istream', 'methodnotwrapped', 'ostream', 'process_exception', 'topods', 'warnings']\n"
     ]
    }
   ],
   "source": [
    "from OCC.Core import TopoDS\n",
    "print(dir(TopoDS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 –ü–∞—Ä—Å–∏–Ω–≥ STEP-—Ñ–∞–π–ª–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_step_file(filename):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç STEP-—Ñ–∞–π–ª –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç TopoDS_Shape\"\"\"\n",
    "    reader = STEPControl.STEPControl_Reader()\n",
    "    reader.ReadFile(str(filename))\n",
    "    reader.TransferRoots()\n",
    "    return reader.OneShape()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'TopoDS_Solid'> <class 'TopoDS_Solid'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(\"outputs/results\", exist_ok=True)\n",
    "\n",
    "#STEP_FILE_1 = \"test.step\"  \n",
    "#STEP_FILE_2 = \"test1.step\" \n",
    "\n",
    "STEP_FILE_1 = \"synthetic_dataset/raw/bracket_000002_trans_00.step\"  \n",
    "STEP_FILE_2 = \"synthetic_dataset/raw/bracket_000002_trans_01.step\" \n",
    "\n",
    "#STEP_FILE_1 = \"synthetic_dataset/raw/bracket_000199_trans_00.step\"  \n",
    "#STEP_FILE_2 = \"synthetic_dataset/raw/bracket_000199_trans_01.step\" \n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π\n",
    "shape1 = read_step_file(STEP_FILE_1)\n",
    "shape2 = read_step_file(STEP_FILE_2)\n",
    "\n",
    "print(shape1, shape2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topology(shape):\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–µ—Ä—à–∏–Ω—ã –∏ —Å–≤—è–∑–∏ –≥—Ä–∞–Ω—å-–≤–µ—Ä—à–∏–Ω–∞ \n",
    "    vertices = []\n",
    "    vertex_map = {}\n",
    "    face_vertex_indices = []\n",
    "\n",
    "    face_explorer = TopExp.TopExp_Explorer(shape, TopAbs.TopAbs_FACE)\n",
    "    while face_explorer.More():\n",
    "        face = face_explorer.Current()\n",
    "        local_vertices = []\n",
    "\n",
    "        edge_explorer = TopExp.TopExp_Explorer(face, TopAbs.TopAbs_EDGE)\n",
    "        while edge_explorer.More():\n",
    "            edge = edge_explorer.Current()\n",
    "            \n",
    "            # –í–ª–æ–∂–µ–Ω–Ω—ã–π —ç–∫—Å–ø–ª–æ—Ä–µ—Ä –¥–ª—è –≤–µ—Ä—à–∏–Ω \n",
    "            vertex_explorer = TopExp.TopExp_Explorer(edge, TopAbs.TopAbs_VERTEX)\n",
    "            while vertex_explorer.More():\n",
    "                vertex = vertex_explorer.Current()\n",
    "                p = BRep_Tool.Pnt(vertex)\n",
    "                key = (round(p.X(), 6), round(p.Y(), 6), round(p.Z(), 6))\n",
    "                if key not in vertex_map:\n",
    "                    vertex_map[key] = len(vertices)\n",
    "                    vertices.append(np.array([p.X(), p.Y(), p.Z()]))\n",
    "                local_vertices.append(vertex_map[key])\n",
    "                vertex_explorer.Next()\n",
    "            \n",
    "            edge_explorer.Next()\n",
    "\n",
    "        if local_vertices:\n",
    "            local_vertices = list(dict.fromkeys(local_vertices))\n",
    "            face_vertex_indices.append(local_vertices)\n",
    "        face_explorer.Next()\n",
    "\n",
    "    return np.array(vertices), face_vertex_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinates(vertices):\n",
    "    if len(vertices) == 0:\n",
    "        return vertices\n",
    "    center = vertices.mean(axis=0)\n",
    "    scale = np.max(np.abs(vertices - center)) + 1e-8\n",
    "    return (vertices - center) / scale\n",
    "\n",
    "def build_graph(vertices, face_vertex_indices):\n",
    "    n_vertices = len(vertices)\n",
    "    n_faces = len(face_vertex_indices)\n",
    "\n",
    "    vertices_norm = normalize_coordinates(vertices)\n",
    "    node_coords = np.zeros((n_vertices + n_faces, 3))\n",
    "    node_types = np.zeros(n_vertices + n_faces, dtype=int)\n",
    "\n",
    "    # –í–µ—Ä—à–∏–Ω—ã\n",
    "    node_coords[:n_vertices] = vertices_norm\n",
    "    node_types[:n_vertices] = 0\n",
    "\n",
    "    # –ì—Ä–∞–Ω–∏\n",
    "    for i, vtx_ids in enumerate(face_vertex_indices):\n",
    "        if vtx_ids:\n",
    "            center = vertices_norm[vtx_ids].mean(axis=0)\n",
    "            node_coords[n_vertices + i] = center\n",
    "            node_types[n_vertices + i] = 1\n",
    "\n",
    "    # –†—ë–±—Ä–∞\n",
    "    edge_index = []\n",
    "    for face_id, vtx_ids in enumerate(face_vertex_indices):\n",
    "        for vtx_id in vtx_ids:\n",
    "            edge_index.append([n_vertices + face_id, vtx_id])\n",
    "            edge_index.append([vtx_id, n_vertices + face_id])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    x = torch.tensor(node_coords, dtype=torch.float)\n",
    "    node_type = torch.tensor(node_types, dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, node_type=node_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ GNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from OCC.Core.STEPControl import STEPControl_Reader\n",
    "\n",
    "class ExistingSyntheticDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ –£–ñ–ï –°–£–©–ï–°–¢–í–£–Æ–©–ò–• —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "    \n",
    "    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ (—É–∂–µ —Å–æ–∑–¥–∞–Ω–∞ –≤–∞—à–∏–º —Å–∫—Ä–∏–ø—Ç–æ–º):\n",
    "        synthetic_dataset/\n",
    "        ‚îú‚îÄ‚îÄ raw/          # STEP-—Ñ–∞–π–ª—ã\n",
    "        ‚îú‚îÄ‚îÄ annotations/  # JSON —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π —Ä–æ–ª–µ–π\n",
    "        ‚îî‚îÄ‚îÄ processed/    # –ì—Ä–∞—Ñ—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ .pt (–±—É–¥—É—Ç —Å–æ–∑–¥–∞–Ω—ã –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)\n",
    "    \"\"\"\n",
    "    def __init__(self, root=\"synthetic_dataset\", transform=None, pre_transform=None):\n",
    "        # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –î–û –≤—ã–∑–æ–≤–∞ super().__init__()\n",
    "        self.role_mapping = {\n",
    "            \"decorative\": 0,\n",
    "            \"functional\": 1,\n",
    "            \"fastening\": 2,\n",
    "            \"reference_plane\": 3\n",
    "        }\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "    \n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return os.path.join(self.root, \"raw\")\n",
    "    \n",
    "    @property\n",
    "    def ann_dir(self):\n",
    "        return os.path.join(self.root, \"annotations\")\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # –ë–µ—Ä—ë–º –¢–û–õ–¨–ö–û –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–±–µ–∑ _trans_)\n",
    "        files = [f for f in os.listdir(self.raw_dir) if f.endswith(\".step\") and \"_trans_\" not in f]\n",
    "        return sorted(files)\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f\"data_{idx:06d}.pt\" for idx in range(len(self.raw_file_names))]\n",
    "    \n",
    "    def process(self):\n",
    "        \"\"\"–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö STEP-—Ñ–∞–π–ª–æ–≤ –≤ –≥—Ä–∞—Ñ—ã —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π\"\"\"\n",
    "        print(f\"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(self.raw_file_names)} —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...\")\n",
    "        \n",
    "        for idx, step_file in enumerate(self.raw_file_names):\n",
    "            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "            reader = STEPControl_Reader()\n",
    "            reader.ReadFile(os.path.join(self.raw_dir, step_file))\n",
    "            reader.TransferRoots()\n",
    "            shape = reader.OneShape()\n",
    "            \n",
    "            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏\n",
    "            vertices, face_vertex_indices = extract_topology(shape)\n",
    "            \n",
    "            # 3. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞\n",
    "            data = build_graph(vertices, face_vertex_indices)\n",
    "            \n",
    "            # 4. –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –∏–∑ JSON\n",
    "            ann_file = os.path.splitext(step_file)[0] + \".json\"\n",
    "            ann_path = os.path.join(self.ann_dir, ann_file)\n",
    "            \n",
    "            if os.path.exists(ann_path):\n",
    "                with open(ann_path, \"r\") as f:\n",
    "                    annotations = json.load(f)\n",
    "                \n",
    "                n_vertices = len(vertices)\n",
    "                n_faces = len(face_vertex_indices)\n",
    "                node_roles = np.zeros(n_vertices + n_faces, dtype=np.int64)\n",
    "                \n",
    "                # –í–µ—Ä—à–∏–Ω—ã ‚Üí –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ (—Ä–æ–ª—å 0)\n",
    "                node_roles[:n_vertices] = self.role_mapping[\"decorative\"]\n",
    "                \n",
    "                # –ì—Ä–∞–Ω–∏ ‚Üí —Ä–∞–∑–º–µ—á–∞–µ–º –ø–æ –±–ª–∏–∑–æ—Å—Ç–∏ –∫ –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è–º\n",
    "                face_centers = data.x[n_vertices:].numpy()\n",
    "                \n",
    "                # –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3)\n",
    "                for ref_plane in annotations.get(\"reference_planes\", []):\n",
    "                    ref_center = np.array(ref_plane[\"center\"])\n",
    "                    distances = np.linalg.norm(face_centers - ref_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 15.0:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"reference_plane\"]\n",
    "                \n",
    "                # –ö—Ä–µ–ø—ë–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ä–æ–ª—å 2)\n",
    "                for fastening in annotations.get(\"fastening_elements\", []):\n",
    "                    fast_center = np.array(fastening[\"center\"])\n",
    "                    distances = np.linalg.norm(face_centers - fast_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 10.0:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"fastening\"]\n",
    "                \n",
    "                # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–æ–ª—å 1)\n",
    "                for func_surf in annotations.get(\"functional_surfaces\", []):\n",
    "                    func_center = np.array(func_surf[\"center\"])\n",
    "                    distances = np.linalg.norm(face_centers - func_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 10.0:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"functional\"]\n",
    "                \n",
    "                # –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏ ‚Üí —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (—Ä–æ–ª—å 1)\n",
    "                for i in range(n_faces):\n",
    "                    if node_roles[n_vertices + i] == 0:\n",
    "                        node_roles[n_vertices + i] = self.role_mapping[\"functional\"]\n",
    "                \n",
    "                data.y = torch.tensor(node_roles, dtype=torch.long)\n",
    "            else:\n",
    "                # –ë–µ–∑ —Ä–∞–∑–º–µ—Ç–∫–∏ ‚Äî –≤—Å–µ –≥—Ä–∞–Ω–∏ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ\n",
    "                n_vertices = len(vertices)\n",
    "                n_faces = len(face_vertex_indices)\n",
    "                node_roles = np.zeros(n_vertices + n_faces, dtype=np.int64)\n",
    "                node_roles[:n_vertices] = self.role_mapping[\"decorative\"]\n",
    "                node_roles[n_vertices:] = self.role_mapping[\"functional\"]\n",
    "                data.y = torch.tensor(node_roles, dtype=torch.long)\n",
    "            \n",
    "            # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –ë–ï–ó –≤–µ—Å–æ–≤ (—Ç–æ–ª—å–∫–æ –¥–∞–Ω–Ω—ã–µ)\n",
    "            torch.save(data, os.path.join(self.processed_dir, f\"data_{idx:06d}.pt\"))\n",
    "        \n",
    "        print(f\"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π\")\n",
    "        print(f\"   –ì—Ä–∞—Ñ—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.processed_dir}\")\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: weights_only=False –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏—Ö –æ–±—ä–µ–∫—Ç–æ–≤\n",
    "        return torch.load(\n",
    "            os.path.join(self.processed_dir, self.processed_file_names[idx]),\n",
    "            weights_only=False  # –û—Ç–∫–ª—é—á–∞–µ–º —Å—Ç—Ä–æ–≥—É—é –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å (–¥–∞–Ω–Ω—ã–µ —Å–≤–æ–∏)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –≤–æ–æ–±—â–µ —Ä–æ–ª—å 3 (–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏) –≤ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö\n",
    "test_data = dataset[0]\n",
    "face_mask = (test_data.node_type == 1)\n",
    "true_roles = test_data.y[face_mask]\n",
    "\n",
    "print(\"üìä –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏:\")\n",
    "print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {face_mask.sum().item()}\")\n",
    "print(f\"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–æ–ª–µ–π (—Ç–æ–ª—å–∫–æ –≥—Ä–∞–Ω–∏):\")\n",
    "for role in range(4):\n",
    "    count = (true_roles == role).sum().item()\n",
    "    role_name = [\"–¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω–∞—è\", \"—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è\", \"–∫—Ä–µ–ø—ë–∂–Ω–∞—è\", \"–æ–ø–æ—Ä–Ω–∞—è –ø–ª–æ—Å–∫–æ—Å—Ç—å\"][role]\n",
    "    print(f\"      –†–æ–ª—å {role} ({role_name:20s}): {count:3d} —à—Ç.\")\n",
    "\n",
    "# –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ü–µ–Ω—Ç—Ä–æ–∏–¥–æ–≤ –≥—Ä–∞–Ω–µ–π –∏ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "print(\"\\nüìç –¶–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π –∏–∑ –≥—Ä–∞—Ñ–∞ (–ø–µ—Ä–≤—ã–µ 5):\")\n",
    "for i in range(min(5, face_mask.sum().item())):\n",
    "    print(f\"   –ì—Ä–∞–Ω—å {i}: {test_data.x[len(test_data.x) - face_mask.sum().item() + i].numpy()}\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏\n",
    "step_file = dataset.raw_file_names[0]\n",
    "ann_file = os.path.splitext(step_file)[0] + \".json\"\n",
    "ann_path = os.path.join(dataset.ann_dir, ann_file)\n",
    "\n",
    "if os.path.exists(ann_path):\n",
    "    with open(ann_path, \"r\") as f:\n",
    "        annotations = json.load(f)\n",
    "    print(f\"\\nüìÑ –û—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–∞—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –∏–∑ {ann_file}:\")\n",
    "    print(f\"   –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏: {len(annotations.get('reference_planes', []))} —à—Ç.\")\n",
    "    for i, rp in enumerate(annotations.get('reference_planes', [])):\n",
    "        print(f\"      {i+1}. –¶–µ–Ω—Ç—Ä: {rp['center']}, –ù–æ—Ä–º–∞–ª—å: {rp['normal']}, –ü–ª–æ—â–∞–¥—å: {rp['area']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    " class FixedSyntheticDataset(Dataset):\n",
    "    \"\"\"\n",
    "    –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "    \"\"\"\n",
    "    def __init__(self, root=\"synthetic_dataset\", transform=None, pre_transform=None):\n",
    "        self.role_mapping = {\n",
    "            \"decorative\": 0,\n",
    "            \"functional\": 1,\n",
    "            \"fastening\": 2,\n",
    "            \"reference_plane\": 3\n",
    "        }\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "    \n",
    "    @property\n",
    "    def raw_dir(self):\n",
    "        return os.path.join(self.root, \"raw\")\n",
    "    \n",
    "    @property\n",
    "    def ann_dir(self):\n",
    "        return os.path.join(self.root, \"annotations\")\n",
    "    \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        files = [f for f in os.listdir(self.raw_dir) if f.endswith(\".step\") and \"_trans_\" not in f]\n",
    "        return sorted(files)\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f\"data_{idx:06d}.pt\" for idx in range(len(self.raw_file_names))]\n",
    "    \n",
    "    def process(self):\n",
    "        print(f\"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π...\")\n",
    "        \n",
    "        for idx, step_file in enumerate(self.raw_file_names):\n",
    "            # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏\n",
    "            reader = STEPControl_Reader()\n",
    "            reader.ReadFile(os.path.join(self.raw_dir, step_file))\n",
    "            reader.TransferRoots()\n",
    "            shape = reader.OneShape()\n",
    "            \n",
    "            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –ë–ï–ó –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "            vertices, face_vertex_indices = extract_topology(shape)\n",
    "            \n",
    "            # –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "            ann_file = os.path.splitext(step_file)[0] + \".json\"\n",
    "            ann_path = os.path.join(self.ann_dir, ann_file)\n",
    "            annotations = {}\n",
    "            if os.path.exists(ann_path):\n",
    "                with open(ann_path, \"r\") as f:\n",
    "                    annotations = json.load(f)\n",
    "            \n",
    "            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π —Å –≥—Ä–∞–Ω—è–º–∏ –î–û –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏\n",
    "            n_vertices = len(vertices)\n",
    "            n_faces = len(face_vertex_indices)\n",
    "            node_roles = np.zeros(n_vertices + n_faces, dtype=np.int64)\n",
    "            node_roles[:n_vertices] = self.role_mapping[\"decorative\"]  # –≤–µ—Ä—à–∏–Ω—ã ‚Üí –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ\n",
    "            \n",
    "            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π –≤ –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö\n",
    "            face_centers_raw = []\n",
    "            for vtx_ids in face_vertex_indices:\n",
    "                if vtx_ids:\n",
    "                    center = vertices[vtx_ids].mean(axis=0)\n",
    "                    face_centers_raw.append(center)\n",
    "            face_centers_raw = np.array(face_centers_raw)\n",
    "            \n",
    "            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π\n",
    "            assigned = np.zeros(n_faces, dtype=bool)\n",
    "            \n",
    "            # 1. –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3) ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç\n",
    "            for ref_plane in annotations.get(\"reference_planes\", []):\n",
    "                ref_center = np.array(ref_plane[\"center\"])\n",
    "                if len(face_centers_raw) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_raw - ref_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 25.0:  # —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ 25 –º–º\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"reference_plane\"]\n",
    "                        assigned[closest_idx] = True\n",
    "            \n",
    "            # 2. –ö—Ä–µ–ø—ë–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ä–æ–ª—å 2)\n",
    "            for fastening in annotations.get(\"fastening_elements\", []):\n",
    "                fast_center = np.array(fastening[\"center\"])\n",
    "                if len(face_centers_raw) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_raw - fast_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 15.0 and not assigned[closest_idx]:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"fastening\"]\n",
    "                        assigned[closest_idx] = True\n",
    "            \n",
    "            # 3. –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–æ–ª—å 1)\n",
    "            for func_surf in annotations.get(\"functional_surfaces\", []):\n",
    "                func_center = np.array(func_surf[\"center\"])\n",
    "                if len(face_centers_raw) > 0:\n",
    "                    distances = np.linalg.norm(face_centers_raw - func_center, axis=1)\n",
    "                    closest_idx = np.argmin(distances)\n",
    "                    if distances[closest_idx] < 15.0 and not assigned[closest_idx]:\n",
    "                        node_roles[n_vertices + closest_idx] = self.role_mapping[\"functional\"]\n",
    "                        assigned[closest_idx] = True\n",
    "            \n",
    "            # 4. –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏ ‚Üí —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (—Ä–æ–ª—å 1)\n",
    "            for i in range(n_faces):\n",
    "                if not assigned[i]:\n",
    "                    node_roles[n_vertices + i] = self.role_mapping[\"functional\"]\n",
    "            \n",
    "            # –¢–µ–ø–µ—Ä—å —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –° –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ï–ô (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º –∫–æ–¥–µ)\n",
    "            data = build_graph(vertices, face_vertex_indices)\n",
    "            data.y = torch.tensor(node_roles, dtype=torch.long)\n",
    "            \n",
    "            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "            torch.save(data, os.path.join(self.processed_dir, f\"data_{idx:06d}.pt\"))\n",
    "        \n",
    "        print(f\"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π\")\n",
    "    \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        return torch.load(\n",
    "            os.path.join(self.processed_dir, self.processed_file_names[idx]),\n",
    "            weights_only=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GATv2Conv, global_mean_pool\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "    def __init__(self, in_channels=3, hidden_dim=64, num_roles=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATv2Conv(in_channels, hidden_dim, heads=4, concat=True, dropout=0.2)\n",
    "        self.conv2 = GATv2Conv(hidden_dim * 4, hidden_dim, heads=2, concat=False, dropout=0.2)\n",
    "        self.role_classifier = torch.nn.Linear(hidden_dim, num_roles)\n",
    "        self.graph_proj = torch.nn.Linear(hidden_dim, 64)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        roles = self.role_classifier(x)\n",
    "        graph_emb = global_mean_pool(x, batch)\n",
    "        graph_emb = self.graph_proj(graph_emb)\n",
    "        return roles, graph_emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  –î–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. –°–æ–∑–¥–∞–Ω–∏–µ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏–∑ –°–£–©–ï–°–¢–í–£–Æ–©–ò–• –¥–∞–Ω–Ω—ã—Ö\n",
    "print(\"üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...\")\n",
    "dataset = ExistingSyntheticDataset(root=\"synthetic_dataset\")\n",
    "\n",
    "# 2. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏\n",
    "from torch.utils.data import random_split\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(\n",
    "    dataset, [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "from torch_geometric.loader import DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"   –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞: {len(train_dataset)} –º–æ–¥–µ–ª–µ–π\")\n",
    "print(f\"   –í–∞–ª–∏–¥–∞—Ü–∏—è:  {len(val_dataset)} –º–æ–¥–µ–ª–µ–π\")\n",
    "\n",
    "# 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "device = torch.device('cpu')  # –∏–ª–∏ 'cuda' –µ—Å–ª–∏ –µ—Å—Ç—å GPU\n",
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4).to(device)\n",
    "\n",
    "# 4. –û–±—É—á–µ–Ω–∏–µ\n",
    "import torch.optim as optim\n",
    "\n",
    "# –í–µ—Å–∞ –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤ (–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ —Ä–µ–¥–∫–∏)\n",
    "class_weights = torch.tensor([0.5, 1.0, 1.5, 3.0], dtype=torch.float, device=device)\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö (50 —ç–ø–æ—Ö)...\\n\")\n",
    "\n",
    "for epoch in range(50):\n",
    "    # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "        \n",
    "        roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "        \n",
    "        # –ü–æ—Ç–µ—Ä—è —Ç–æ–ª—å–∫–æ –¥–ª—è –≥—Ä–∞–Ω–µ–π (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≤–µ—Ä—à–∏–Ω—ã)\n",
    "        face_mask = (data.node_type == 1)\n",
    "        if face_mask.sum() > 0:\n",
    "            loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    \n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "            roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "            \n",
    "            face_mask = (data.node_type == 1)\n",
    "            if face_mask.sum() > 0:\n",
    "                loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "                val_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"gnn_best.pth\")\n",
    "        status = \"‚≠ê\"\n",
    "    else:\n",
    "        status = \"\"\n",
    "    \n",
    "    print(f\"–≠–ø–æ—Ö–∞ {epoch+1:2d}/50 | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} {status}\")\n",
    "\n",
    "print(f\"\\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: gnn_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –°–æ–∑–¥–∞–Ω–∏–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "print(\"üì¶ –ü–µ—Ä–µ–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π...\")\n",
    "dataset = FixedSyntheticDataset(root=\"synthetic_dataset\")\n",
    "\n",
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏\n",
    "test_data = dataset[0]\n",
    "face_mask = (test_data.node_type == 1)\n",
    "true_roles = test_data.y[face_mask]\n",
    "role3_count = (true_roles == 3).sum().item()\n",
    "print(f\"\\n‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è:\")\n",
    "print(f\"   –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3) –≤ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏: {role3_count} –∏–∑ {face_mask.sum().item()} –≥—Ä–∞–Ω–µ–π\")\n",
    "if role3_count == 0:\n",
    "    print(\"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –î–∞–∂–µ –ø–æ—Å–ª–µ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ—Ç –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π!\")\n",
    "    print(\"   –í–æ–∑–º–æ–∂–Ω–æ, –ø—Ä–æ–±–ª–µ–º–∞ –≤ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–∏ –≤ JSON\")\n",
    "else:\n",
    "    print(\"‚úÖ –†–∞–∑–º–µ—Ç–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–∞ ‚Äî –Ω–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ\")\n",
    "\n",
    "# –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∏\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# –ú–æ–¥–µ–ª—å\n",
    "device = torch.device('cpu')\n",
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4).to(device)\n",
    "\n",
    "# –£—Å–∏–ª–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Ä–æ–ª–∏ 3 (–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏)\n",
    "class_weights = torch.tensor([0.2, 0.3, 1.0, 10.0], dtype=torch.float, device=device)  # —Ä–æ–ª—å 3 –∏–º–µ–µ—Ç –≤–µ—Å 10!\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "\n",
    "# –û–±—É—á–µ–Ω–∏–µ —Å —Ä–∞–Ω–Ω–µ–π –æ—Å—Ç–∞–Ω–æ–≤–∫–æ–π\n",
    "best_val_loss = float('inf')\n",
    "patience = 0\n",
    "max_patience = 15\n",
    "\n",
    "print(\"\\nüöÄ –û–±—É—á–µ–Ω–∏–µ —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3)...\\n\")\n",
    "\n",
    "for epoch in range(150):  # —É–≤–µ–ª–∏—á–µ–Ω–æ –¥–æ 150 —ç–ø–æ—Ö\n",
    "    # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct_role3 = 0\n",
    "    train_total_role3 = 0\n",
    "    \n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "        batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "        \n",
    "        roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "        \n",
    "        face_mask = (data.node_type == 1)\n",
    "        if face_mask.sum() > 0:\n",
    "            loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "            \n",
    "            # –°—á—ë—Ç—á–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –¥–ª—è —Ä–æ–ª–∏ 3\n",
    "            preds = roles_pred[face_mask].argmax(dim=1)\n",
    "            role3_mask = (data.y[face_mask] == 3)\n",
    "            if role3_mask.sum() > 0:\n",
    "                train_correct_role3 += (preds[role3_mask] == 3).sum().item()\n",
    "                train_total_role3 += role3_mask.sum().item()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * data.num_graphs\n",
    "    \n",
    "    avg_train_loss = train_loss / len(train_loader.dataset)\n",
    "    role3_acc = train_correct_role3 / train_total_role3 if train_total_role3 > 0 else 0\n",
    "    \n",
    "    # –í–∞–ª–∏–¥–∞—Ü–∏—è\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct_role3 = 0\n",
    "    val_total_role3 = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in val_loader:\n",
    "            data = data.to(device)\n",
    "            batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)\n",
    "            roles_pred, _ = model(data.x, data.edge_index, batch)\n",
    "            \n",
    "            face_mask = (data.node_type == 1)\n",
    "            if face_mask.sum() > 0:\n",
    "                loss = criterion(roles_pred[face_mask], data.y[face_mask])\n",
    "                val_loss += loss.item() * data.num_graphs\n",
    "                \n",
    "                preds = roles_pred[face_mask].argmax(dim=1)\n",
    "                role3_mask = (data.y[face_mask] == 3)\n",
    "                if role3_mask.sum() > 0:\n",
    "                    val_correct_role3 += (preds[role3_mask] == 3).sum().item()\n",
    "                    val_total_role3 += role3_mask.sum().item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader.dataset)\n",
    "    val_role3_acc = val_correct_role3 / val_total_role3 if val_total_role3 > 0 else 0\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"gnn_best.pth\")\n",
    "        patience = 0\n",
    "        status = \"‚≠ê\"\n",
    "    else:\n",
    "        patience += 1\n",
    "        status = \"\"\n",
    "    \n",
    "    print(f\"–≠–ø–æ—Ö–∞ {epoch+1:3d}/150 | \"\n",
    "          f\"Loss: {avg_train_loss:.4f} ‚Üí {avg_val_loss:.4f} | \"\n",
    "          f\"RefAcc: {role3_acc:.1%} ‚Üí {val_role3_acc:.1%} {status}\")\n",
    "    \n",
    "    if patience >= max_patience:\n",
    "        print(f\"\\n‚èπÔ∏è  –†–∞–Ω–Ω—è—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(f\"\\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: gnn_best.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# —Ç–µ—Å—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è:\n",
      "   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: 14\n",
      "   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 0\n",
      "   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): 0\n",
      "\n",
      "üìã –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 10 –≥—Ä–∞–Ω–µ–π):\n",
      "–ì—Ä–∞–Ω—å | –ò—Å—Ç–∏–Ω–Ω–∞—è —Ä–æ–ª—å | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ä–æ–ª—å | –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ\n",
      "-------------------------------------------------------\n",
      "   0  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   1  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   2  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   3  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   4  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   5  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   6  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   7  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   8  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "   9  | —Ñ—É–Ω–∫—Ü        | —Ñ—É–Ω–∫—Ü            | ‚úÖ\n",
      "\n",
      "üîç –¢–µ—Å—Ç –Ω–∞ –≤–∞—à–∏—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å):\n",
      "   –ù–∞–π–¥–µ–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: 3\n",
      "‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É —Å–æ–≤–º–µ—â–µ–Ω–∏—é!\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –∏ —Ç–µ—Å—Ç\n",
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "model.load_state_dict(torch.load(\"gnn_best.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "test_data = dataset[0]\n",
    "with torch.no_grad():\n",
    "    batch = torch.zeros(test_data.x.size(0), dtype=torch.long)\n",
    "    roles_pred, _ = model(test_data.x, test_data.edge_index, batch)\n",
    "    pred_classes = roles_pred.argmax(dim=1)\n",
    "\n",
    "face_mask = (test_data.node_type == 1)\n",
    "true_roles = test_data.y[face_mask]\n",
    "pred_roles = pred_classes[face_mask]\n",
    "\n",
    "print(\"\\n‚úÖ –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –æ–±—É—á–µ–Ω–∏—è:\")\n",
    "print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {face_mask.sum().item()}\")\n",
    "print(f\"   –ò—Å—Ç–∏–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): {(true_roles == 3).sum().item()}\")\n",
    "print(f\"   –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã—Ö –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): {(pred_roles == 3).sum().item()}\")\n",
    "\n",
    "# –ü–æ–¥—Ä–æ–±–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π\n",
    "print(\"\\nüìã –î–µ—Ç–∞–ª—å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ (–ø–µ—Ä–≤—ã–µ 10 –≥—Ä–∞–Ω–µ–π):\")\n",
    "print(\"–ì—Ä–∞–Ω—å | –ò—Å—Ç–∏–Ω–Ω–∞—è —Ä–æ–ª—å | –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è —Ä–æ–ª—å | –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ\")\n",
    "print(\"-\" * 55)\n",
    "for i in range(min(10, len(true_roles))):\n",
    "    match = \"‚úÖ\" if true_roles[i] == pred_roles[i] else \"‚ùå\"\n",
    "    true_name = [\"–¥–µ–∫–æ—Ä\", \"—Ñ—É–Ω–∫—Ü\", \"–∫—Ä–µ–ø—ë–∂\", \"–æ–ø–æ—Ä–Ω\"][true_roles[i]]\n",
    "    pred_name = [\"–¥–µ–∫–æ—Ä\", \"—Ñ—É–Ω–∫—Ü\", \"–∫—Ä–µ–ø—ë–∂\", \"–æ–ø–æ—Ä–Ω\"][pred_roles[i]]\n",
    "    print(f\" {i:3d}  | {true_name:12s} | {pred_name:16s} | {match}\")\n",
    "\n",
    "# –¢–µ—Å—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö\n",
    "print(\"\\nüîç –¢–µ—Å—Ç –Ω–∞ –≤–∞—à–∏—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å):\")\n",
    "v1, fv1 = extract_topology(shape1)\n",
    "g1 = build_graph(v1, fv1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)\n",
    "    roles1, _ = model(g1.x, g1.edge_index, batch1)\n",
    "    ref1 = find_reference_planes(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy())\n",
    "\n",
    "print(f\"   –ù–∞–π–¥–µ–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ —Ä–µ–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏: {len(ref1)}\")\n",
    "if len(ref1) >= 3:\n",
    "    print(\"‚úÖ –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º—É —Å–æ–≤–º–µ—â–µ–Ω–∏—é!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é:\n",
      "   –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 1: 3\n",
      "   –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 2: 3\n",
      "‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏!\n",
      "   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–º–µ—â–µ–Ω–∏–µ...\n",
      "\u001b[32;1m‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_with_gnn.step\n",
      "\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 2                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/results/aligned_with_gnn.step(882 ents)  Write  Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "model.load_state_dict(torch.load(\"gnn_best.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∞—à–∏—Ö —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–∏–∑ –Ω–æ—É—Ç–±—É–∫–∞)\n",
    "v1, fv1 = extract_topology(shape1)\n",
    "v2, fv2 = extract_topology(shape2)\n",
    "\n",
    "g1 = build_graph(v1, fv1)\n",
    "g2 = build_graph(v2, fv2)\n",
    "\n",
    "# –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–æ–ª–µ–π\n",
    "with torch.no_grad():\n",
    "    batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)\n",
    "    batch2 = torch.zeros(g2.x.size(0), dtype=torch.long)\n",
    "    roles1, _ = model(g1.x, g1.edge_index, batch1)\n",
    "    roles2, _ = model(g2.x, g2.edge_index, batch2)\n",
    "\n",
    "# –ü–æ–∏—Å–∫ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3)\n",
    "ref1 = find_reference_planes(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy())\n",
    "ref2 = find_reference_planes(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy())\n",
    "\n",
    "print(f\"\\nüîç –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é:\")\n",
    "print(f\"   –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 1: {len(ref1)}\")\n",
    "print(f\"   –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 2: {len(ref2)}\")\n",
    "\n",
    "if len(ref1) >= 3 and len(ref2) >= 3:\n",
    "    print(\"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç –æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏!\")\n",
    "    print(\"   –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ —Å–æ–≤–º–µ—â–µ–Ω–∏–µ...\")\n",
    "    \n",
    "    # –°–æ–≤–º–µ—â–µ–Ω–∏–µ (–≤–∞—à–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è —Ñ—É–Ω–∫—Ü–∏—è)\n",
    "    R_mat, t_vec = align_with_umeyama(ref1[:3], ref2[:3])\n",
    "    \n",
    "    # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è (–≤–∞—à —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫–æ–¥)\n",
    "    from OCC.Core.gp import gp_Trsf\n",
    "    from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "    \n",
    "    trsf = gp_Trsf()\n",
    "    trsf.SetValues(\n",
    "        float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),\n",
    "        float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),\n",
    "        float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])\n",
    "    )\n",
    "    \n",
    "    transform = BRepBuilderAPI_Transform(shape2, trsf)\n",
    "    shape2_aligned = transform.Shape()\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "    os.makedirs(\"outputs/results\", exist_ok=True)\n",
    "    writer = STEPControl_Writer()\n",
    "    writer.Transfer(shape2_aligned, STEPControl_AsIs)\n",
    "    writer.Write(\"outputs/results/aligned_with_gnn.step\")\n",
    "    \n",
    "    print(\"‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_with_gnn.step\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞—Ö–æ–¥–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\")\n",
    "    print(\"   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:\")\n",
    "    print(\"   ‚Ä¢ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ –ø—Ä–æ—Å—Ç—ã—Ö —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö\")\n",
    "    print(\"   ‚Ä¢ –†–µ–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ —Å–ª–æ–∂–Ω–µ–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö\")\n",
    "    print(\"   ‚Ä¢ –ù—É–∂–Ω–æ –¥–æ–æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ 500+ –º–æ–¥–µ–ª—è—Ö –∏–ª–∏ –¥–æ–±–∞–≤–∏—Ç—å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)\n",
    "model.load_state_dict(torch.load(\"gnn_best.pth\", map_location='cpu'))\n",
    "model.eval()\n",
    "\n",
    "# –¢–µ—Å—Ç –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "test_data = dataset[0]\n",
    "with torch.no_grad():\n",
    "    batch = torch.zeros(test_data.x.size(0), dtype=torch.long)\n",
    "    roles_pred, _ = model(test_data.x, test_data.edge_index, batch)\n",
    "    pred_classes = roles_pred.argmax(dim=1)\n",
    "\n",
    "# –ü–æ–¥—Å—á—ë—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3) —Å—Ä–µ–¥–∏ –≥—Ä–∞–Ω–µ–π\n",
    "face_mask = (test_data.node_type == 1)\n",
    "ref_planes_found = (pred_classes[face_mask] == 3).sum().item()\n",
    "total_faces = face_mask.sum().item()\n",
    "\n",
    "print(f\"\\nüîç –¢–µ—Å—Ç –Ω–∞ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞:\")\n",
    "print(f\"   –í—Å–µ–≥–æ –≥—Ä–∞–Ω–µ–π: {total_faces}\")\n",
    "print(f\"   –ù–∞–π–¥–µ–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3): {ref_planes_found}\")\n",
    "print(f\"   –ü—Ä–æ—Ü–µ–Ω—Ç –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π: {ref_planes_found / total_faces * 100:.1f}%\")\n",
    "print(f\"   {'‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (‚â•3)' if ref_planes_found >= 3 else '‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è –°–æ–≤–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reference_planes(role_probs, node_types, coords, top_k=3):\n",
    "    face_mask = (node_types == 1)\n",
    "    if not np.any(face_mask):\n",
    "        return np.array([])\n",
    "    \n",
    "    ref_scores = role_probs[face_mask, 3]  # –∏–Ω–¥–µ–∫—Å 3 = reference_plane\n",
    "    top_indices = np.argsort(-ref_scores)[:top_k]\n",
    "    face_indices = np.where(face_mask)[0][top_indices]\n",
    "    return coords[face_indices]\n",
    "\n",
    "def align_with_umeyama(src_pts, tgt_pts):\n",
    "    assert src_pts.shape == tgt_pts.shape and src_pts.shape[0] >= 3\n",
    "    \n",
    "    src_mean = src_pts.mean(axis=0)\n",
    "    tgt_mean = tgt_pts.mean(axis=0)\n",
    "    src_c = src_pts - src_mean\n",
    "    tgt_c = tgt_pts - tgt_mean\n",
    "    \n",
    "    H = src_c.T @ tgt_c\n",
    "    U, S, Vt = np.linalg.svd(H)\n",
    "    R_opt = Vt.T @ U.T\n",
    "    \n",
    "    if np.linalg.det(R_opt) < 0:\n",
    "        Vt[-1, :] *= -1\n",
    "        R_opt = Vt.T @ U.T\n",
    "        \n",
    "    t_opt = tgt_mean - R_opt @ src_mean\n",
    "    return R_opt, t_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –∑–∞–ø—É—Å–∫ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–æ–¥–µ–ª—å 1: 34 —É–∑–ª–æ–≤\n",
      "–ú–æ–¥–µ–ª—å 2: 34 —É–∑–ª–æ–≤\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏\n",
    "v1, fv1 = extract_topology(shape1)\n",
    "v2, fv2 = extract_topology(shape2)\n",
    "\n",
    "# –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤\n",
    "g1 = build_graph(v1, fv1)\n",
    "g2 = build_graph(v2, fv2)\n",
    "\n",
    "print(f\"–ú–æ–¥–µ–ª—å 1: {g1.x.size(0)} —É–∑–ª–æ–≤\")\n",
    "print(f\"–ú–æ–¥–µ–ª—å 2: {g2.x.size(0)} —É–∑–ª–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\n",
      "\n",
      "üéØ –ú–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: 1.000\n"
     ]
    }
   ],
   "source": [
    "# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏\n",
    "model = GNNModel()\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∑–∫–∞ –≤–µ—Å–æ–≤ \n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"gnn_best.pth\", map_location='cpu'))\n",
    "    print(\"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞.\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# –ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "with torch.no_grad():\n",
    "    batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)\n",
    "    batch2 = torch.zeros(g2.x.size(0), dtype=torch.long)\n",
    "    roles1, emb1 = model(g1.x, g1.edge_index, batch1)\n",
    "    roles2, emb2 = model(g2.x, g2.edge_index, batch2)\n",
    "\n",
    "# –ú–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏\n",
    "similarity = float(torch.cosine_similarity(emb1, emb2).item())\n",
    "print(f\"\\nüéØ –ú–µ—Ç—Ä–∏–∫–∞ —Å—Ö–æ–∂–µ—Å—Ç–∏: {similarity:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "—Å–æ–≤–º–µ—â–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\n",
      "–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞:\n",
      "[[-0.46977624 -0.20261793  0.85921836]\n",
      " [ 0.611248   -0.7769023   0.15099236]\n",
      " [ 0.636935    0.5961281   0.48882005]]\n",
      "–í–µ–∫—Ç–æ—Ä —Å–¥–≤–∏–≥–∞: [ 0.65383744 -0.5989876  -0.61852497]\n"
     ]
    }
   ],
   "source": [
    "# –°–æ–≤–º–µ—â–µ–Ω–∏–µ\n",
    "ref1 = find_reference_planes(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy())\n",
    "ref2 = find_reference_planes(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy())\n",
    "\n",
    "if len(ref1) >= 3 and len(ref2) >= 3:\n",
    "    R_mat, t_vec = align_with_umeyama(ref1[:3], ref2[:3])\n",
    "    print(\"—Å–æ–≤–º–µ—â–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\")\n",
    "else:\n",
    "    R_mat, t_vec = np.eye(3), np.zeros(3)\n",
    "    print(\"–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è\")\n",
    "\n",
    "print(f\"–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞:\\n{R_mat}\")\n",
    "print(f\"–í–µ–∫—Ç–æ—Ä —Å–¥–≤–∏–≥–∞: {t_vec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6Ô∏è –≠–∫—Å–ø–æ—Ä—Ç —Å–æ–≤–º–µ—â—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 2                      ******\u001b[0m\n",
      "\n",
      "‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ outputs/results/aligned_model.step\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/results/aligned_model.step(882 ents)  Write  Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "from OCC.Core.gp import gp_Trsf\n",
    "from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "import os\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "os.makedirs(\"outputs/results\", exist_ok=True)\n",
    "\n",
    "# –°–æ–∑–¥–∞—ë–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (–¢–û–õ–¨–ö–û 12 –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤: 3√ó4 –º–∞—Ç—Ä–∏—Ü–∞)\n",
    "trsf = gp_Trsf()\n",
    "trsf.SetValues(\n",
    "    float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),\n",
    "    float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),\n",
    "    float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])\n",
    ")\n",
    "\n",
    "# –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\n",
    "transform = BRepBuilderAPI_Transform(shape2, trsf)\n",
    "shape2_aligned = transform.Shape()\n",
    "\n",
    "# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ\n",
    "writer = STEPControl_Writer()\n",
    "writer.Transfer(shape2_aligned, STEPControl_AsIs)\n",
    "status = writer.Write(\"outputs/results/aligned_model.step\")\n",
    "\n",
    "if status == 1:  # IFSelect_RetDone\n",
    "    print(\"\\n‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ outputs/results/aligned_model.step\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ STEP-—Ñ–∞–π–ª–∞ (–∫–æ–¥ —Å—Ç–∞—Ç—É—Å–∞: {status})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_intersection(shape1, shape2, tolerance=1e-3):\n",
    "    \"\"\"–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –ª–∏ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\"\"\"\n",
    "    from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape\n",
    "    from OCC.Core.gp import gp_Pnt\n",
    "    \n",
    "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—è–º–∏\n",
    "    dist_checker = BRepExtrema_DistShapeShape(shape1, shape2)\n",
    "    dist_checker.Perform()\n",
    "    \n",
    "    if dist_checker.IsDone():\n",
    "        min_dist = dist_checker.Value()\n",
    "        print(f\"üîç –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏: {min_dist:.6f} –º–º\")\n",
    "        if min_dist < tolerance:\n",
    "            print(\"‚úÖ –ú–æ–¥–µ–ª–∏ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è ‚Äî –º–æ–∂–Ω–æ –≤—ã–ø–æ–ª–Ω—è—Ç—å –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –ù–ï –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è ‚Äî —É–≤–µ–ª–∏—á—å—Ç–µ —Å–¥–≤–∏–≥/–ø–æ–≤–æ—Ä–æ—Ç\")\n",
    "        return min_dist\n",
    "    else:\n",
    "        print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏: 20.950899 –º–º\n",
      "‚ö†Ô∏è –ú–æ–¥–µ–ª–∏ –ù–ï –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è ‚Äî —É–≤–µ–ª–∏—á—å—Ç–µ —Å–¥–≤–∏–≥/–ø–æ–≤–æ—Ä–æ—Ç\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20.950898684766774"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è\n",
    "check_intersection(shape1, shape2_aligned, tolerance=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –ë—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Cut, BRepAlgoAPI_Fuse\n",
    "from OCC.Core.TopExp import TopExp_Explorer\n",
    "from OCC.Core.TopAbs import TopAbs_SOLID\n",
    "from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "import os\n",
    "\n",
    "def get_solid(shape):\n",
    "    \"\"\"–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤–æ–µ —Ç–≤–µ—Ä–¥–æ–µ —Ç–µ–ª–æ (Solid) –∏–∑ —Ñ–æ—Ä–º—ã\"\"\"\n",
    "    explorer = TopExp_Explorer(shape, TopAbs_SOLID)\n",
    "    if explorer.More():\n",
    "        return explorer.Current()  # –í –≤–∞—à–µ–π –≤–µ—Ä—Å–∏–∏ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –Ω–µ —Ç—Ä–µ–±—É–µ—Ç—Å—è\n",
    "    else:\n",
    "        raise ValueError(\"–§–æ—Ä–º–∞ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–≤–µ—Ä–¥—ã—Ö —Ç–µ–ª (Solids). –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª —Å–æ–¥–µ—Ä–∂–∏—Ç –æ–±—ä–µ–º–Ω—É—é –≥–µ–æ–º–µ—Ç—Ä–∏—é.\")\n",
    "\n",
    "def boolean_symmetric_difference(shape1, shape2, tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    –í—ã—á–∏—Å–ª—è–µ—Ç —Å–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫—É—é —Ä–∞–∑–Ω–æ—Å—Ç—å: (A - B) ‚à™ (B - A)\n",
    "    –ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –í–°–ï —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏:\n",
    "      - –ö—Ä–∞—Å–Ω—ã–π: –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 1, –Ω–æ –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏ 2\n",
    "      - –°–∏–Ω–∏–π: –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 2, –Ω–æ –Ω–µ—Ç –≤ –º–æ–¥–µ–ª–∏ 1\n",
    "    \"\"\"\n",
    "    solid1 = get_solid(shape1)\n",
    "    solid2 = get_solid(shape2)\n",
    "    \n",
    "    try:\n",
    "        # –ß–∞—Å—Ç—å 1: —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 1, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –º–æ–¥–µ–ª–∏ 2\n",
    "        cut1 = BRepAlgoAPI_Cut(solid1, solid2)\n",
    "        cut1.SetFuzzyValue(tolerance)  # –£–ª—É—á—à–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–ª–∏–∑–∫–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π\n",
    "        if not cut1.IsDone():\n",
    "            print(\"‚ö†Ô∏è –í—ã—á–∏—Ç–∞–Ω–∏–µ (–º–æ–¥–µ–ª—å1 - –º–æ–¥–µ–ª—å2) –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\")\n",
    "            diff1 = None\n",
    "        else:\n",
    "            diff1 = cut1.Shape()\n",
    "        \n",
    "        # –ß–∞—Å—Ç—å 2: —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 2, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –º–æ–¥–µ–ª–∏ 1\n",
    "        cut2 = BRepAlgoAPI_Cut(solid2, solid1)\n",
    "        cut2.SetFuzzyValue(tolerance)\n",
    "        if not cut2.IsDone():\n",
    "            print(\"‚ö†Ô∏è –í—ã—á–∏—Ç–∞–Ω–∏–µ (–º–æ–¥–µ–ª—å2 - –º–æ–¥–µ–ª—å1) –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\")\n",
    "            diff2 = None\n",
    "        else:\n",
    "            diff2 = cut2.Shape()\n",
    "        \n",
    "        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–∞–∑–ª–∏—á–∏—è\n",
    "        if diff1 is None and diff2 is None:\n",
    "            raise RuntimeError(\"–û–±–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤—ã—á–∏—Ç–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –Ω–µ—É–¥–∞—á–µ–π\")\n",
    "        elif diff1 is None:\n",
    "            return diff2\n",
    "        elif diff2 is None:\n",
    "            return diff1\n",
    "        else:\n",
    "            fuse = BRepAlgoAPI_Fuse(diff1, diff2)\n",
    "            fuse.SetFuzzyValue(tolerance)\n",
    "            if fuse.IsDone():\n",
    "                return fuse.Shape()\n",
    "            else:\n",
    "                # –ï—Å–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±–µ —á–∞—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "                return (diff1, diff2)\n",
    "                \n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"–û—à–∏–±–∫–∞ –±—É–ª–µ–≤–æ–π –æ–ø–µ—Ä–∞—Ü–∏–∏: {str(e)}\\n\"\n",
    "                         f\"–°–æ–≤–µ—Ç: —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –ø–æ—Å–ª–µ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\")\n",
    "\n",
    "def save_step(shape, filename):\n",
    "    \"\"\"–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ñ–æ—Ä–º—É –≤ STEP-—Ñ–∞–π–ª\"\"\"\n",
    "    os.makedirs(os.path.dirname(filename) or \".\", exist_ok=True)\n",
    "    writer = STEPControl_Writer()\n",
    "    writer.Transfer(shape, STEPControl_AsIs)\n",
    "    status = writer.Write(filename)\n",
    "    return status == 1  # IFSelect_RetDone = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏...\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "‚úÖ –í—Å–µ —Ä–∞–∑–ª–∏—á–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: outputs/results/differences_combined.step\n",
      "üí° –°–æ–≤–µ—Ç: –æ—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª –≤ FreeCAD –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ —Ü–≤–µ—Ç–æ–≤—É—é —Ä–∞—Å–∫—Ä–∞—Å–∫—É:\n",
      "   - –ö—Ä–∞—Å–Ω—ã–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏\n",
      "   - –°–∏–Ω–∏–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/results/differences_combined.step(2982 ents)  Write  Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# === –ë—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏—á–∏–π ===\n",
    "print(\"\\nüîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏...\")\n",
    "\n",
    "try:\n",
    "    # –°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å ‚Äî –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –í–°–ï –æ—Ç–ª–∏—á–∏—è\n",
    "    diff = boolean_symmetric_difference(shape1, shape2_aligned)\n",
    "    \n",
    "    if isinstance(diff, tuple):\n",
    "        # –ï—Å–ª–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –Ω–µ —É–¥–∞–ª–æ—Å—å ‚Äî —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–µ —á–∞—Å—Ç–∏ –æ—Ç–¥–µ–ª—å–Ω–æ\n",
    "        save_step(diff[0], \"outputs/results/differences_model1_only.step\")\n",
    "        save_step(diff[1], \"outputs/results/differences_model2_only.step\")\n",
    "        print(\"‚úÖ –†–∞–∑–ª–∏—á–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –¥–≤—É—Ö —Ñ–∞–π–ª–∞—Ö:\")\n",
    "        print(\"   - differences_model1_only.step : —ç–ª–µ–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –≤ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏\")\n",
    "        print(\"   - differences_model2_only.step : —ç–ª–µ–º–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –≤–æ –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏\")\n",
    "    else:\n",
    "        save_step(diff, \"outputs/results/differences_combined.step\")\n",
    "        print(\"‚úÖ –í—Å–µ —Ä–∞–∑–ª–∏—á–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: outputs/results/differences_combined.step\")\n",
    "        print(\"üí° –°–æ–≤–µ—Ç: –æ—Ç–∫—Ä–æ–π—Ç–µ —Ñ–∞–π–ª –≤ FreeCAD –∏ –ø—Ä–∏–º–µ–Ω–∏—Ç–µ —Ü–≤–µ—Ç–æ–≤—É—é —Ä–∞—Å–∫—Ä–∞—Å–∫—É:\")\n",
    "        print(\"   - –ö—Ä–∞—Å–Ω—ã–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏\")\n",
    "        print(\"   - –°–∏–Ω–∏–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –≤—Ç–æ—Ä–æ–π –º–æ–¥–µ–ª–∏\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏: {e}\")\n",
    "    print(\"   –ü—Ä–∏—á–∏–Ω—ã –º–æ–≥—É—Ç –±—ã—Ç—å:\")\n",
    "    print(\"   ‚Ä¢ –ú–æ–¥–µ–ª–∏ –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è –ø–æ—Å–ª–µ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\")\n",
    "    print(\"   ‚Ä¢ –ì–µ–æ–º–µ—Ç—Ä–∏—è —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–µ—Ñ–µ–∫—Ç—ã (–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –Ω–æ—Ä–º–∞–ª–∏, —Å–∞–º–æ–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è)\")\n",
    "    print(\"   ‚Ä¢ –¢—Ä–µ–±—É–µ—Ç—Å—è —É–≤–µ–ª–∏—á–∏—Ç—å –ø–∞—Ä–∞–º–µ—Ç—Ä tolerance –≤ —Ñ—É–Ω–∫—Ü–∏–∏\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# —Å–¥–µ–ª–∞—Ç—å \n",
    "- –î–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ —Å–æ–∑–¥–∞–π—Ç–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ (–ø—Ä–∏–º–µ—Ä –≤ README)\n",
    "-  –†–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–∂–Ω–æ –æ—Ç–∫—Ä—ã—Ç—å –≤ FreeCAD –∏–ª–∏ –ª—é–±–æ–π CAD-—Å–∏—Å—Ç–µ–º–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_large_planes(shape, min_area=100.0, max_planes=5):\n",
    "    \"\"\"\n",
    "    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å pythonocc-core 7.9.0)\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    shape : TopoDS_Shape\n",
    "        CAD-–º–æ–¥–µ–ª—å –≤ —Ñ–æ—Ä–º–∞—Ç–µ STEP\n",
    "    min_area : float\n",
    "        –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø–ª–æ—â–∞–¥—å –≥—Ä–∞–Ω–∏ –¥–ª—è –≤–∫–ª—é—á–µ–Ω–∏—è (–º–º¬≤)\n",
    "    max_planes : int\n",
    "        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    list[dict] : –°–ø–∏—Å–æ–∫ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π —Å –∫–ª—é—á–∞–º–∏:\n",
    "        - 'area': –ø–ª–æ—â–∞–¥—å –≥—Ä–∞–Ω–∏ (–º–º¬≤)\n",
    "        - 'center': —Ü–µ–Ω—Ç—Ä–æ–∏–¥ –≥—Ä–∞–Ω–∏ (np.array[3])\n",
    "        - 'normal': –Ω–æ—Ä–º–∞–ª—å –∫ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (np.array[3])\n",
    "    \"\"\"\n",
    "    from OCC.Core.TopExp import TopExp_Explorer\n",
    "    from OCC.Core.TopAbs import TopAbs_FACE\n",
    "    from OCC.Core.BRep import BRep_Tool\n",
    "    from OCC.Core.BRepGProp import brepgprop_SurfaceProperties  # –°—Ç–∞—Ä—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0\n",
    "    from OCC.Core.GProp import GProp_GProps\n",
    "    from OCC.Core.Geom import Geom_Plane\n",
    "    from OCC.Core.gp import gp_Pnt\n",
    "    import numpy as np\n",
    "    \n",
    "    planes = []\n",
    "    explorer = TopExp_Explorer(shape, TopAbs_FACE)\n",
    "    \n",
    "    while explorer.More():\n",
    "        face = explorer.Current()  # –†–∞–±–æ—Ç–∞–µ–º –Ω–∞–ø—Ä—è–º—É—é —Å TopoDS_Shape (–±–µ–∑ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤!)\n",
    "        \n",
    "        # –ü—Ä–æ–≤–µ—Ä–∫–∞: –ø–ª–æ—Å–∫–∞—è –ª–∏ –≥—Ä–∞–Ω—å?\n",
    "        surface = BRep_Tool.Surface(face)\n",
    "        if not surface.IsKind(\"Geom_Plane\"):\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø–ª–æ—â–∞–¥–∏ –≥—Ä–∞–Ω–∏ (—Å—Ç–∞—Ä—ã–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å ‚Äî —Ä–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –≤ 7.9.0)\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
    "        area = props.Mass()\n",
    "        \n",
    "        if area < min_area:\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        # –¶–µ–Ω—Ç—Ä–æ–∏–¥ –≥—Ä–∞–Ω–∏\n",
    "        cog = props.CentreOfMass()\n",
    "        \n",
    "        # –ù–æ—Ä–º–∞–ª—å –∫ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (–±–µ–∑ IsNull ‚Äî –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ try/except)\n",
    "        try:\n",
    "            plane = Geom_Plane.DownCast(surface)\n",
    "            # –í 7.9.0 DownCast –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç, –¥–∞–∂–µ –µ—Å–ª–∏ –∫–∞—Å—Ç –Ω–µ —É–¥–∞–ª—Å—è\n",
    "            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ –¥–æ—Å—Ç—É–ø –∫ –º–µ—Ç–æ–¥–∞–º\n",
    "            normal = plane.Axis().Direction()\n",
    "        except:\n",
    "            explorer.Next()\n",
    "            continue\n",
    "        \n",
    "        planes.append({\n",
    "            'area': area,\n",
    "            'center': np.array([cog.X(), cog.Y(), cog.Z()]),\n",
    "            'normal': np.array([normal.X(), normal.Y(), normal.Z()])\n",
    "        })\n",
    "        \n",
    "        explorer.Next()\n",
    "    \n",
    "    # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –ø–ª–æ—â–∞–¥–∏ (–∫—Ä—É–ø–Ω–µ–π—à–∏–µ –ø–µ—Ä–≤—ã–º–∏)\n",
    "    planes.sort(key=lambda x: x['area'], reverse=True)\n",
    "    return planes[:max_planes]\n",
    "\n",
    "\n",
    "def evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000):\n",
    "    \"\"\"\n",
    "    –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ –≤–µ—Ä—à–∏–Ω—ã (–±–µ–∑ —Å–ª–æ–∂–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ —Ç–æ—á–µ–∫)\n",
    "    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç –≤–∞—à—É —Ä–∞–±–æ—á—É—é —Ñ—É–Ω–∫—Ü–∏—é extract_topology\n",
    "    \n",
    "    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "    ----------\n",
    "    shape1 : TopoDS_Shape\n",
    "        –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å (—Ü–µ–ª—å)\n",
    "    shape2_aligned : TopoDS_Shape\n",
    "        –í—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\n",
    "    n_max_vertices : int\n",
    "        –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —á–∏—Å–ª–æ –≤–µ—Ä—à–∏–Ω –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:\n",
    "    -----------\n",
    "    dict : –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\n",
    "    \"\"\"\n",
    "    from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape\n",
    "    import numpy as np\n",
    "    from scipy.spatial import cKDTree\n",
    "    \n",
    "    # –®–∞–≥ 1: –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –•–∞—É—Å–¥–æ—Ä—Ñ–∞ (–±—ã—Å—Ç—Ä–∞—è –æ—Ü–µ–Ω–∫–∞)\n",
    "    dist_checker = BRepExtrema_DistShapeShape()\n",
    "    dist_checker.LoadS1(shape1)\n",
    "    dist_checker.LoadS2(shape2_aligned)\n",
    "    dist_checker.Perform()\n",
    "    \n",
    "    if not dist_checker.IsDone():\n",
    "        return {'success': False, 'error': '–†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è'}\n",
    "    \n",
    "    min_dist = dist_checker.Value()\n",
    "    \n",
    "    # –®–∞–≥ 2: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω —á–µ—Ä–µ–∑ –í–ê–®–£ —Ä–∞–±–æ—á—É—é —Ñ—É–Ω–∫—Ü–∏—é extract_topology\n",
    "    vertices1, _ = extract_topology(shape1)\n",
    "    vertices2, _ = extract_topology(shape2_aligned)\n",
    "    \n",
    "    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –≤–µ—Ä—à–∏–Ω –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏\n",
    "    if len(vertices1) > n_max_vertices:\n",
    "        indices = np.random.choice(len(vertices1), n_max_vertices, replace=False)\n",
    "        vertices1 = vertices1[indices]\n",
    "    if len(vertices2) > n_max_vertices:\n",
    "        indices = np.random.choice(len(vertices2), n_max_vertices, replace=False)\n",
    "        vertices2 = vertices2[indices]\n",
    "    \n",
    "    if len(vertices1) == 0 or len(vertices2) == 0:\n",
    "        return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–µ—Ä—à–∏–Ω—ã'}\n",
    "    \n",
    "    # –®–∞–≥ 3: –†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Ç–æ—á–µ–∫\n",
    "    tree2 = cKDTree(vertices2)\n",
    "    dists12, _ = tree2.query(vertices1, k=1)\n",
    "    \n",
    "    tree1 = cKDTree(vertices1)\n",
    "    dists21, _ = tree1.query(vertices2, k=1)\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞\n",
    "    hausdorff_sym = max(dists12.max(), dists21.max())\n",
    "    mean_dist = (dists12.mean() + dists21.mean()) / 2.0\n",
    "    \n",
    "    return {\n",
    "        'success': True,\n",
    "        'hausdorff_min': min_dist,\n",
    "        'hausdorff_symmetric': hausdorff_sym,\n",
    "        'mean_distance': mean_dist,\n",
    "        'max_distance': max(dists12.max(), dists21.max()),\n",
    "        'rms_distance': np.sqrt((dists12**2).mean()),\n",
    "        'inlier_ratio_0.1mm': (dists12 < 0.1).mean(),\n",
    "        'inlier_ratio_0.5mm': (dists12 < 0.5).mean(),\n",
    "        'inlier_ratio_1.0mm': (dists12 < 1.0).mean(),\n",
    "        'sample_count': len(vertices1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ù–∞–π–¥–µ–Ω–æ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 1: 5\n",
      "–ù–∞–π–¥–µ–Ω–æ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 2: 5\n",
      "  –ü–ª–æ—Å–∫–æ—Å—Ç—å 1: –ø–ª–æ—â–∞–¥—å=4842.9 –º–º¬≤, —Ü–µ–Ω—Ç—Ä=[32.63397457 28.74798519 22.61988315]\n",
      "  –ü–ª–æ—Å–∫–æ—Å—Ç—å 2: –ø–ª–æ—â–∞–¥—å=2171.5 –º–º¬≤, —Ü–µ–Ω—Ç—Ä=[46.08245502 33.49638683 48.26793349]\n",
      "  –ü–ª–æ—Å–∫–æ—Å—Ç—å 3: –ø–ª–æ—â–∞–¥—å=2171.5 –º–º¬≤, —Ü–µ–Ω—Ç—Ä=[ 5.63086121 25.47563883 11.60375637]\n",
      "\n",
      "‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ –æ–ø–æ—Ä–Ω—ã–º –ø–ª–æ—Å–∫–æ—Å—Ç—è–º –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\n",
      "–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞:\n",
      "[[-0.79367806 -0.42209879 -0.43807277]\n",
      " [ 0.01031397 -0.7293473   0.68406589]\n",
      " [-0.60825058  0.53840982  0.58322046]]\n",
      "–í–µ–∫—Ç–æ—Ä —Å–¥–≤–∏–≥–∞: [ 92.93298127  12.81374282 -20.57567155]\n",
      "\n",
      "üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è...\n",
      "   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞:      61.3314 –º–º\n",
      "   –ú–∞–∫—Å. –æ—à–∏–±–∫–∞:        87.5443 –º–º\n",
      "   RMS –æ—à–∏–±–∫–∞:          61.6722 –º–º\n",
      "   –¢–æ—á–µ–∫ < 0.1 –º–º:      0.0%\n",
      "   –¢–æ—á–µ–∫ < 1.0 –º–º:      0.0%\n",
      "\n",
      "‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_by_planes.step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/3267780437.py:44: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(face, props)  # ‚Üê —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ 7.9.0 –∏–∑ conda-forge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 2                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/results/aligned_by_planes.step(890 ents)  Write  Done\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# 1. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –±–µ–∑ GNN\n",
    "planes1 = extract_large_planes(shape1, min_area=50.0, max_planes=5)\n",
    "planes2 = extract_large_planes(shape2, min_area=50.0, max_planes=5)\n",
    "\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 1: {len(planes1)}\")\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –≤ –º–æ–¥–µ–ª–∏ 2: {len(planes2)}\")\n",
    "\n",
    "# –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç—è—Ö\n",
    "for i, p in enumerate(planes1[:min(3, len(planes1))]):\n",
    "    print(f\"  –ü–ª–æ—Å–∫–æ—Å—Ç—å {i+1}: –ø–ª–æ—â–∞–¥—å={p['area']:.1f} –º–º¬≤, —Ü–µ–Ω—Ç—Ä={p['center']}\")\n",
    "\n",
    "# 2. –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ 3 –∫—Ä—É–ø–Ω–µ–π—à–∏–º –ø–ª–æ—Å–∫–æ—Å—Ç—è–º\n",
    "if len(planes1) >= 3 and len(planes2) >= 3:\n",
    "    src_pts = np.array([p['center'] for p in planes1[:3]])\n",
    "    tgt_pts = np.array([p['center'] for p in planes2[:3]])\n",
    "    \n",
    "    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤–∞—à—É —É–∂–µ –∏–º–µ—é—â—É—é—Å—è —Ñ—É–Ω–∫—Ü–∏—é align_with_umeyama\n",
    "    R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)\n",
    "    \n",
    "    print(\"\\n‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ –æ–ø–æ—Ä–Ω—ã–º –ø–ª–æ—Å–∫–æ—Å—Ç—è–º –≤—ã–ø–æ–ª–Ω–µ–Ω–æ\")\n",
    "    print(f\"–ú–∞—Ç—Ä–∏—Ü–∞ –ø–æ–≤–æ—Ä–æ—Ç–∞:\\n{R_mat}\")\n",
    "    print(f\"–í–µ–∫—Ç–æ—Ä —Å–¥–≤–∏–≥–∞: {t_vec}\")\n",
    "    \n",
    "    # 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è\n",
    "    from OCC.Core.gp import gp_Trsf\n",
    "    from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform\n",
    "    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "    import os\n",
    "    \n",
    "    trsf = gp_Trsf()\n",
    "    trsf.SetValues(\n",
    "        float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),\n",
    "        float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),\n",
    "        float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])\n",
    "    )\n",
    "    \n",
    "    transform = BRepBuilderAPI_Transform(shape2, trsf)\n",
    "    shape2_aligned = transform.Shape()\n",
    "    \n",
    "    # 4. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\n",
    "    print(\"\\nüìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è...\")\n",
    "    metrics = evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000)\n",
    "    \n",
    "    if metrics['success']:\n",
    "        print(f\"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞:      {metrics['mean_distance']:.4f} –º–º\")\n",
    "        print(f\"   –ú–∞–∫—Å. –æ—à–∏–±–∫–∞:        {metrics['max_distance']:.4f} –º–º\")\n",
    "        print(f\"   RMS –æ—à–∏–±–∫–∞:          {metrics['rms_distance']:.4f} –º–º\")\n",
    "        print(f\"   –¢–æ—á–µ–∫ < 0.1 –º–º:      {metrics['inlier_ratio_0.1mm']*100:.1f}%\")\n",
    "        print(f\"   –¢–æ—á–µ–∫ < 1.0 –º–º:      {metrics['inlier_ratio_1.0mm']*100:.1f}%\")\n",
    "        \n",
    "        # 5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞\n",
    "        os.makedirs(\"outputs/results\", exist_ok=True)\n",
    "        writer = STEPControl_Writer()\n",
    "        writer.Transfer(shape2_aligned, STEPControl_AsIs)\n",
    "        writer.Write(\"outputs/results/aligned_by_planes.step\")\n",
    "        print(\"\\n‚úÖ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_by_planes.step\")\n",
    "    else:\n",
    "        print(f\"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏: {metrics['error']}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (—Ç—Ä–µ–±—É–µ—Ç—Å—è –º–∏–Ω–∏–º—É–º 3)\")\n",
    "    print(\"   –°–æ–≤–µ—Ç—ã:\")\n",
    "    print(\"   ‚Ä¢ –£–º–µ–Ω—å—à–∏—Ç–µ min_area (–ø–æ–ø—Ä–æ–±—É–π—Ç–µ 10.0 –∏–ª–∏ –¥–∞–∂–µ 1.0)\")\n",
    "    print(\"   ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –º–æ–¥–µ–ª–∏ –≤ FreeCAD ‚Äî –µ—Å—Ç—å –ª–∏ –≤ –Ω–∏—Ö –ø–ª–æ—Å–∫–∏–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏?\")\n",
    "    print(\"   ‚Ä¢ –î–ª—è –º–æ–¥–µ–ª–µ–π –±–µ–∑ –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ —Ü–µ–Ω—Ç—Ä–æ–∏–¥–∞–º (—Å–º. –Ω–∏–∂–µ)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_solid(shape):\n",
    "    \"\"\"\n",
    "    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Ñ–æ—Ä–º—É –≤ —Ç–≤—ë—Ä–¥–æ–µ —Ç–µ–ª–æ (Solid), –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ.\n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π Solid –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω—É—é —Ñ–æ—Ä–º—É.\n",
    "    \"\"\"\n",
    "    from OCC.Core.TopExp import TopExp_Explorer\n",
    "    from OCC.Core.TopAbs import TopAbs_SOLID\n",
    "    from OCC.Core.TopoDS import topods_Solid\n",
    "    \n",
    "    explorer = TopExp_Explorer(shape, TopAbs_SOLID)\n",
    "    if explorer.More():\n",
    "        try:\n",
    "            return topods_Solid(explorer.Current())\n",
    "        except:\n",
    "            pass\n",
    "    return shape  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–∞–∫ –µ—Å—Ç—å (–º–æ–∂–µ—Ç –±—ã—Ç—å Shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "<>:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/2176951558.py:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def boolean_operations(shape1, shape2_aligned, tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ–≤–º–µ—â—ë–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:\n",
    "        - 'fuse': –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (A ‚à™ B)\n",
    "        - 'common': –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (A ‚à© B)\n",
    "        - 'diff1': —Ä–∞–∑–Ω–æ—Å—Ç—å (A \\ B) ‚Äî —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 1, –Ω–æ –Ω–µ—Ç –≤–æ 2\n",
    "        - 'diff2': —Ä–∞–∑–Ω–æ—Å—Ç—å (B \\ A) ‚Äî —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 2, –Ω–æ –Ω–µ—Ç –≤ 1\n",
    "        - 'symdiff': —Å–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å ‚Äî –í–°–ï —Ä–∞–∑–ª–∏—á–∏—è\n",
    "    \"\"\"\n",
    "    from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Fuse, BRepAlgoAPI_Common, BRepAlgoAPI_Cut\n",
    "    from OCC.Core.TopoDS import TopoDS_Solid\n",
    "    import numpy as np\n",
    "    \n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ç–≤—ë—Ä–¥—ã–µ —Ç–µ–ª–∞\n",
    "    solid1 = ensure_solid(shape1)\n",
    "    solid2 = ensure_solid(shape2_aligned)\n",
    "    \n",
    "    results = {}\n",
    "    errors = []\n",
    "    \n",
    "    # 1. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (A ‚à™ B)\n",
    "    try:\n",
    "        fuse = BRepAlgoAPI_Fuse(solid1, solid2)\n",
    "        fuse.SetFuzzyValue(tolerance)  # –£–ª—É—á—à–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–ª–∏–∑–∫–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π\n",
    "        if fuse.IsDone():\n",
    "            results['fuse'] = fuse.Shape()\n",
    "        else:\n",
    "            errors.append(\"fuse\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"fuse: {str(e)}\")\n",
    "    \n",
    "    # 2. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (A ‚à© B)\n",
    "    try:\n",
    "        common = BRepAlgoAPI_Common(solid1, solid2)\n",
    "        common.SetFuzzyValue(tolerance)\n",
    "        if common.IsDone():\n",
    "            results['common'] = common.Shape()\n",
    "        else:\n",
    "            errors.append(\"common\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"common: {str(e)}\")\n",
    "    \n",
    "    # 3. –†–∞–∑–Ω–æ—Å—Ç—å (A \\ B) ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 1\n",
    "    try:\n",
    "        cut1 = BRepAlgoAPI_Cut(solid1, solid2)\n",
    "        cut1.SetFuzzyValue(tolerance)\n",
    "        if cut1.IsDone():\n",
    "            results['diff1'] = cut1.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff1\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff1: {str(e)}\")\n",
    "    \n",
    "    # 4. –†–∞–∑–Ω–æ—Å—Ç—å (B \\ A) ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 2\n",
    "    try:\n",
    "        cut2 = BRepAlgoAPI_Cut(solid2, solid1)\n",
    "        cut2.SetFuzzyValue(tolerance)\n",
    "        if cut2.IsDone():\n",
    "            results['diff2'] = cut2.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff2\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff2: {str(e)}\")\n",
    "    \n",
    "    # 5. –°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å = (A\\B) ‚à™ (B\\A)\n",
    "    if 'diff1' in results and 'diff2' in results:\n",
    "        try:\n",
    "            symdiff = BRepAlgoAPI_Fuse(results['diff1'], results['diff2'])\n",
    "            symdiff.SetFuzzyValue(tolerance)\n",
    "            if symdiff.IsDone():\n",
    "                results['symdiff'] = symdiff.Shape()\n",
    "        except:\n",
    "            pass  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–∞–∑–ª–∏—á–∏—è\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö\n",
    "    results['errors'] = errors if errors else None\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_volumes(shape):\n",
    "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—ä—ë–º –∏ –ø–ª–æ—â–∞–¥—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—ã\"\"\"\n",
    "    from OCC.Core.GProp import GProp_GProps\n",
    "    from OCC.Core.BRepGProp import brepgprop_VolumeProperties, brepgprop_SurfaceProperties\n",
    "    \n",
    "    volume = 0.0\n",
    "    area = 0.0\n",
    "    \n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_VolumeProperties(shape, props)\n",
    "        volume = props.Mass()\n",
    "    except:\n",
    "        pass  # –î–ª—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π –æ–±—ä—ë–º = 0\n",
    "    \n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_SurfaceProperties(shape, props)\n",
    "        area = props.Mass()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return volume, area\n",
    "\n",
    "\n",
    "def analyze_differences(shape1, shape2_aligned, tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏:\n",
    "    - –û–±—ä—ë–º—ã —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —á–∞—Å—Ç–µ–π\n",
    "    - –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑–ª–∏—á–∏–π –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –æ–±—â–µ–π –º–æ–¥–µ–ª–∏\n",
    "    - –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏\n",
    "    \"\"\"\n",
    "    results = boolean_operations(shape1, shape2_aligned, tolerance)\n",
    "    \n",
    "    if results['errors']:\n",
    "        print(\"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –ø—Ä–∏ –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏—è—Ö:\")\n",
    "        for err in results['errors']:\n",
    "            print(f\"   ‚Ä¢ {err}\")\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—ä—ë–º—ã\n",
    "    vol1, area1 = compute_volumes(shape1)\n",
    "    vol2, area2 = compute_volumes(shape2_aligned)\n",
    "    \n",
    "    vol_diff1 = compute_volumes(results['diff1'])[0] if 'diff1' in results else 0.0\n",
    "    vol_diff2 = compute_volumes(results['diff2'])[0] if 'diff2' in results else 0.0\n",
    "    vol_common = compute_volumes(results['common'])[0] if 'common' in results else 0.0\n",
    "    \n",
    "    # –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑–ª–∏—á–∏–π\n",
    "    total_vol = max(vol1, vol2)\n",
    "    diff_percent = ((vol_diff1 + vol_diff2) / total_vol * 100) if total_vol > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'volume_model1': vol1,\n",
    "        'volume_model2': vol2,\n",
    "        'volume_unique_to_1': vol_diff1,\n",
    "        'volume_unique_to_2': vol_diff2,\n",
    "        'volume_common': vol_common,\n",
    "        'difference_percent': diff_percent,\n",
    "        'results': results\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "<>:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:2: DeprecationWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "def boolean_operations(shape1, shape2_aligned, tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    –í—ã–ø–æ–ª–Ω—è–µ—Ç –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è —Å–æ–≤–º–µ—â—ë–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "    (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å pythonocc-core 7.9.0 –±–µ–∑ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤)\n",
    "    \n",
    "    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ª–æ–≤–∞—Ä—å —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏:\n",
    "        - 'fuse': –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (A ‚à™ B)\n",
    "        - 'common': –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (A ‚à© B)\n",
    "        - 'diff1': —Ä–∞–∑–Ω–æ—Å—Ç—å (A \\ B) ‚Äî —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 1, –Ω–æ –Ω–µ—Ç –≤–æ 2\n",
    "        - 'diff2': —Ä–∞–∑–Ω–æ—Å—Ç—å (B \\ A) ‚Äî —á—Ç–æ –µ—Å—Ç—å –≤ –º–æ–¥–µ–ª–∏ 2, –Ω–æ –Ω–µ—Ç –≤ 1\n",
    "        - 'symdiff': —Å–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å ‚Äî –í–°–ï —Ä–∞–∑–ª–∏—á–∏—è\n",
    "    \"\"\"\n",
    "    from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Fuse, BRepAlgoAPI_Common, BRepAlgoAPI_Cut\n",
    "    \n",
    "    results = {}\n",
    "    errors = []\n",
    "    \n",
    "    # 1. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ (A ‚à™ B)\n",
    "    try:\n",
    "        fuse = BRepAlgoAPI_Fuse(shape1, shape2_aligned)\n",
    "        fuse.SetFuzzyValue(tolerance)  # –£–ª—É—á—à–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å –¥–ª—è –±–ª–∏–∑–∫–∏—Ö –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π\n",
    "        if fuse.IsDone():\n",
    "            results['fuse'] = fuse.Shape()\n",
    "        else:\n",
    "            errors.append(\"fuse: –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"fuse: {str(e)}\")\n",
    "    \n",
    "    # 2. –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ (A ‚à© B)\n",
    "    try:\n",
    "        common = BRepAlgoAPI_Common(shape1, shape2_aligned)\n",
    "        common.SetFuzzyValue(tolerance)\n",
    "        if common.IsDone():\n",
    "            results['common'] = common.Shape()\n",
    "        else:\n",
    "            errors.append(\"common: –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"common: {str(e)}\")\n",
    "    \n",
    "    # 3. –†–∞–∑–Ω–æ—Å—Ç—å (A \\ B) ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 1\n",
    "    try:\n",
    "        cut1 = BRepAlgoAPI_Cut(shape1, shape2_aligned)\n",
    "        cut1.SetFuzzyValue(tolerance)\n",
    "        if cut1.IsDone():\n",
    "            results['diff1'] = cut1.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff1: –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff1: {str(e)}\")\n",
    "    \n",
    "    # 4. –†–∞–∑–Ω–æ—Å—Ç—å (B \\ A) ‚Äî —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 2\n",
    "    try:\n",
    "        cut2 = BRepAlgoAPI_Cut(shape2_aligned, shape1)\n",
    "        cut2.SetFuzzyValue(tolerance)\n",
    "        if cut2.IsDone():\n",
    "            results['diff2'] = cut2.Shape()\n",
    "        else:\n",
    "            errors.append(\"diff2: –æ–ø–µ—Ä–∞—Ü–∏—è –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞\")\n",
    "    except Exception as e:\n",
    "        errors.append(f\"diff2: {str(e)}\")\n",
    "    \n",
    "    # 5. –°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å = (A\\B) ‚à™ (B\\A)\n",
    "    if 'diff1' in results and 'diff2' in results:\n",
    "        try:\n",
    "            symdiff = BRepAlgoAPI_Fuse(results['diff1'], results['diff2'])\n",
    "            symdiff.SetFuzzyValue(tolerance)\n",
    "            if symdiff.IsDone():\n",
    "                results['symdiff'] = symdiff.Shape()\n",
    "        except:\n",
    "            pass  # –ù–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ä–∞–∑–ª–∏—á–∏—è\n",
    "    \n",
    "    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–∞—Ö\n",
    "    if errors:\n",
    "        results['errors'] = errors\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_volumes(shape):\n",
    "    \"\"\"–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—ä—ë–º –∏ –ø–ª–æ—â–∞–¥—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ —Ñ–æ—Ä–º—ã (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º TopoDS_Shape)\"\"\"\n",
    "    from OCC.Core.GProp import GProp_GProps\n",
    "    from OCC.Core.BRepGProp import brepgprop_VolumeProperties, brepgprop_SurfaceProperties\n",
    "    \n",
    "    volume = 0.0\n",
    "    area = 0.0\n",
    "    \n",
    "    # –û–±—ä—ë–º (—Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ–ª)\n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_VolumeProperties(shape, props)\n",
    "        volume = props.Mass()\n",
    "    except:\n",
    "        volume = 0.0  # –î–ª—è –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–µ–π –æ–±—ä—ë–º = 0\n",
    "    \n",
    "    # –ü–ª–æ—â–∞–¥—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –≤—Å–µ—Ö —Ç–∏–ø–æ–≤)\n",
    "    try:\n",
    "        props = GProp_GProps()\n",
    "        brepgprop_SurfaceProperties(shape, props)\n",
    "        area = props.Mass()\n",
    "    except:\n",
    "        area = 0.0\n",
    "    \n",
    "    return volume, area\n",
    "\n",
    "\n",
    "def analyze_differences(shape1, shape2_aligned, tolerance=1e-5):\n",
    "    \"\"\"\n",
    "    –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "    \"\"\"\n",
    "    results = boolean_operations(shape1, shape2_aligned, tolerance)\n",
    "    \n",
    "    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—ä—ë–º—ã\n",
    "    vol1, area1 = compute_volumes(shape1)\n",
    "    vol2, area2 = compute_volumes(shape2_aligned)\n",
    "    \n",
    "    vol_diff1 = compute_volumes(results['diff1'])[0] if 'diff1' in results else 0.0\n",
    "    vol_diff2 = compute_volumes(results['diff2'])[0] if 'diff2' in results else 0.0\n",
    "    vol_common = compute_volumes(results['common'])[0] if 'common' in results else 0.0\n",
    "    \n",
    "    # –ü—Ä–æ—Ü–µ–Ω—Ç —Ä–∞–∑–ª–∏—á–∏–π\n",
    "    total_vol = max(vol1, vol2)\n",
    "    diff_percent = ((vol_diff1 + vol_diff2) / total_vol * 100) if total_vol > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'volume_model1': vol1,\n",
    "        'volume_model2': vol2,\n",
    "        'volume_unique_to_1': vol_diff1,\n",
    "        'volume_unique_to_2': vol_diff2,\n",
    "        'volume_common': vol_common,\n",
    "        'difference_percent': diff_percent,\n",
    "        'area_model1': area1,\n",
    "        'area_model2': area2,\n",
    "        'results': results\n",
    "    }\n",
    "\n",
    "\n",
    "def save_boolean_results(results, output_dir=\"outputs/boolean\"):\n",
    "    \"\"\"\n",
    "    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ STEP-—Ñ–∞–π–ª—ã\n",
    "    \"\"\"\n",
    "    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs\n",
    "    import os\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    saved = []\n",
    "    \n",
    "    mapping = {\n",
    "        'fuse': 'union.step',\n",
    "        'common': 'intersection.step',\n",
    "        'diff1': 'unique_to_model1.step',\n",
    "        'diff2': 'unique_to_model2.step',\n",
    "        'symdiff': 'all_differences.step'\n",
    "    }\n",
    "    \n",
    "    for key, filename in mapping.items():\n",
    "        if key in results:\n",
    "            try:\n",
    "                writer = STEPControl_Writer()\n",
    "                writer.Transfer(results[key], STEPControl_AsIs)\n",
    "                status = writer.Write(os.path.join(output_dir, filename))\n",
    "                if status == 1:  # IFSelect_RetDone\n",
    "                    saved.append(filename)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {filename}: {e}\")\n",
    "    \n",
    "    return saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏...\n",
      "\n",
      "üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\n",
      "   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 1:        68429.20 –º–º¬≥\n",
      "   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 2:        68429.20 –º–º¬≥\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω–æ –º–æ–¥–µ–ª–∏ 1:    68429.20 –º–º¬≥ (100.0%)\n",
      "   –£–Ω–∏–∫–∞–ª—å–Ω–æ –º–æ–¥–µ–ª–∏ 2:    68429.20 –º–º¬≥ (100.0%)\n",
      "   –û–±—â–∞—è —á–∞—Å—Ç—å:           0.00 –º–º¬≥\n",
      "   üìå –†–∞–∑–ª–∏—á–∏—è:           200.00% –æ—Ç –æ–±—â–µ–π –º–æ–¥–µ–ª–∏\n",
      "\n",
      "‚ùå –ú–æ–¥–µ–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è (—Ä–∞–∑–ª–∏—á–∏—è > 5%) ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/boolean/union.step(1806 ents)  Write  Done\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/boolean/intersection.step(20 ents)  Write  Done\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ FreeCAD:\n",
      "   ‚Ä¢ outputs/boolean/union.step\n",
      "   ‚Ä¢ outputs/boolean/intersection.step\n",
      "   ‚Ä¢ outputs/boolean/unique_to_model1.step\n",
      "   ‚Ä¢ outputs/boolean/unique_to_model2.step\n",
      "   ‚Ä¢ outputs/boolean/all_differences.step\n",
      "\n",
      "üí° –°–æ–≤–µ—Ç—ã –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ FreeCAD:\n",
      "   1. –û—Ç–∫—Ä–æ–π—Ç–µ 'all_differences.step' ‚Äî —ç—Ç–æ –í–°–ï —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏\n",
      "   2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ü–≤–µ—Ç–∞:\n",
      "      ‚Ä¢ –ö—Ä–∞—Å–Ω—ã–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 1 (unique_to_model1.step)\n",
      "      ‚Ä¢ –°–∏–Ω–∏–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 2 (unique_to_model2.step)\n",
      "   3. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—ã–∫–æ–≤–∫–∏ –æ—Ç–∫—Ä–æ–π—Ç–µ 'intersection.step' ‚Äî –æ–±—â–∞—è –∑–æ–Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–∞\n",
      "\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/boolean/unique_to_model1.step(890 ents)  Write  Done\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/boolean/unique_to_model2.step(890 ents)  Write  Done\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Statistics on Transfer (Write)                 ******\u001b[0m\n",
      "\u001b[32;1m\n",
      "*******************************************************************\n",
      "******        Transfer Mode = 0  I.E.  As Is       ******\u001b[0m\n",
      "\u001b[32;1m******        Transferring Shape, ShapeType = 0                      ******\u001b[0m\n",
      "\u001b[32;1m** WorkSession : Sending all data\u001b[0m\n",
      "\u001b[32;1m Step File Name : outputs/boolean/all_differences.step(1806 ents)  Write  Done\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:90: DeprecationWarning: Call to deprecated function brepgprop_VolumeProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.VolumeProperties\n",
      "  brepgprop_VolumeProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:98: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:90: DeprecationWarning: Call to deprecated function brepgprop_VolumeProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.VolumeProperties\n",
      "  brepgprop_VolumeProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:98: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:90: DeprecationWarning: Call to deprecated function brepgprop_VolumeProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.VolumeProperties\n",
      "  brepgprop_VolumeProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:98: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:90: DeprecationWarning: Call to deprecated function brepgprop_VolumeProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.VolumeProperties\n",
      "  brepgprop_VolumeProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:98: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:90: DeprecationWarning: Call to deprecated function brepgprop_VolumeProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.VolumeProperties\n",
      "  brepgprop_VolumeProperties(shape, props)\n",
      "/var/folders/0t/6sq2wg4j0416j_4tk2z0wgfh0000gn/T/ipykernel_16267/652969966.py:98: DeprecationWarning: Call to deprecated function brepgprop_SurfaceProperties since pythonocc-core 7.7.1. This function will be removed in a future release, please rather use the static method brepgprop.SurfaceProperties\n",
      "  brepgprop_SurfaceProperties(shape, props)\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º, —á—Ç–æ —É –≤–∞—Å —É–∂–µ –µ—Å—Ç—å:\n",
    "#   shape1 ‚Äî –ø–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å\n",
    "#   shape2_aligned ‚Äî –≤—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Å–æ–≤–º–µ—â–µ–Ω–∏—è\n",
    "\n",
    "print(\"üîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏ —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏...\")\n",
    "\n",
    "# 1. –í—ã–ø–æ–ª–Ω—è–µ–º –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏\n",
    "analysis = analyze_differences(shape1, shape2_aligned, tolerance=1e-4)\n",
    "\n",
    "# 2. –í—ã–≤–æ–¥–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "print(f\"\\nüìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑:\")\n",
    "print(f\"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 1:        {analysis['volume_model1']:.2f} –º–º¬≥\")\n",
    "print(f\"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 2:        {analysis['volume_model2']:.2f} –º–º¬≥\")\n",
    "print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω–æ –º–æ–¥–µ–ª–∏ 1:    {analysis['volume_unique_to_1']:.2f} –º–º¬≥ ({analysis['volume_unique_to_1']/analysis['volume_model1']*100:.1f}%)\")\n",
    "print(f\"   –£–Ω–∏–∫–∞–ª—å–Ω–æ –º–æ–¥–µ–ª–∏ 2:    {analysis['volume_unique_to_2']:.2f} –º–º¬≥ ({analysis['volume_unique_to_2']/analysis['volume_model2']*100:.1f}%)\")\n",
    "print(f\"   –û–±—â–∞—è —á–∞—Å—Ç—å:           {analysis['volume_common']:.2f} –º–º¬≥\")\n",
    "print(f\"   üìå –†–∞–∑–ª–∏—á–∏—è:           {analysis['difference_percent']:.2f}% –æ—Ç –æ–±—â–µ–π –º–æ–¥–µ–ª–∏\")\n",
    "\n",
    "# 3. –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤\n",
    "if analysis['difference_percent'] < 0.1:\n",
    "    print(\"\\n‚úÖ –ú–æ–¥–µ–ª–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã (—Ä–∞–∑–ª–∏—á–∏—è < 0.1%)\")\n",
    "elif analysis['difference_percent'] < 1.0:\n",
    "    print(\"\\n‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ (—Ä–∞–∑–ª–∏—á–∏—è < 1%) ‚Äî –≤–æ–∑–º–æ–∂–Ω—ã –¥–æ–ø—É—Å–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞\")\n",
    "elif analysis['difference_percent'] < 5.0:\n",
    "    print(\"\\nüî∂ –ú–æ–¥–µ–ª–∏ —É–º–µ—Ä–µ–Ω–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è (—Ä–∞–∑–ª–∏—á–∏—è 1-5%) ‚Äî –ø—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã\")\n",
    "else:\n",
    "    print(\"\\n‚ùå –ú–æ–¥–µ–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è (—Ä–∞–∑–ª–∏—á–∏—è > 5%) ‚Äî —Ç—Ä–µ–±—É–µ—Ç—Å—è —Ä—É—á–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞\")\n",
    "\n",
    "# 4. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ FreeCAD\n",
    "saved_files = save_boolean_results(analysis['results'], \"outputs/boolean\")\n",
    "\n",
    "print(f\"\\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ FreeCAD:\")\n",
    "for fname in saved_files:\n",
    "    print(f\"   ‚Ä¢ outputs/boolean/{fname}\")\n",
    "\n",
    "print(\"\\nüí° –°–æ–≤–µ—Ç—ã –ø–æ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –≤ FreeCAD:\")\n",
    "print(\"   1. –û—Ç–∫—Ä–æ–π—Ç–µ 'all_differences.step' ‚Äî —ç—Ç–æ –í–°–ï —Ä–∞–∑–ª–∏—á–∏—è –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏\")\n",
    "print(\"   2. –ü—Ä–∏–º–µ–Ω–∏—Ç–µ —Ü–≤–µ—Ç–∞:\")\n",
    "print(\"      ‚Ä¢ –ö—Ä–∞—Å–Ω—ã–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 1 (unique_to_model1.step)\")\n",
    "print(\"      ‚Ä¢ –°–∏–Ω–∏–π: —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ 2 (unique_to_model2.step)\")\n",
    "print(\"   3. –î–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç—ã–∫–æ–≤–∫–∏ –æ—Ç–∫—Ä–æ–π—Ç–µ 'intersection.step' ‚Äî –æ–±—â–∞—è –∑–æ–Ω–∞ –∫–æ–Ω—Ç–∞–∫—Ç–∞\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cad_step",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

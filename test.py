#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ ‚Üí –æ–±—É—á–µ–Ω–∏–µ GNN ‚Üí —Å–æ–≤–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ‚Üí –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏
–°—Ç–∞–±–∏–ª—å–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ macOS —Å pythonocc-core 7.9.0
"""

# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 0. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ò–ù–ò–¶–ò–ê–õ–ò–ó–ê–¶–ò–Ø (–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –í –ü–ï–†–í–û–ô –Ø–ß–ï–ô–ö–ï!)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
import os
import gc
import sys
import numpy as np
import torch

# üî¥ –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ macOS:
os.environ["OMP_NUM_THREADS"] = "1"
os.environ["OPENBLAS_NUM_THREADS"] = "1"
os.environ["MKL_NUM_THREADS"] = "1"
os.environ["VECLIB_MAXIMUM_THREADS"] = "1"
os.environ["NUMEXPR_NUM_THREADS"] = "1"
torch.set_num_threads(1)

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –≥–µ–æ–º–µ—Ç—Ä–∏–µ–π
try:
    from OCC.Core import STEPControl, TopExp, TopAbs
    from OCC.Core.BRep import BRep_Tool
    from OCC.Core.gp import gp_Pnt, gp_Vec, gp_Trsf
    from OCC.Core.BRepBuilderAPI import BRepBuilderAPI_Transform
    from OCC.Core.STEPControl import STEPControl_Writer, STEPControl_AsIs
    from OCC.Core.GProp import GProp_GProps
    from OCC.Core.BRepGProp import brepgprop_VolumeProperties, brepgprop_SurfaceProperties
    from OCC.Core.BRepExtrema import BRepExtrema_DistShapeShape
    from OCC.Core.BRepAlgoAPI import BRepAlgoAPI_Fuse, BRepAlgoAPI_Common, BRepAlgoAPI_Cut
    from OCC.Core.TopExp import TopExp_Explorer
    from OCC.Core.TopAbs import TopAbs_FACE
    from OCC.Core.Geom import Geom_Plane
    from OCC.Core.BRepPrimAPI import (
        BRepPrimAPI_MakeBox,
        BRepPrimAPI_MakeCylinder,
        BRepPrimAPI_MakeSphere,
        BRepPrimAPI_MakeCone
    )
except ImportError as e:
    print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
    print("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: conda install -c conda-forge pythonocc-core=7.9.0")
    sys.exit(1)

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è
from torch_geometric.data import Data, Dataset
from torch_geometric.nn import GATv2Conv, global_mean_pool
from torch_geometric.loader import DataLoader
from scipy.spatial import cKDTree
import json

print("‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
print(f"   Python: {sys.version.split()[0]}")
print(f"   PyTorch: {torch.__version__}")
print(f"   NumPy: {np.__version__}")
gc.collect()


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 1. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ó–ê–ì–†–£–ó–ö–ê –ò –ü–ê–†–°–ò–ù–ì –ú–û–î–ï–õ–ï–ô
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def safe_read_step_file(filename, max_attempts=3):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ STEP-—Ñ–∞–π–ª–∞ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–µ–≥—Ñ–æ–ª—Ç–æ–≤"""
    for attempt in range(max_attempts):
        try:
            reader = STEPControl.STEPControl_Reader()
            status = reader.ReadFile(str(filename))
            if status != 1:  # IFSelect_RetDone = 1
                raise RuntimeError(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {filename}: —Å—Ç–∞—Ç—É—Å {status}")
            
            reader.TransferRoots()
            shape = reader.OneShape()
            
            # –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û: –æ—Å–≤–æ–±–æ–∂–¥–∞–µ–º —Ä–µ—Å—É—Ä—Å—ã –¥–æ –≤–æ–∑–≤—Ä–∞—Ç–∞
            del reader
            gc.collect()
            
            return shape
            
        except Exception as e:
            print(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_attempts} –Ω–µ —É–¥–∞–ª–∞—Å—å –¥–ª—è {filename}: {e}")
            gc.collect()
            if attempt == max_attempts - 1:
                print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {filename} –ø–æ—Å–ª–µ {max_attempts} –ø–æ–ø—ã—Ç–æ–∫")
                return None


def extract_topology(shape):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤–µ—Ä—à–∏–Ω—ã –∏ —Å–≤—è–∑–∏ –≥—Ä–∞–Ω—å-–≤–µ—Ä—à–∏–Ω–∞ (–≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Ä–∞–±–æ—á–∞—è –¥–ª—è pythonocc-core 7.9.0)"""
    vertices = []
    vertex_map = {}
    face_vertex_indices = []

    face_explorer = TopExp.TopExp_Explorer(shape, TopAbs.TopAbs_FACE)
    while face_explorer.More():
        face = face_explorer.Current()
        local_vertices = []

        edge_explorer = TopExp.TopExp_Explorer(face, TopAbs.TopAbs_EDGE)
        while edge_explorer.More():
            edge = edge_explorer.Current()
            vertex_explorer = TopExp.TopExp_Explorer(edge, TopAbs.TopAbs_VERTEX)
            while vertex_explorer.More():
                vertex = vertex_explorer.Current()
                p = BRep_Tool.Pnt(vertex)
                key = (round(p.X(), 6), round(p.Y(), 6), round(p.Z(), 6))
                if key not in vertex_map:
                    vertex_map[key] = len(vertices)
                    vertices.append(np.array([p.X(), p.Y(), p.Z()]))
                local_vertices.append(vertex_map[key])
                vertex_explorer.Next()
            edge_explorer.Next()

        if local_vertices:
            local_vertices = list(dict.fromkeys(local_vertices))
            face_vertex_indices.append(local_vertices)
        face_explorer.Next()

    gc.collect()
    return np.array(vertices), face_vertex_indices


def compute_center_of_mass(shape):
    """–í—ã—á–∏—Å–ª—è–µ—Ç —Ü–µ–Ω—Ç—Ä –º–∞—Å—Å —Ç–µ–ª–∞ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–∞–∫ —Å–ø–∏—Å–æ–∫ [x, y, z]"""
    props = GProp_GProps()
    try:
        brepgprop_VolumeProperties(shape, props)
        cog = props.CentreOfMass()
        return [float(cog.X()), float(cog.Y()), float(cog.Z())]
    except:
        from OCC.Core.Bnd import Bnd_Box
        from OCC.Core.BRepBndLib import brepbndlib_Add
        bbox = Bnd_Box()
        brepbndlib_Add(shape, bbox)
        xmin, ymin, zmin, xmax, ymax, zmax = bbox.Get()
        return [float((xmin+xmax)/2), float((ymin+ymax)/2), float((zmin+zmax)/2)]


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 2. –ü–û–°–¢–†–û–ï–ù–ò–ï –ì–†–ê–§–ê –ò–ó –¢–û–ü–û–õ–û–ì–ò–ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def normalize_coordinates(vertices):
    if len(vertices) == 0:
        return vertices
    center = vertices.mean(axis=0)
    scale = np.max(np.abs(vertices - center)) + 1e-8
    return (vertices - center) / scale


def build_graph(vertices, face_vertex_indices):
    n_vertices = len(vertices)
    n_faces = len(face_vertex_indices)

    vertices_norm = normalize_coordinates(vertices)
    node_coords = np.zeros((n_vertices + n_faces, 3))
    node_types = np.zeros(n_vertices + n_faces, dtype=int)

    # –í–µ—Ä—à–∏–Ω—ã
    node_coords[:n_vertices] = vertices_norm
    node_types[:n_vertices] = 0

    # –ì—Ä–∞–Ω–∏
    for i, vtx_ids in enumerate(face_vertex_indices):
        if vtx_ids:
            center = vertices_norm[vtx_ids].mean(axis=0)
            node_coords[n_vertices + i] = center
            node_types[n_vertices + i] = 1

    # –†—ë–±—Ä–∞
    edge_index = []
    for face_id, vtx_ids in enumerate(face_vertex_indices):
        for vtx_id in vtx_ids:
            edge_index.append([n_vertices + face_id, vtx_id])
            edge_index.append([vtx_id, n_vertices + face_id])

    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()
    x = torch.tensor(node_coords, dtype=torch.float)
    node_type = torch.tensor(node_types, dtype=torch.long)

    gc.collect()
    return Data(x=x, edge_index=edge_index, node_type=node_type)


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 3. –ì–ï–ù–ï–†–ê–¶–ò–Ø –°–ò–ù–¢–ï–¢–ò–ß–ï–°–ö–û–ì–û –î–ê–¢–ê–°–ï–¢–ê (4 —Ç–∏–ø–∞ –¥–µ—Ç–∞–ª–µ–π)
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def create_synthetic_part(part_type="bracket", seed=None, size_variation=1.0):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–π –¥–µ—Ç–∞–ª–∏ —Å –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π (–≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã –≤ JSON)
    
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ç–∏–ø—ã: "bracket", "flange", "block_with_holes", "t_bracket"
    """
    if seed is not None:
        np.random.seed(seed)
    
    base_size = 100.0 * size_variation
    thickness = 10.0 * size_variation
    
    if part_type == "bracket":
        # –ö—Ä–æ–Ω—à—Ç–µ–π–Ω: –æ—Å–Ω–æ–≤–∞–Ω–∏–µ + –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–∞—è –ø–ª–∞—Å—Ç–∏–Ω–∞ + 2 –æ—Ç–≤–µ—Ä—Å—Ç–∏—è
        base = BRepPrimAPI_MakeBox(base_size, base_size*0.5, thickness).Shape()
        wall = BRepPrimAPI_MakeBox(thickness, base_size*0.5, base_size*0.4).Shape()
        
        trsf = gp_Trsf()
        trsf.SetTranslation(gp_Vec(base_size - thickness, 0, thickness))
        transform = BRepBuilderAPI_Transform(wall, trsf)
        wall_pos = transform.Shape()
        
        part = BRepAlgoAPI_Fuse(base, wall_pos).Shape()
        
        holes = []
        for i in range(2):
            hole = BRepPrimAPI_MakeCylinder(5.0 * size_variation, thickness*1.5).Shape()
            trsf = gp_Trsf()
            trsf.SetTranslation(gp_Vec(base_size*0.3 + i*base_size*0.4, base_size*0.25, -thickness*0.25))
            transform = BRepBuilderAPI_Transform(hole, trsf)
            hole_pos = transform.Shape()
            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()
            holes.append({
                'center': [
                    float(base_size*0.3 + i*base_size*0.4),
                    float(base_size*0.25),
                    float(thickness/2)
                ],
                'diameter': float(10.0 * size_variation),
                'type': 'through_hole'
            })
        
        cog = compute_center_of_mass(part)
        annotations = {
            "center_of_mass": cog,
            "reference_planes": [
                {
                    "center": [float(base_size/2), float(base_size*0.25), float(thickness/2)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(base_size*base_size*0.5),
                    "role": 3
                },
                {
                    "center": [float(base_size - thickness/2), float(base_size*0.25), float(base_size*0.2 + thickness)],
                    "normal": [1.0, 0.0, 0.0],
                    "area": float(base_size*0.5*base_size*0.4),
                    "role": 3
                },
                {
                    "center": [float(base_size/2), float(base_size*0.25), 0.0],
                    "normal": [0.0, 0.0, -1.0],
                    "area": float(base_size*base_size*0.5),
                    "role": 3
                }
            ],
            "fastening_elements": holes,
            "functional_surfaces": [
                {
                    "center": [float(base_size - thickness/2), float(base_size*0.25), float(base_size*0.2 + thickness + base_size*0.2)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(thickness*base_size*0.5),
                    "role": 1
                }
            ],
            "part_type": "bracket"
        }
        return part, annotations
    
    elif part_type == "flange":
        # –§–ª–∞–Ω–µ—Ü: –¥–∏—Å–∫ —Å 4 –æ—Ç–≤–µ—Ä—Å—Ç–∏—è–º–∏ –ø–æ –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏
        radius = base_size * 0.5
        flange = BRepPrimAPI_MakeCylinder(radius, thickness).Shape()
        
        # –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–æ–µ –æ—Ç–≤–µ—Ä—Å—Ç–∏–µ
        center_hole = BRepPrimAPI_MakeCylinder(radius*0.2, thickness*1.5).Shape()
        part = BRepAlgoAPI_Cut(flange, center_hole).Shape()
        
        # 4 –æ—Ç–≤–µ—Ä—Å—Ç–∏—è –ø–æ –æ–∫—Ä—É–∂–Ω–æ—Å—Ç–∏
        holes = []
        for i in range(4):
            angle = np.radians(i * 90)
            x = radius * 0.6 * np.cos(angle)
            y = radius * 0.6 * np.sin(angle)
            hole = BRepPrimAPI_MakeCylinder(6.0 * size_variation, thickness*1.5).Shape()
            trsf = gp_Trsf()
            trsf.SetTranslation(gp_Vec(x, y, -thickness*0.25))
            transform = BRepBuilderAPI_Transform(hole, trsf)
            hole_pos = transform.Shape()
            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()
            holes.append({
                'center': [float(x), float(y), float(thickness/2)],
                'diameter': float(12.0 * size_variation),
                'type': 'mounting_hole'
            })
        
        cog = compute_center_of_mass(part)
        annotations = {
            "center_of_mass": cog,
            "reference_planes": [
                {
                    "center": [0.0, 0.0, float(thickness/2)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(np.pi * radius**2),
                    "role": 3
                },
                {
                    "center": [0.0, 0.0, 0.0],
                    "normal": [0.0, 0.0, -1.0],
                    "area": float(np.pi * radius**2),
                    "role": 3
                }
            ],
            "fastening_elements": holes,
            "functional_surfaces": [
                {
                    "center": [0.0, 0.0, float(thickness/2)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(np.pi * (radius**2 - (radius*0.2)**2)),
                    "role": 1
                }
            ],
            "part_type": "flange"
        }
        return part, annotations
    
    elif part_type == "block_with_holes":
        # –ë—Ä—É—Å–æ–∫ —Å 6 –æ—Ç–≤–µ—Ä—Å—Ç–∏—è–º–∏ (2 —Ä—è–¥–∞ –ø–æ 3)
        block = BRepPrimAPI_MakeBox(base_size, base_size, base_size*0.5).Shape()
        
        holes = []
        for i in range(2):  # 2 —Ä—è–¥–∞
            for j in range(3):  # 3 –æ—Ç–≤–µ—Ä—Å—Ç–∏—è –≤ —Ä—è–¥—É
                x = base_size * 0.25 + j * base_size * 0.25
                y = base_size * 0.3 + i * base_size * 0.4
                hole = BRepPrimAPI_MakeCylinder(4.0 * size_variation, base_size*0.6).Shape()
                trsf = gp_Trsf()
                trsf.SetTranslation(gp_Vec(x, y, -base_size*0.05))
                transform = BRepBuilderAPI_Transform(hole, trsf)
                hole_pos = transform.Shape()
                block = BRepAlgoAPI_Cut(block, hole_pos).Shape()
                holes.append({
                    'center': [float(x), float(y), float(base_size*0.25)],
                    'diameter': float(8.0 * size_variation),
                    'type': 'grid_hole'
                })
        
        cog = compute_center_of_mass(block)
        annotations = {
            "center_of_mass": cog,
            "reference_planes": [
                {
                    "center": [float(base_size/2), float(base_size/2), float(base_size*0.25)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(base_size**2),
                    "role": 3
                },
                {
                    "center": [float(base_size/2), float(base_size/2), 0.0],
                    "normal": [0.0, 0.0, -1.0],
                    "area": float(base_size**2),
                    "role": 3
                },
                {
                    "center": [0.0, float(base_size/2), float(base_size*0.25)],
                    "normal": [-1.0, 0.0, 0.0],
                    "area": float(base_size*base_size*0.5),
                    "role": 3
                }
            ],
            "fastening_elements": holes,
            "functional_surfaces": [],
            "part_type": "block_with_holes"
        }
        return block, annotations
    
    elif part_type == "t_bracket":
        # T-–æ–±—Ä–∞–∑–Ω—ã–π –∫—Ä–æ–Ω—à—Ç–µ–π–Ω
        base = BRepPrimAPI_MakeBox(base_size, thickness, thickness).Shape()
        vertical = BRepPrimAPI_MakeBox(thickness, base_size*0.6, base_size*0.3).Shape()
        
        trsf = gp_Trsf()
        trsf.SetTranslation(gp_Vec((base_size-thickness)/2, 0, thickness))
        transform = BRepBuilderAPI_Transform(vertical, trsf)
        vertical_pos = transform.Shape()
        
        part = BRepAlgoAPI_Fuse(base, vertical_pos).Shape()
        
        # –û—Ç–≤–µ—Ä—Å—Ç–∏—è –≤ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏
        holes = []
        for i in range(2):
            hole = BRepPrimAPI_MakeCylinder(5.0 * size_variation, thickness*1.5).Shape()
            trsf = gp_Trsf()
            trsf.SetTranslation(gp_Vec(base_size*0.25 + i*base_size*0.5, thickness/2, -thickness*0.25))
            transform = BRepBuilderAPI_Transform(hole, trsf)
            hole_pos = transform.Shape()
            part = BRepAlgoAPI_Cut(part, hole_pos).Shape()
            holes.append({
                'center': [
                    float(base_size*0.25 + i*base_size*0.5),
                    float(thickness/2),
                    float(thickness/2)
                ],
                'diameter': float(10.0 * size_variation),
                'type': 'mounting_hole'
            })
        
        cog = compute_center_of_mass(part)
        annotations = {
            "center_of_mass": cog,
            "reference_planes": [
                {
                    "center": [float(base_size/2), float(thickness/2), float(thickness/2)],
                    "normal": [0.0, 0.0, 1.0],
                    "area": float(base_size*thickness),
                    "role": 3
                },
                {
                    "center": [float(base_size/2), float(thickness/2), 0.0],
                    "normal": [0.0, 0.0, -1.0],
                    "area": float(base_size*thickness),
                    "role": 3
                },
                {
                    "center": [float((base_size-thickness)/2 + thickness/2), float(base_size*0.3), float(base_size*0.15 + thickness)],
                    "normal": [1.0, 0.0, 0.0],
                    "area": float(thickness*base_size*0.6),
                    "role": 3
                }
            ],
            "fastening_elements": holes,
            "functional_surfaces": [],
            "part_type": "t_bracket"
        }
        return part, annotations
    
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–µ—Ç–∞–ª–∏: {part_type}")


def generate_enhanced_dataset(output_dir="enhanced_dataset", n_samples=50):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
    
    –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –≤—ã—Ö–æ–¥–∞:
        enhanced_dataset/
        ‚îú‚îÄ‚îÄ raw/              # STEP-—Ñ–∞–π–ª—ã –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        ‚îú‚îÄ‚îÄ annotations/      # JSON —Å –ø–æ–ª–Ω–æ–π —Ä–∞–∑–º–µ—Ç–∫–æ–π
        ‚îî‚îÄ‚îÄ pairs/            # –ü–∞—Ä—ã –º–æ–¥–µ–ª–µ–π —Å –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è–º–∏
    """
    os.makedirs(os.path.join(output_dir, "raw"), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "annotations"), exist_ok=True)
    os.makedirs(os.path.join(output_dir, "pairs"), exist_ok=True)
    
    part_types = ["bracket", "flange", "block_with_holes", "t_bracket"]
    pair_id = 0
    
    print(f"üîÑ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è {n_samples} —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π...")
    
    for i in range(n_samples):
        part_type = np.random.choice(part_types)
        size_var = np.random.uniform(0.8, 1.2)
        
        shape_orig, ann_orig = create_synthetic_part(
            part_type=part_type, 
            seed=i,
            size_variation=size_var
        )
        
        orig_filename = f"{part_type}_{i:06d}.step"
        orig_path = os.path.join(output_dir, "raw", orig_filename)
        writer = STEPControl_Writer()
        writer.Transfer(shape_orig, STEPControl_AsIs)
        writer.Write(orig_path)
        
        ann_path = os.path.join(output_dir, "annotations", f"{part_type}_{i:06d}.json")
        with open(ann_path, "w", encoding="utf-8") as f:
            json.dump(ann_orig, f, indent=2, ensure_ascii=False)
        
        gc.collect()  # –û—á–∏—Å—Ç–∫–∞ –ø–∞–º—è—Ç–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
    
    print(f"‚úÖ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ {n_samples} –º–æ–¥–µ–ª–µ–π")
    print(f"üìÅ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_dir}")
    return output_dir


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 4. –î–ê–¢–ê–°–ï–¢ –î–õ–Ø PYTORCH GEOMETRIC
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class FixedSyntheticDataset(Dataset):
    """
    –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ–º –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    """
    def __init__(self, root="enhanced_dataset", transform=None, pre_transform=None):
        self.role_mapping = {
            "decorative": 0,
            "functional": 1,
            "fastening": 2,
            "reference_plane": 3
        }
        super().__init__(root, transform, pre_transform)
    
    @property
    def raw_dir(self):
        return os.path.join(self.root, "raw")
    
    @property
    def ann_dir(self):
        return os.path.join(self.root, "annotations")
    
    @property
    def raw_file_names(self):
        files = [f for f in os.listdir(self.raw_dir) if f.endswith(".step") and "_trans_" not in f]
        return sorted(files)
    
    @property
    def processed_file_names(self):
        return [f"data_{idx:06d}.pt" for idx in range(len(self.raw_file_names))]
    
    def process(self):
        print(f"üîÑ –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π...")
        
        for idx, step_file in enumerate(self.raw_file_names):
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
            reader = STEPControl.STEPControl_Reader()
            reader.ReadFile(os.path.join(self.raw_dir, step_file))
            reader.TransferRoots()
            shape = reader.OneShape()
            
            # 2. –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ ‚Üí –ò–°–•–û–î–ù–´–ï –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ –º–º
            vertices, face_vertex_indices = extract_topology(shape)
            
            # 3. –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
            ann_file = os.path.splitext(step_file)[0] + ".json"
            ann_path = os.path.join(self.ann_dir, ann_file)
            annotations = {}
            if os.path.exists(ann_path):
                try:
                    with open(ann_path, "r", encoding="utf-8") as f:
                        annotations = json.load(f)
                except Exception as e:
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {ann_file}: {e}")
                    continue
            
            # 4. –°–û–ü–û–°–¢–ê–í–õ–ï–ù–ò–ï –í –ò–°–•–û–î–ù–´–• –ö–û–û–†–î–ò–ù–ê–¢–ê–• (–º–º)
            n_vertices = len(vertices)
            n_faces = len(face_vertex_indices)
            node_roles = np.zeros(n_vertices + n_faces, dtype=np.int64)
            node_roles[:n_vertices] = self.role_mapping["decorative"]  # –≤–µ—Ä—à–∏–Ω—ã ‚Üí –¥–µ–∫–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ
            
            # –í—ã—á–∏—Å–ª—è–µ–º —Ü–µ–Ω—Ç—Ä–æ–∏–¥—ã –≥—Ä–∞–Ω–µ–π –≤ –ò–°–•–û–î–ù–´–• –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞—Ö (–º–º)
            face_centers_mm = []
            for vtx_ids in face_vertex_indices:
                if vtx_ids:
                    center = vertices[vtx_ids].mean(axis=0)
                    face_centers_mm.append(center)
            face_centers_mm = np.array(face_centers_mm)
            
            # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
            assigned = np.zeros(n_faces, dtype=bool)
            
            # –û–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏ (—Ä–æ–ª—å 3) ‚Äî –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
            for ref_plane in annotations.get("reference_planes", []):
                ref_center = np.array(ref_plane["center"])
                if len(face_centers_mm) > 0:
                    distances = np.linalg.norm(face_centers_mm - ref_center, axis=1)
                    closest_idx = np.argmin(distances)
                    if distances[closest_idx] < 50.0:  # —É–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ 50 –º–º
                        node_roles[n_vertices + closest_idx] = self.role_mapping["reference_plane"]
                        assigned[closest_idx] = True
            
            # –ö—Ä–µ–ø—ë–∂–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã (—Ä–æ–ª—å 2)
            for fastening in annotations.get("fastening_elements", []):
                fast_center = np.array(fastening["center"])
                if len(face_centers_mm) > 0:
                    distances = np.linalg.norm(face_centers_mm - fast_center, axis=1)
                    closest_idx = np.argmin(distances)
                    if distances[closest_idx] < 20.0 and not assigned[closest_idx]:
                        node_roles[n_vertices + closest_idx] = self.role_mapping["fastening"]
                        assigned[closest_idx] = True
            
            # –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–æ–ª—å 1)
            for func_surf in annotations.get("functional_surfaces", []):
                func_center = np.array(func_surf["center"])
                if len(face_centers_mm) > 0:
                    distances = np.linalg.norm(face_centers_mm - func_center, axis=1)
                    closest_idx = np.argmin(distances)
                    if distances[closest_idx] < 20.0 and not assigned[closest_idx]:
                        node_roles[n_vertices + closest_idx] = self.role_mapping["functional"]
                        assigned[closest_idx] = True
            
            # –û—Å—Ç–∞–ª—å–Ω—ã–µ –≥—Ä–∞–Ω–∏ ‚Üí —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–µ (—Ä–æ–ª—å 1)
            for i in range(n_faces):
                if not assigned[i]:
                    node_roles[n_vertices + i] = self.role_mapping["functional"]
            
            # 5. –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –° –ù–û–†–ú–ê–õ–ò–ó–ê–¶–ò–ï–ô
            data = build_graph(vertices, face_vertex_indices)
            data.y = torch.tensor(node_roles, dtype=torch.long)
            
            # 6. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
            torch.save(data, os.path.join(self.processed_dir, f"data_{idx:06d}.pt"))
        
        print(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(self.raw_file_names)} –º–æ–¥–µ–ª–µ–π")
        print(f"   –ì—Ä–∞—Ñ—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.processed_dir}")
    
    def len(self):
        return len(self.processed_file_names)
    
    def get(self, idx):
        return torch.load(
            os.path.join(self.processed_dir, self.processed_file_names[idx]),
            weights_only=False
        )


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 5. –ê–†–•–ò–¢–ï–ö–¢–£–†–ê GNN
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

class GNNModel(torch.nn.Module):
    def __init__(self, in_channels=3, hidden_dim=64, num_roles=4):
        super().__init__()
        self.conv1 = GATv2Conv(in_channels, hidden_dim, heads=4, concat=True, dropout=0.2)
        self.conv2 = GATv2Conv(hidden_dim * 4, hidden_dim, heads=2, concat=False, dropout=0.2)
        self.role_classifier = torch.nn.Linear(hidden_dim, num_roles)
        self.graph_proj = torch.nn.Linear(hidden_dim, 64)

    def forward(self, x, edge_index, batch):
        x = torch.nn.functional.relu(self.conv1(x, edge_index))
        x = torch.nn.functional.relu(self.conv2(x, edge_index))
        roles = self.role_classifier(x)
        graph_emb = global_mean_pool(x, batch)
        graph_emb = self.graph_proj(graph_emb)
        return roles, graph_emb


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 6. –°–û–í–ú–ï–©–ï–ù–ò–ï –ú–û–î–ï–õ–ï–ô –ò –ë–£–õ–ï–í–´ –û–ü–ï–†–ê–¶–ò–ò
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def align_with_umeyama(src_pts, tgt_pts):
    """–ê–ª–≥–æ—Ä–∏—Ç–º –£–º—ç—è–º—ã –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è"""
    assert src_pts.shape == tgt_pts.shape and src_pts.shape[0] >= 3
    src_mean = src_pts.mean(axis=0)
    tgt_mean = tgt_pts.mean(axis=0)
    src_c = src_pts - src_mean
    tgt_c = tgt_pts - tgt_mean
    H = src_c.T @ tgt_c
    U, S, Vt = np.linalg.svd(H)
    R_opt = Vt.T @ U.T
    if np.linalg.det(R_opt) < 0:
        Vt[-1, :] *= -1
        R_opt = Vt.T @ U.T
    t_opt = tgt_mean - R_opt @ src_mean
    return R_opt, t_opt


def find_elements_by_role(role_probs, node_types, coords, role_idx=3, top_k=3):
    """
    –ù–∞—Ö–æ–¥–∏—Ç —ç–ª–µ–º–µ–Ω—Ç—ã –∑–∞–¥–∞–Ω–Ω–æ–π —Ä–æ–ª–∏ (0=–¥–µ–∫–æ—Ä, 1=—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è, 2=–æ—Ç–≤–µ—Ä—Å—Ç–∏—è, 3=–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏)
    """
    face_mask = (node_types == 1)
    if not np.any(face_mask):
        return np.array([])
    
    scores = role_probs[face_mask, role_idx]
    top_indices = np.argsort(-scores)[:top_k]
    face_indices = np.where(face_mask)[0][top_indices]
    return coords[face_indices]


def extract_large_planes(shape, min_area=10.0, max_planes=5):
    """
    –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –∫—Ä—É–ø–Ω—ã—Ö –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π –±–µ–∑ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (–ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å pythonocc-core 7.9.0)
    """
    planes = []
    explorer = TopExp_Explorer(shape, TopAbs_FACE)
    
    while explorer.More():
        face = explorer.Current()
        surface = BRep_Tool.Surface(face)
        
        if not surface.IsKind("Geom_Plane"):
            explorer.Next()
            continue
        
        props = GProp_GProps()
        brepgprop_SurfaceProperties(face, props)
        area = props.Mass()
        
        if area < min_area:
            explorer.Next()
            continue
        
        cog = props.CentreOfMass()
        
        try:
            plane = Geom_Plane.DownCast(surface)
            normal = plane.Axis().Direction()
        except:
            explorer.Next()
            continue
        
        planes.append({
            'area': float(area),
            'center': np.array([cog.X(), cog.Y(), cog.Z()]),
            'normal': np.array([normal.X(), normal.Y(), normal.Z()])
        })
        explorer.Next()
    
    planes.sort(key=lambda x: x['area'], reverse=True)
    gc.collect()
    return planes[:max_planes]


def evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000):
    """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –≤–µ—Ä—à–∏–Ω–∞–º–∏"""
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –•–∞—É—Å–¥–æ—Ä—Ñ–∞
    dist_checker = BRepExtrema_DistShapeShape()
    dist_checker.LoadS1(shape1)
    dist_checker.LoadS2(shape2_aligned)
    dist_checker.Perform()
    
    if not dist_checker.IsDone():
        return {'success': False, 'error': '–†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è'}
    
    min_dist = dist_checker.Value()
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ—Ä—à–∏–Ω
    vertices1, _ = extract_topology(shape1)
    vertices2, _ = extract_topology(shape2_aligned)
    
    # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —á–∏—Å–ª–∞ –≤–µ—Ä—à–∏–Ω –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
    if len(vertices1) > n_max_vertices:
        indices = np.random.choice(len(vertices1), n_max_vertices, replace=False)
        vertices1 = vertices1[indices]
    if len(vertices2) > n_max_vertices:
        indices = np.random.choice(len(vertices2), n_max_vertices, replace=False)
        vertices2 = vertices2[indices]
    
    if len(vertices1) == 0 or len(vertices2) == 0:
        return {'success': False, 'error': '–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –≤–µ—Ä—à–∏–Ω—ã'}
    
    # –†–∞—Å—á—ë—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
    tree2 = cKDTree(vertices2)
    dists12, _ = tree2.query(vertices1, k=1)
    
    tree1 = cKDTree(vertices1)
    dists21, _ = tree1.query(vertices2, k=1)
    
    hausdorff_sym = max(dists12.max(), dists21.max())
    mean_dist = (dists12.mean() + dists21.mean()) / 2.0
    
    gc.collect()
    return {
        'success': True,
        'hausdorff_min': min_dist,
        'hausdorff_symmetric': hausdorff_sym,
        'mean_distance': mean_dist,
        'max_distance': max(dists12.max(), dists21.max()),
        'rms_distance': np.sqrt((dists12**2).mean()),
        'inlier_ratio_0.1mm': (dists12 < 0.1).mean(),
        'inlier_ratio_1.0mm': (dists12 < 1.0).mean(),
        'sample_count': len(vertices1)
    }


def boolean_operations(shape1, shape2_aligned, tolerance=1e-3):
    """
    –í—ã–ø–æ–ª–Ω—è–µ—Ç –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞–ø—Ä—è–º—É—é —Å TopoDS_Shape (–±–µ–∑ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤)
    """
    results = {}
    errors = []
    
    # –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ
    try:
        fuse = BRepAlgoAPI_Fuse(shape1, shape2_aligned)
        fuse.SetFuzzyValue(tolerance)
        if fuse.IsDone():
            results['fuse'] = fuse.Shape()
        else:
            errors.append("fuse")
    except Exception as e:
        errors.append(f"fuse: {str(e)}")
    
    # –ü–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ
    try:
        common = BRepAlgoAPI_Common(shape1, shape2_aligned)
        common.SetFuzzyValue(tolerance)
        if common.IsDone():
            results['common'] = common.Shape()
        else:
            errors.append("common")
    except Exception as e:
        errors.append(f"common: {str(e)}")
    
    # –†–∞–∑–Ω–æ—Å—Ç—å (A \ B)
    try:
        cut1 = BRepAlgoAPI_Cut(shape1, shape2_aligned)
        cut1.SetFuzzyValue(tolerance)
        if cut1.IsDone():
            results['diff1'] = cut1.Shape()
        else:
            errors.append("diff1")
    except Exception as e:
        errors.append(f"diff1: {str(e)}")
    
    # –†–∞–∑–Ω–æ—Å—Ç—å (B \ A)
    try:
        cut2 = BRepAlgoAPI_Cut(shape2_aligned, shape1)
        cut2.SetFuzzyValue(tolerance)
        if cut2.IsDone():
            results['diff2'] = cut2.Shape()
        else:
            errors.append("diff2")
    except Exception as e:
        errors.append(f"diff2: {str(e)}")
    
    # –°–∏–º–º–µ—Ç—Ä–∏—á–µ—Å–∫–∞—è —Ä–∞–∑–Ω–æ—Å—Ç—å
    if 'diff1' in results and 'diff2' in results:
        try:
            symdiff = BRepAlgoAPI_Fuse(results['diff1'], results['diff2'])
            symdiff.SetFuzzyValue(tolerance)
            if symdiff.IsDone():
                results['symdiff'] = symdiff.Shape()
        except:
            pass
    
    if errors:
        results['errors'] = errors
    
    gc.collect()
    return results


def compute_volumes(shape):
    """–í—ã—á–∏—Å–ª—è–µ—Ç –æ–±—ä—ë–º –∏ –ø–ª–æ—â–∞–¥—å –ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç–∏ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –ª—é–±—ã–º TopoDS_Shape)"""
    volume = 0.0
    area = 0.0
    
    try:
        props = GProp_GProps()
        brepgprop_VolumeProperties(shape, props)
        volume = props.Mass()
    except:
        volume = 0.0
    
    try:
        props = GProp_GProps()
        brepgprop_SurfaceProperties(shape, props)
        area = props.Mass()
    except:
        area = 0.0
    
    return volume, area


def analyze_differences(shape1, shape2_aligned, tolerance=1e-3):
    """–ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏"""
    results = boolean_operations(shape1, shape2_aligned, tolerance)
    
    vol1, area1 = compute_volumes(shape1)
    vol2, area2 = compute_volumes(shape2_aligned)
    
    vol_diff1 = compute_volumes(results['diff1'])[0] if 'diff1' in results else 0.0
    vol_diff2 = compute_volumes(results['diff2'])[0] if 'diff2' in results else 0.0
    vol_common = compute_volumes(results['common'])[0] if 'common' in results else 0.0
    
    total_vol = max(vol1, vol2)
    diff_percent = ((vol_diff1 + vol_diff2) / total_vol * 100) if total_vol > 0 else 0.0
    
    gc.collect()
    return {
        'volume_model1': vol1,
        'volume_model2': vol2,
        'volume_unique_to_1': vol_diff1,
        'volume_unique_to_2': vol_diff2,
        'volume_common': vol_common,
        'difference_percent': diff_percent,
        'area_model1': area1,
        'area_model2': area2,
        'results': results
    }


def save_boolean_results(results, output_dir="outputs/boolean"):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π –≤ STEP-—Ñ–∞–π–ª—ã"""
    os.makedirs(output_dir, exist_ok=True)
    saved = []
    
    mapping = {
        'fuse': 'union.step',
        'common': 'intersection.step',
        'diff1': 'unique_to_model1.step',
        'diff2': 'unique_to_model2.step',
        'symdiff': 'all_differences.step'
    }
    
    for key, filename in mapping.items():
        if key in results:
            try:
                writer = STEPControl_Writer()
                writer.Transfer(results[key], STEPControl_AsIs)
                status = writer.Write(os.path.join(output_dir, filename))
                if status == 1:
                    saved.append(filename)
            except Exception as e:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å {filename}: {e}")
    
    gc.collect()
    return saved


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 7. –ì–õ–ê–í–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

def main_pipeline(step_file_1, step_file_2, use_gnn=False, model_path="gnn_best.pth"):
    """
    –ü–æ–ª–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –∏ —Å–æ–≤–º–µ—â–µ–Ω–∏—è –¥–≤—É—Ö –º–æ–¥–µ–ª–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º:
    - –¶–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å (–≤—Å–µ–≥–¥–∞)
    - –û—Ç–≤–µ—Ä—Å—Ç–∏–π (—Ä–æ–ª—å 2)
    - –û–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3)
    """
    # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç —Å–µ–≥—Ñ–æ–ª—Ç–æ–≤
    print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
    shape1 = safe_read_step_file(step_file_1)
    shape2 = safe_read_step_file(step_file_2)
    
    if shape1 is None or shape2 is None:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –æ–¥–Ω—É –∏–ª–∏ –æ–±–µ –º–æ–¥–µ–ª–∏")
        return None
    
    # 2. –°–æ–≤–º–µ—â–µ–Ω–∏–µ
    print("üîß –°–æ–≤–º–µ—â–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
    R_mat, t_vec = None, None
    
    if use_gnn:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –º–æ–¥–µ–ª–∏
        if not os.path.exists(model_path):
            print(f"‚ö†Ô∏è –ú–æ–¥–µ–ª—å {model_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É")
            use_gnn = False
        else:
            try:
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4)
                model.load_state_dict(torch.load(model_path, map_location='cpu'))
                model.eval()
                
                # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–æ–ø–æ–ª–æ–≥–∏–∏ –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–æ–≤
                v1, fv1 = extract_topology(shape1)
                v2, fv2 = extract_topology(shape2)
                g1 = build_graph(v1, fv1)
                g2 = build_graph(v2, fv2)
                
                # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ä–æ–ª–µ–π
                with torch.no_grad():
                    batch1 = torch.zeros(g1.x.size(0), dtype=torch.long)
                    batch2 = torch.zeros(g2.x.size(0), dtype=torch.long)
                    roles1, _ = model(g1.x, g1.edge_index, batch1)
                    roles2, _ = model(g2.x, g2.edge_index, batch2)
                
                # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–Ω—Ç—Ä–∞ –º–∞—Å—Å (–≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω)
                cog1 = np.array(compute_center_of_mass(shape1))
                cog2 = np.array(compute_center_of_mass(shape2))
                
                # –ü–æ–∏—Å–∫ –æ—Ç–≤–µ—Ä—Å—Ç–∏–π (—Ä–æ–ª—å 2) –∏ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3)
                holes1 = find_elements_by_role(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy(), role_idx=2, top_k=2)
                holes2 = find_elements_by_role(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy(), role_idx=2, top_k=2)
                ref_planes1 = find_elements_by_role(roles1.softmax(dim=1).numpy(), g1.node_type.numpy(), g1.x[:, :3].numpy(), role_idx=3, top_k=2)
                ref_planes2 = find_elements_by_role(roles2.softmax(dim=1).numpy(), g2.node_type.numpy(), g2.x[:, :3].numpy(), role_idx=3, top_k=2)
                
                # –°–±–æ—Ä —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (–≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞)
                points1 = [cog1]  # –¶–µ–Ω—Ç—Ä –º–∞—Å—Å ‚Äî –ø–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞!
                points2 = [cog2]
                points1.extend(holes1[:min(2, len(holes1))])      # –î–æ 2 –æ—Ç–≤–µ—Ä—Å—Ç–∏–π
                points2.extend(holes2[:min(2, len(holes2))])
                points1.extend(ref_planes1[:min(2, len(ref_planes1))])  # –î–æ 2 –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π
                points2.extend(ref_planes2[:min(2, len(ref_planes2))])
                
                # –°–æ–≤–º–µ—â–µ–Ω–∏–µ –ø–æ –ø–µ—Ä–≤—ã–º 3 —Ç–æ—á–∫–∞–º
                if len(points1) >= 3 and len(points2) >= 3:
                    src_pts = np.array(points1[:3])
                    tgt_pts = np.array(points2[:3])
                    R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)
                    print(f"‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ GNN –≤—ã–ø–æ–ª–Ω–µ–Ω–æ –ø–æ {len(points1[:3])} —Ç–æ—á–∫–∞–º:")
                    print(f"   ‚Ä¢ –¶–µ–Ω—Ç—Ä –º–∞—Å—Å")
                    print(f"   ‚Ä¢ {len(holes1[:2])} –æ—Ç–≤–µ—Ä—Å—Ç–∏–π")
                    print(f"   ‚Ä¢ {len(ref_planes1[:2])} –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π")
                else:
                    print(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è —Å–æ–≤–º–µ—â–µ–Ω–∏—è (–Ω–∞–π–¥–µ–Ω–æ: {len(points1)}/{len(points2)}, –Ω—É–∂–Ω–æ ‚â•3) ‚Äî –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É")
                    use_gnn = False
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ GNN ({type(e).__name__}): {e}")
                print("‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –±–µ–∑ GNN")
                use_gnn = False
    
    # –†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥: —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ –∫—Ä—É–ø–Ω—ã–º –ø–ª–æ—Å–∫–∏–º –≥—Ä–∞–Ω—è–º
    if not use_gnn:
        planes1 = extract_large_planes(shape1, min_area=10.0, max_planes=5)
        planes2 = extract_large_planes(shape2, min_area=10.0, max_planes=5)
        
        if len(planes1) >= 3 and len(planes2) >= 3:
            src_pts = np.array([p['center'] for p in planes1[:3]])
            tgt_pts = np.array([p['center'] for p in planes2[:3]])
            R_mat, t_vec = align_with_umeyama(src_pts, tgt_pts)
            print("‚úÖ –°–æ–≤–º–µ—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ —ç–≤—Ä–∏—Å—Ç–∏–∫—É –≤—ã–ø–æ–ª–Ω–µ–Ω–æ (–ø–æ 3 –∫—Ä—É–ø–Ω–µ–π—à–∏–º –ø–ª–æ—Å–∫–æ—Å—Ç—è–º)")
        else:
            print("‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–ª–æ—Å–∫–∏—Ö –≥—Ä–∞–Ω–µ–π ‚Äî –ø—Ä–∏–º–µ–Ω—è—é —Ç–æ–∂–¥–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ")
            R_mat, t_vec = np.eye(3), np.zeros(3)
    
    # 3. –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è
    trsf = gp_Trsf()
    trsf.SetValues(
        float(R_mat[0,0]), float(R_mat[0,1]), float(R_mat[0,2]), float(t_vec[0]),
        float(R_mat[1,0]), float(R_mat[1,1]), float(R_mat[1,2]), float(t_vec[1]),
        float(R_mat[2,0]), float(R_mat[2,1]), float(R_mat[2,2]), float(t_vec[2])
    )
    
    transform = BRepBuilderAPI_Transform(shape2, trsf)
    shape2_aligned = transform.Shape()
    gc.collect()
    
    # 4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ–≤–º–µ—â—ë–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
    os.makedirs("outputs/results", exist_ok=True)
    writer = STEPControl_Writer()
    writer.Transfer(shape2_aligned, STEPControl_AsIs)
    writer.Write("outputs/results/aligned_model.step")
    print("üíæ –°–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: outputs/results/aligned_model.step")
    
    # 5. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è
    print("\nüìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è...")
    metrics = evaluate_alignment(shape1, shape2_aligned, n_max_vertices=2000)
    if metrics['success']:
        print(f"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {metrics['mean_distance']:.4f} –º–º")
        print(f"   –¢–æ—á–µ–∫ < 0.1 –º–º: {metrics['inlier_ratio_0.1mm']*100:.1f}%")
    
    # 6. –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏
    print("\nüîç –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–ª–∏—á–∏–π —á–µ—Ä–µ–∑ –±—É–ª–µ–≤—ã –æ–ø–µ—Ä–∞—Ü–∏–∏...")
    analysis = analyze_differences(shape1, shape2_aligned, tolerance=1e-3)
    
    print(f"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 1:     {analysis['volume_model1']:.2f} –º–º¬≥")
    print(f"   –û–±—ä—ë–º –º–æ–¥–µ–ª–∏ 2:     {analysis['volume_model2']:.2f} –º–º¬≥")
    print(f"   –†–∞–∑–ª–∏—á–∏—è:           {analysis['difference_percent']:.2f}%")
    
    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è
    if analysis['difference_percent'] < 0.1:
        print("‚úÖ –ú–æ–¥–µ–ª–∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –∏–¥–µ–Ω—Ç–∏—á–Ω—ã")
    elif analysis['difference_percent'] < 1.0:
        print("‚ö†Ô∏è  –ú–æ–¥–µ–ª–∏ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏ (–≤–æ–∑–º–æ–∂–Ω—ã –¥–æ–ø—É—Å–∫–∏)")
    elif analysis['difference_percent'] < 5.0:
        print("üî∂ –ú–æ–¥–µ–ª–∏ —É–º–µ—Ä–µ–Ω–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
    else:
        print("‚ùå –ú–æ–¥–µ–ª–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–ª–∏—á–∞—é—Ç—Å—è")
    
    # 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
    saved_files = save_boolean_results(analysis['results'], "outputs/boolean")
    if saved_files:
        print(f"\nüíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã —Ñ–∞–π–ª—ã –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏:")
        for fname in saved_files:
            print(f"   ‚Ä¢ outputs/boolean/{fname}")
        print("\nüí° –û—Ç–∫—Ä–æ–π—Ç–µ 'all_differences.step' –≤ FreeCAD –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä–∞–∑–ª–∏—á–∏–π")
    
    gc.collect()
    return {
        'alignment_metrics': metrics,
        'difference_analysis': analysis,
        'saved_files': saved_files
    }


# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 8. –ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø –ò –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

if __name__ == "__main__":
    print("="*70)
    print("üöÄ –ó–ê–ü–£–°–ö –ü–û–õ–ù–û–ì–û –ü–ê–ô–ü–õ–ê–ô–ù–ê: –ì–ï–ù–ï–†–ê–¶–ò–Ø ‚Üí –û–ë–£–ß–ï–ù–ò–ï ‚Üí –°–û–í–ú–ï–©–ï–ù–ò–ï ‚Üí –ë–£–õ–ï–í–´ –û–ü–ï–†–ê–¶–ò–ò")
    print("="*70)
    
    # –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞ (50 –º–æ–¥–µ–ª–µ–π –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞)
    print("\nüîÑ –®–∞–≥ 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ (50 –º–æ–¥–µ–ª–µ–π)...")
    dataset_path = generate_enhanced_dataset("enhanced_dataset", n_samples=50)
    
    # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    print("\nüîÑ –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
    dataset = FixedSyntheticDataset(root="enhanced_dataset")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏
    test_data = dataset[0]
    face_mask = (test_data.node_type == 1)
    role3_count = (test_data.y[face_mask] == 3).sum().item()
    print(f"‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ç–∫–∏: –Ω–∞–π–¥–µ–Ω–æ –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π (—Ä–æ–ª—å 3) –≤ –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏: {role3_count}/14")
    
    if role3_count < 3:
        print("‚ùå –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –í —Ä–∞–∑–º–µ—Ç–∫–µ –Ω–µ—Ç –æ–ø–æ—Ä–Ω—ã—Ö –ø–ª–æ—Å–∫–æ—Å—Ç–µ–π!")
        print("   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ—É–Ω–∫—Ü–∏—é create_synthetic_part ‚Äî –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤—Å–µ 4 —Ç–∏–ø–∞ –¥–µ—Ç–∞–ª–µ–π")
        sys.exit(1)
    
    # –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
    print("\nüîÑ –®–∞–≥ 3: –û–±—É—á–µ–Ω–∏–µ GNN –Ω–∞ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    
    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é/–≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
    train_size = int(0.8 * len(dataset))
    val_size = len(dataset) - train_size
    from torch.utils.data import random_split
    train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=torch.Generator().manual_seed(42))
    
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)  # —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–π –±–∞—Ç—á –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
    device = torch.device('cpu')
    model = GNNModel(in_channels=3, hidden_dim=64, num_roles=4).to(device)
    
    # –£—Å–∏–ª–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –¥–ª—è —Ä–æ–ª–∏ 3 (–æ–ø–æ—Ä–Ω—ã–µ –ø–ª–æ—Å–∫–æ—Å—Ç–∏)
    class_weights = torch.tensor([0.2, 0.3, 1.0, 10.0], dtype=torch.float, device=device)
    criterion = torch.nn.CrossEntropyLoss(weight=class_weights)
    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)
    
    best_val_loss = float('inf')
    print("\n–û–±—É—á–µ–Ω–∏–µ (10 —ç–ø–æ—Ö –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞)...\n")
    
    for epoch in range(10):  # 10 —ç–ø–æ—Ö –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        model.train()
        train_loss = 0
        for data in train_loader:
            data = data.to(device)
            batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)
            roles_pred, _ = model(data.x, data.edge_index, batch)
            
            face_mask = (data.node_type == 1)
            if face_mask.sum() > 0:
                loss = criterion(roles_pred[face_mask], data.y[face_mask])
                optimizer.zero_grad()
                loss.backward()
                optimizer.step()
                train_loss += loss.item() * data.num_graphs
        
        avg_train_loss = train_loss / len(train_loader.dataset)
        
        # –í–∞–ª–∏–¥–∞—Ü–∏—è
        model.eval()
        val_loss = 0
        with torch.no_grad():
            for data in val_loader:
                data = data.to(device)
                batch = torch.zeros(data.x.size(0), dtype=torch.long, device=device)
                roles_pred, _ = model(data.x, data.edge_index, batch)
                
                face_mask = (data.node_type == 1)
                if face_mask.sum() > 0:
                    loss = criterion(roles_pred[face_mask], data.y[face_mask])
                    val_loss += loss.item() * data.num_graphs
        
        avg_val_loss = val_loss / len(val_loader.dataset)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª—É—á—à–µ–π –º–æ–¥–µ–ª–∏
        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            torch.save(model.state_dict(), "gnn_best.pth")
            status = "‚≠ê"
        else:
            status = ""
        
        print(f"–≠–ø–æ—Ö–∞ {epoch+1:2d}/10 | Loss: {avg_train_loss:.4f} ‚Üí {avg_val_loss:.4f} {status}")
    
    print(f"\n‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: gnn_best.pth")
    
    # –®–∞–≥ 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö
    print("\nüîÑ –®–∞–≥ 4: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª—è—Ö...")
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç–µ –í–ê–®–ò —Ä–µ–∞–ª—å–Ω—ã–µ –º–æ–¥–µ–ª–∏ (–∑–∞–º–µ–Ω–∏—Ç–µ –ø—É—Ç–∏ –Ω–∞ –≤–∞—à–∏ —Ñ–∞–π–ª—ã)
    STEP_FILE_1 = "test.step"
    STEP_FILE_2 = "test1.step"
    
    if not os.path.exists(STEP_FILE_1) or not os.path.exists(STEP_FILE_2):
        print(f"‚ö†Ô∏è –§–∞–π–ª—ã {STEP_FILE_1} –∏–ª–∏ {STEP_FILE_2} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        print("   –°–æ–∑–¥–∞—ë–º —Ç–µ—Å—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏...")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ –¥–≤–µ –º–æ–¥–µ–ª–∏ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∫–∞–∫ —Ç–µ—Å—Ç–æ–≤—ã–µ
        reader1 = STEPControl.STEPControl_Reader()
        reader1.ReadFile("enhanced_dataset/raw/bracket_000000.step")
        reader1.TransferRoots()
        shape1_test = reader1.OneShape()
        
        reader2 = STEPControl.STEPControl_Reader()
        reader2.ReadFile("enhanced_dataset/raw/flange_000001.step")
        reader2.TransferRoots()
        shape2_test = reader2.OneShape()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã
        writer1 = STEPControl_Writer()
        writer1.Transfer(shape1_test, STEPControl_AsIs)
        writer1.Write("test.step")
        
        writer2 = STEPControl_Writer()
        writer2.Transfer(shape2_test, STEPControl_AsIs)
        writer2.Write("test1.step")
        
        STEP_FILE_1 = "test.step"
        STEP_FILE_2 = "test1.step"
        print(f"‚úÖ –°–æ–∑–¥–∞–Ω—ã —Ç–µ—Å—Ç–æ–≤—ã–µ —Ñ–∞–π–ª—ã: {STEP_FILE_1}, {STEP_FILE_2}")
    
    # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é
    print("\nüöÄ –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞ —Å–æ–≤–º–µ—â–µ–Ω–∏—è —Å –æ–±—É—á–µ–Ω–Ω–æ–π GNN...")
    results = main_pipeline(
        step_file_1=STEP_FILE_1,
        step_file_2=STEP_FILE_2,
        use_gnn=True,
        model_path="gnn_best.pth"
    )
    
    if results is not None:
        print("\n" + "="*70)
        print("‚úÖ –ü–ê–ô–ü–õ–ê–ô–ù –ó–ê–í–ï–†–®–Å–ù –£–°–ü–ï–®–ù–û!")
        print("="*70)
        print("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        print("  ‚Ä¢ outputs/results/aligned_model.step ‚Äî —Å–æ–≤–º–µ—â—ë–Ω–Ω–∞—è –º–æ–¥–µ–ª—å")
        print("  ‚Ä¢ outputs/boolean/ ‚Äî —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–ª–µ–≤—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
        print("\nüí° –°–æ–≤–µ—Ç—ã:")
        print("  1. –û—Ç–∫—Ä–æ–π—Ç–µ aligned_model.step –≤ FreeCAD –¥–ª—è –≤–∏–∑—É–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–æ–≤–º–µ—â–µ–Ω–∏—è")
        print("  2. –û—Ç–∫—Ä–æ–π—Ç–µ all_differences.step –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞–∑–ª–∏—á–∏–π –º–µ–∂–¥—É –º–æ–¥–µ–ª—è–º–∏")
        print("  3. –î–ª—è –ø—Ä–æ–º—ã—à–ª–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –Ω–∞ 500+ –º–æ–¥–µ–ª—è—Ö")
    else:
        print("\n‚ùå –ü–∞–π–ø–ª–∞–π–Ω –∑–∞–≤–µ—Ä—à–∏–ª—Å—è —Å –æ—à–∏–±–∫–æ–π")